---
title: "Statistical Modelling of Operational Risk Stress-Testing with 2 Modelling Approaches: Regression Model and Historical Simulation Model using R Programming Language (version 3.0)"
author: "Imir Osmanov"
date: "`r Sys.Date()`"
output:
  pdf_document:
    latex_engine: xelatex
    fig_caption: yes
    number_sections: yes
    toc: yes
    toc_depth: 3
    includes:
      in_header: preamble.tex
  html_document:
    df_print: paged
    toc: yes
    toc_depth: 3
    toc_float: yes
    number_sections: yes
  word_document:
    toc: yes
    toc_depth: 3
    fig_caption: yes
geometry: a4paper, left=0.5in, right=0.5in, top=0.5in, bottom=0.5in
fontsize: 10pt
header-includes:
  - \usepackage{booktabs}
  - \usepackage{xcolor}
  - \usepackage{longtable}
  - \usepackage{titling}
  - \usepackage{lmodern}  # Ensures smooth font rendering
  - \usepackage{etoolbox} # Helps with modifying \maketitle
  - \pretitle{\begin{center}\large}
  - \posttitle{\par\end{center}\vspace{1em}}
  - \preauthor{\begin{center}\large}
  - \postauthor{\par\end{center}\vspace{1em}}
  - \predate{\begin{center}\large}
  - \postdate{\par\end{center}\vspace{2em}\newpage}
---








# Introduction

Operational Risk loss stress testing (forecasting) is performed using two modeling approaches:

Regression Model – This includes a Linear Regression Model and a Generalized Additive Model (GAM) to estimate loss amounts (impact/severity) and a Poisson Regression Model to assess the frequency (number) of Operational Risk events.
Historical Simulation Model – This involves computing Operational Risk Value-at-Risk (VaR) using Monte Carlo simulation.
All modeling and analysis are conducted in the R programming language. The methodology follows an adaptation of the Federal Reserve System’s Dodd-Frank Act Stress Test framework (source).

Historical data on Operational Risk losses is obtained from the "OpVaR" R package (now archived). Since the currency of losses is unspecified, they are assumed to be in US dollars. This dataset is used for all computations within the notebook.

Banking statistics for second-tier banks in Kazakhstan are sourced from the National Bank of Kazakhstan (www.nationalbank.kz), while macroeconomic data for Kazakhstan is retrieved from the "AFR" R package.

This project is solely for educational purposes, aiming to demonstrate proficiency in R programming and statistical modeling. It does not intend to provide financial forecasts, conclusions, or methodological recommendations.

Note: The Operational Risk loss data used in this project does not represent the Kazakhstani banking industry and does not reflect its actual Operational Risk exposure.

# Executive Summary
## Purpose:
The objective of this analysis is to apply statistical methodologies for stress testing Operational Risk using two modeling approaches:

Regression Model (Macroeconomic Model) – This involves various regression techniques, including Multiple Linear Regression, Generalized Additive Model (GAM), and Multiple Poisson Regression, to model the impact of macroeconomic factors on Operational Risk losses.
Historical Simulation Model – This computes Operational Risk Value-at-Risk (VaR) using Monte Carlo simulation.
The study focuses on developing a methodology for Operational Risk Stress Testing, leveraging automation within the R programming language to enhance efficiency and reproducibility.

## Main findings:
Stress testing of Operational Risk was conducted using the following approaches:

Severity Prediction: Multiple Linear Regression (MLR) and the Generalized Additive Model (GAM) were used to predict the severity of losses.
Frequency Prediction: Multiple Poisson Regression was applied to estimate the frequency (number) of Operational Risk losses. A statistical threshold of 0.35 (35%) for R^2 and an alpha level of 0.1 (90% confidence) were used as evaluation criteria.
Value-at-Risk Estimation: Monte Carlo simulation was employed to estimate Operational Risk Value-at-Risk (VaR) at 95%, 99%, and 99.9% confidence levels.
Model Selection and Performance
Since the assumptions of linearity and normality were not fully met for MLR, alternative non-linear models were tested, including second-degree, third-degree, and sixth-degree Polynomial Regression models, as well as GAM.

Polynomial Regression models yielded higher R^2 values:

Second-degree: R^2 = 0.449 (44.9%)
Third-degree: R^2 = 0.562 (56.2%)
Sixth-degree: R^2 = 0.867 (86.7%)
However, all p-values for independent variables exceeded the alpha threshold of 0.1, making them statistically insignificant. As a result, these models were not used for stress testing.
Generalized Additive Model (GAM):

Adjusted R^2 = 0.359 (35.9%)
Explained 44% of the deviance
All p-values were below the alpha threshold of 0.1
Multiple Linear Regression (MLR):

R^2 = 0.4426 (44.3%)
Adjusted R^2 = 0.359 (35.9%)
All p-values were below 0.1
Since GAM and MLR both met the statistical significance criteria, the null hypothesis (H0) was rejected in favor of the alternative hypothesis (HA), confirming a relationship between Operational Risk losses and macroeconomic variables.

**Optimal Model for Predicting Loss Severity**

The optimal model was selected from 1,330 possible combinations of independent macroeconomic variables based on the highest R^2 (Coefficient of Determination) and statistical tests. The most effective model for predicting the amount (severity) of Operational Risk losses was determined using the following independent variables from the "AFR" R package dataset:

GDD_Trn_R_y: Real Gross Value Added for Transportation

GDD_Inf_R_y: Real Gross Value Added for Information

Rincpop_q_y: Real Population Average Monthly Income

The dependent variable was the proportion of total Operational Risk losses in the assets of Bank "X", which were taken as total assets of banking system.

**Frequency of Losses**

Multiple Poisson Regression was employed to estimate the frequency of losses. The results indicated that Multiple Poisson Regression provided reasonable predictions, with Multiple Negative Binomial Regression closely aligning with its outcomes. A statistical threshold of 0.35 (35%) for R^2 and an alpha level of 0.1 (90% confidence) were maintained.

The best model for predicting loss frequency was identified using Multiple Poisson Regression with the following independent variables:

ruktzt: RUB/KZT exchange rate

Rincpop_q_y: Real Population Average Monthly Income

GDD_R_y: Real Gross Value Added

The dependent variable was the total frequency of Operational Risk losses for Bank "X". The Pseudo R^2 for this model was 0.48 (r2ML, r2CU), with all p-values below the 0.1 threshold. Consequently, the null hypothesis (H0) was rejected in favor of the alternative hypothesis (Ha), reinforcing the correlation between frequency of Operational Risk losses and macroeconomic variables.

**Correlation Analysis**

Across all models, a negative correlation was observed between independent and dependent variables.

**Predicted Outcomes**

**Multiple Linear Regression (Loss Severity)**

Positive Scenario:

Highest loss: KZT 46,228,220

Lowest loss: KZT 36,771,242

Negative Scenario:

Highest loss: KZT 54,684,134

Lowest loss: KZT 52,068,502

**Generalized Additive Model (Loss Severity)**

Positive Scenario:

Highest loss: KZT 27,999,022

Lowest loss: KZT 25,739,693

Negative Scenario:

Highest loss: KZT 63,592,518

Lowest loss: KZT 61,240,187

**Multiple Poisson Regression (Loss Frequency)**

Positive Scenario:

Highest frequency: 3,101

Lowest frequency: 568

Negative Scenario:

Highest frequency: 162

Lowest frequency: 115

**Historical Simulation Model**
Computation of Operational Risk Value-at-Risk (VaR)
Operational Risk Value-at-Risk (VaR) was computed using the Poisson Distribution to model the frequency (number) of Operational Risk events and Weibull and Log-Normal Distributions to model the severity (impact) of Operational Risk events. These distributions were selected based on statistical estimation results.

**Monthly Expected Loss (EL)**
The Expected Loss (EL), representing the mathematical expectation, was KZT 13,512,161 for the mean value and KZT 12,173,884 for the median value. These values remained consistent across all confidence intervals (75%, 95%, 99%, and 99.9%).

**Monthly Operational Risk Value-at-Risk (VaR)**
At a 95% confidence level, the monthly VaR was KZT 26,360,656, with an Unexpected Loss (UL) of KZT 12,848,494 based on the mean and KZT 14,186,771 based on the median.

At a 99% confidence level, the monthly VaR increased to KZT 35,823,119, with an Unexpected Loss (UL) of KZT 22,310,958 for the mean and KZT 23,649,235 for the median.

At a 99.9% confidence level, the monthly VaR reached KZT 52,619,586, while the Unexpected Loss (UL) was KZT 39,107,424 for the mean and KZT 40,445,701 for the median.

**Quarterly Expected Loss (EL)**
The Expected Loss (EL) was scaled linearly over time by multiplying the monthly EL by 3. As a result, the quarterly EL was KZT 40,536,484 for the mean and KZT 36,521,653 for the median, remaining the same across all confidence intervals.

Quarterly Operational Risk Value-at-Risk (VaR)
Quarterly VaR was computed by multiplying the monthly VaR by the square root of 3.

At a 95% confidence level, the quarterly VaR was KZT 45,657,995, with an Unexpected Loss (UL) of KZT 5,121,511 for the mean and KZT 9,136,341 for the median.

At a 99% confidence level, the quarterly VaR increased to KZT 62,047,463, while the Unexpected Loss (UL) was KZT 21,510,979 for the mean and KZT 25,525,810 for the median.

At a 99.9% confidence level, the quarterly VaR was KZT 91,139,796, with an Unexpected Loss (UL) of KZT 50,603,312 for the mean and KZT 54,618,143 for the median.

**Operational Risk Loss Estimates**
Final Operational Risk Loss estimates are derived as the average of projections of 2 modelling approaches: 1) Regression Model and 2) Historical Simulation Model, and are following:

**Average of Multiple Linear Regression (Loss Severity) and Monte-Carlo Simulation (95% and 99.9% confidence levels)**

Positive Scenario:

Highest loss: KZT 45,943,965

Lowest loss: KZT 41,214,107

Negative Scenario:

Highest loss: KZT 72,911,965

Lowest loss: KZT 71,604,149

**Average of Generalized Additive Model (Loss Severity) and Monte-Carlo Simulation (95% and 99.9% confidence levels)**

Positive Scenario:

Highest loss: KZT 36,828,508

Lowest loss: KZT 35,698,844

Negative Scenario:

Highest loss: KZT 77,366,157

Lowest loss: KZT 76,189,991.

**Final Considerations**

The results of this stress testing should be interpreted with caution, as certain modeling assumptions, such as linearity and normality in Regression Models, were not fully met. However, despite these limitations, the findings offer meaningful insights into the relationship between Operational Risk losses and macroeconomic variables, contributing to risk assessment and mitigation efforts.

## Methodology:
The methodology for modeling Operational Risk losses consists of two key approaches:

Regression Models – This includes Multiple Linear Regression and non-linear models such as Polynomial Regression and the Generalized Additive Model (GAM) for predicting the severity (impact) of losses, along with Multiple Poisson Regression for estimating the frequency (number) of Operational Risk events. The optimal regression model was selected from 1,330 possible combinations of independent macroeconomic variables based on the highest R² (Coefficient of Determination) and statistical validation. Additionally, the model successfully passed statistical tests for multicollinearity (Variance Inflation Factor) and stationarity.

Historical Simulation Model – Operational Risk Value-at-Risk (VaR) estimation was conducted using Monte Carlo simulation.

Forecasting of Operational Risk losses was performed using coefficients derived from the regression models. Loss amounts were expressed as a proportion of total Operational Risk losses relative to total assets, with total asset values obtained from the "Total Assets" of all second-tier banks in Kazakhstan. Data on Operational Risk loss amounts and frequencies were sourced from the "OpVaR" R package.

This methodology is based on the Federal Reserve System Dodd-Frank Act Stress-Test methodology, which suggests that Operational Risk loss estimates should be derived as the average projection from two modeling approaches: a Linear Regression Model and a Historical Simulation Model. The Regression Model captures the sensitivity of Operational Risk losses to macroeconomic fluctuations, while the Simulation Model accounts for variations in losses across different types of Operational Risk events.

## Recommendations:
While directly correlating individual company financial data with national macroeconomic variables presents challenges, further research is recommended to explore the relationships between macroeconomic factors and specific categories of Operational Risk. Regression models could be applied to identify potential links, particularly for the following Basel Operational Risk categories:

1. Internal Fraud

2. External Fraud

3. Employment Practices and Workplace Safety

4. Clients, Products, and Business Practices

5. Execution, Delivery, and Process Management

6. Business Disruption and System Failures

7. Damage to Physical Assets
(Note: Damage to Physical Assets is expected to show no significant relationship with macroeconomic variables).

# Analysis of Dependent and Independent (Macroeconomic) Variables
## Importing required R packages (libraries):
```{r message=FALSE, warning=FALSE}
# Importing required R packages (libraries):
library(AFR)
library(tidyverse)
library(ggplot2)
library(readxl)
library(corrplot)
library(lubridate)
library(scales)
library(zoo)
library(combinat)
library(car)
library(lmtest)
library(tseries)
library(MASS)
library(dplyr)
library(ggfortify)
library(GGally)
library(glm2)
library(pscl)
library(MASS)
library(ggpubr)
library(mgcv)
library(knitr)
library(kableExtra)
library(extraDistr)
library(fitdistrplus)
library(nortest)
```

## Analysis of Dependent Variables

### Banking industry statistics

#### Downloading banking industry statistics

```{r warning=FALSE}
# Downloading necessary files
# Banking statistics
banking_stats <- read_csv("C:\\Users\\user\\Documents\\Imir\\My Data Analysis Projects\\Data\\bank_stats_2010_2023.csv")
banking_stats <- as.data.frame(banking_stats)
head(banking_stats)
tail(banking_stats)
```
```{r}
# Checking dataframes for datatypes and size
summary(banking_stats)
str(banking_stats)
```
**Findings:** The banking industry statistics reflect the total assets value of second-tier banks. A total of 168 observations were recorded for the period from January 1, 2010, to December 1, 2023.

```{r}
# Checking for missing values
cat("\nMissing values per column:\n")
missing_values <- colSums(is.na(banking_stats))
print(missing_values)

# Checking for duplicated rows
cat("\nDuplicated rows:\n")
duplicated_rows <- banking_stats[duplicated(banking_stats), ]
if (nrow(duplicated_rows) > 0) {
  print(duplicated_rows)
} else {
  cat("No duplicated rows found.\n")
}
```
**Findings:** The data frame on banking statistics contains no missing or duplicated values.

#### Data preprocessing

```{r}
# Dropping columns "File Name"
banking_stats <- banking_stats %>% dplyr::select(-`File Name`)
```

```{r}
# Renaming column "Sheet Name" to "Date"
banking_stats <- banking_stats %>% rename(Date = `Sheet Name`, Value = Value)
str(banking_stats)
```
```{r}
# Changing data types of "Date" and "Value" columns
banking_stats$`Date` <- as.Date(banking_stats$`Date`, format = "%d.%m.%Y")
banking_stats$Value <- format(banking_stats$Value, scientific = FALSE)
str(banking_stats)
```
```{r}
# Checking data frame
head(banking_stats)
tail(banking_stats)
```
```{r}
# Filtering dataframe to include only data for 3, 6, 9 and 12 months 
# or 1st, 2nd, 3rd and 4th Quarters.
banking_stats$Date <- as.Date(banking_stats$Date)
banking_stats_filtered <- banking_stats %>% 
  filter(format(Date, "%m") %in% c("03", "06", "09", "12"))
```

```{r}
# Checking data frame
str(banking_stats_filtered)
head(banking_stats_filtered)
tail(banking_stats_filtered)
```
**Findings:** The "Value" column is of character data type and needs to be corrected.

```{r}
# Create a new column for 'Value (Billion)'
# Convert 'Value' column to numeric
banking_stats_filtered$Value <- as.numeric(banking_stats_filtered$Value)

# Now perform the division to create the 'Value (Billion)' column
banking_stats_filtered$`Value_billion` <- banking_stats_filtered$Value / 1000000000
```

```{r}
# Checking the data frame
str(banking_stats_filtered)
head(banking_stats_filtered)
```
#### Analisys of banking industry statistics

```{r}
# Analyzing the data frame
glimpse(banking_stats_filtered)
summary(banking_stats_filtered)
```
**Findings:** The minimum value in the data frame is KZT 11.75 billion, the mean is KZT 24.07 billion, and the maximum value is KZT 49.17 billion.

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating the line plot
ggplot(banking_stats_filtered, aes(x = Date, y = `Value_billion`)) +
  geom_line() + 
  geom_point() +  
  labs(
    x = 'Year',
    y = 'Total Assets (Billions KZT)',
    title = 'Total Assets of Banking System'
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
**Findings:** The total assets of Kazakhstan's banking industry have experienced consistent and rapid growth over time, with no significant downturns observed.

### Operational Risk Losses

#### Downloading data on Operational Risk Losses

#### Operational Risk Type 1

```{r}
# Downloading necessary files
# Operational losses type 1
or_type1 <- read_excel("C:\\Users\\user\\Documents\\Imir\\My Data Analysis Projects\\Data\\file1.xlsx")
or_type1 <- as.data.frame(or_type1)
head(or_type1)
tail(or_type1)
```
#### Exploratory Data Analysis of Operational Risk Type 1
```{r}
# Checking for missing values
cat("\nMissing values per column:\n")
missing_values <- colSums(is.na(or_type1))
print(missing_values)

# Checking for duplicated rows
cat("\nDuplicated rows:\n")
duplicated_rows <- or_type1[duplicated(or_type1), ]
if (nrow(duplicated_rows) > 0) {
  print(duplicated_rows)
} else {
  cat("No duplicated rows found.\n")
}
```
**Findings:** There are no null or duplicated values in Operational Risk Type 1.

```{r}
# Exploratory data analysis
summary(or_type1)
glimpse(or_type1)
str(or_type1)
```
**Findings:** The dataset contains 1,965 observations for Operational Risk Type 1, with all columns having appropriate data types. The descriptive statistics for the dataset are as follows:
Minimum value: USD 5
Mean: USD 1,017
Median: USD 760
Maximum value: USD 6,382

#### Visualization of Operational Risk Type 1

```{r fig.align="center", fig.width=6, fig.height=4}
# Histogram of distribution of Operational Risk Losses type 1
ggplot(data = or_type1, mapping = aes(x = Loss)) +
  geom_histogram(binwidth = 50, 
                 fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Operational Risk Type 1", 
       x = "Loss amount (USD)", y = "Frequency") +
  theme_bw()
```
```{r fig.align="center", fig.width=6, fig.height=4}
# Boxplot of distribution of Operational Risk Losses type 1
ggplot(data = or_type1, mapping = aes(x = Loss)) +
  geom_boxplot(fill = "blue", 
               color = "black", alpha = 0.7) +
  labs(title = "Boxplot of Operational Risk Type 1", 
       x = "Loss amount (USD)") +
  theme_bw()
```
**Findings:** The histogram and boxplot reveal the presence of outliers, which is further confirmed by the significant difference between the mean and the median.

#### Data preprocessing for Operational Risk Type 1

```{r}
# Extracting outliers from dataframe
Quartile_1 <- quantile(or_type1$Loss, 0.25) 
Quartile_3 <- quantile(or_type1$Loss, 0.75) 
IQR <- Quartile_3 - Quartile_1                 
lower_bound <- Quartile_1 - 1.5 * IQR         
upper_bound <- Quartile_3 + 1.5 * IQR        

# Identifying outliers
outliers_loss_1 <- or_type1$Loss[or_type1$Loss < lower_bound | or_type1$Loss > upper_bound]

# Print the outliers
print("Outliers (IQR method):")
print(outliers_loss_1)

```
```{r}
# Filtering the dataset to exclude outliers
or_type1_cleaned <- or_type1[or_type1$Loss >= lower_bound & 
                               or_type1$Loss <= upper_bound, ]

# Print the cleaned dataset
print("Dataset after removing outliers:")
head(or_type1_cleaned)
str(or_type1_cleaned)
```
```{r}
# Exploratory data analysis
str(or_type1_cleaned)
summary(or_type1_cleaned)
```
**Findings:** There are 1,892 observations for Operational Risk Type 1. All columns have appropriate data types. The descriptive statistics are as follows: minimum value is USD 5, mean is USD 911, median is USD 716, and maximum is USD 3,029. The data has been cleaned of outliers.

#### Visualization of Operational Risk Type 1  after cleaning from outliers
```{r fig.align="center", fig.width=6, fig.height=4}
# Histogram of distribution of Operational Risk Losses type 1
ggplot(data = or_type1_cleaned, mapping = aes(x = Loss)) +
  geom_histogram(binwidth = 50, 
                 fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Operational Risk Type 1 after cleaning from outliers", 
       x = "Loss amount (USD)", y = "Frequency") +
  theme_bw()
```
```{r fig.align="center", fig.width=6, fig.height=4}
# Boxplot of distribution of Operational Risk Losses type 1
ggplot(data = or_type1_cleaned, mapping = aes(x = Loss)) +
  geom_boxplot(fill = "blue", 
               color = "black", alpha = 0.7) +
  labs(title = "Boxplot of Operational Risk Type 1 after cleaning from outliers", 
       x = "Loss amount (USD)") +
  theme_bw()
```
**Findings:** The histogram and boxplot suggest the absence of significant outliers, which is further supported by the minimal difference between the mean and the median.

```{r}
# Extracting 'Year' and 'Month' from the 'Date' column
or_type1_cleaned$Year <- year(or_type1_cleaned$Date)
or_type1_cleaned$Month <- month(or_type1_cleaned$Date)

# Grouping by 'Year' and 'Month', summing the 'Loss' column
or_loss_type1_monthly <- or_type1_cleaned %>%
  group_by(Year, Month) %>%
  summarise(Loss_1 = sum(Loss, na.rm = TRUE), .groups = "drop")
```

```{r}
# Printing the first 5 rows
head(or_loss_type1_monthly)

# Printing the last 5 rows
tail(or_loss_type1_monthly)

str(or_loss_type1_monthly)
```
```{r}
# Creating a 'Month_Group' column based on the specified month intervals 
# (3, 6, 9, 12 months)
or_loss_type1_monthly$Month_Group <- case_when(
  or_loss_type1_monthly$Month %in% c(1, 2, 3) ~ "Q1",
  or_loss_type1_monthly$Month %in% c(4, 5, 6) ~ "Q2",
  or_loss_type1_monthly$Month %in% c(7, 8, 9) ~ "Q3",
  or_loss_type1_monthly$Month %in% c(10, 11, 12) ~ "Q4",
  TRUE ~ "Other"
)

# Grouping by 'Year' and 'Month_Group', summing the 'Loss_1' column
grouped_by_month_type1 <- or_loss_type1_monthly %>%
  group_by(Year, Month_Group) %>%
  summarise(Total_Loss_1 = sum(Loss_1, na.rm = TRUE), .groups = "drop")
```

```{r}
# Checking the results
head(grouped_by_month_type1)
tail(grouped_by_month_type1)
```
```{r}
# Creating a 'Year-Quarter' column in the "YYYY-QX" format
grouped_by_month_type1$Year_Quarter <- paste0(grouped_by_month_type1$Year, 
                                              "-Q", gsub("Q", "", 
                                                         grouped_by_month_type1$Month_Group))

# Checking the results
head(grouped_by_month_type1)

```
```{r}
# Droping 'Year' and 'Month_Group' columns and 
# reordering the remaining columns
or_loss_type1_quarterly <- grouped_by_month_type1 %>% 
  dplyr::select(Year_Quarter, Total_Loss_1)
```

```{r}
# Checking data frame
head(or_loss_type1_quarterly)
```

#### Operational Risk Type 2

```{r}
# Downloading necessary files
# Operational losses type 2
or_type2 <- read_excel("C:\\Users\\user\\Documents\\Imir\\My Data Analysis Projects\\Data\\file2.xlsx")
head(or_type2)
tail(or_type2)
```
#### Exploratory Data Analysis of Operational Risk Type 2

```{r}
# Checking for missing values
cat("\nMissing values per column:\n")
missing_values <- colSums(is.na(or_type2))
print(missing_values)

# Checking for duplicated rows
cat("\nDuplicated rows:\n")
duplicated_rows <- or_type2[duplicated(or_type2), ]
if (nrow(duplicated_rows) > 0) {
  print(duplicated_rows)
} else {
  cat("No duplicated rows found.\n")
}
```
**Findings:** There are no null or duplicated values in Operational Risk Type 2.

```{r}
# Exploratory data analysis
summary(or_type2)
glimpse(or_type2)
str(or_type2)
```
**Findings:** The dataset contains 2,025 observations for Operational Risk Type 2. All columns have appropriate data types. The descriptive statistics are as follows: minimum value is USD 3, mean is USD 1,139, median is USD 850, and maximum is USD 6,213.

#### Visualization of Operational Risk Type 2

```{r fig.align="center", fig.width=6, fig.height=4}
# Histogram of distribution of Operational Risk Losses type 2
ggplot(data = or_type2, mapping = aes(x = Loss)) +
  geom_histogram(binwidth = 50, fill = "red", 
                 color = "black", alpha = 0.7) +
  labs(title = "Histogram of Operational Risk Type 2", 
       x = "Loss amount (USD)", y = "Frequency") +
  theme_bw()
```
```{r fig.align="center", fig.width=6, fig.height=4}
# Boxplot of distribution of Operational Risk Losses type 2
ggplot(data = or_type2, mapping = aes(x = Loss)) +
  geom_boxplot(fill = "red", 
               color = "black", alpha = 0.7) +
  labs(title = "Boxplot of Operational Risk Type 2", 
       x = "Loss amount (USD)") +
  theme_bw()
```
**Findings:** The histogram and boxplot indicate the presence of outliers, as demonstrated by the significant difference between the mean and the median.

#### Data preprocessing for Operational Risk Type 2

```{r}
# Extracting outliers from dataframe
Quartile_1 <- quantile(or_type2$Loss, 0.25) 
Quartile_3 <- quantile(or_type2$Loss, 0.75) 
IQR <- Quartile_3 - Quartile_1                 
lower_bound <- Quartile_1 - 1.5 * IQR       
upper_bound <- Quartile_3 + 1.5 * IQR         

# Identifying outliers
outliers_loss_2 <- or_type2$Loss[or_type2$Loss < lower_bound | or_type2$Loss > upper_bound]

# Print the outliers
print("Outliers (IQR method):")
print(outliers_loss_2)
```
```{r}
# Filtering the dataset to exclude outliers
or_type2_cleaned <- or_type2[or_type2$Loss >= lower_bound & 
                               or_type2$Loss <= upper_bound, ]

# Print the cleaned dataset
print("Dataset after removing outliers:")
head(or_type2_cleaned)
str(or_type2_cleaned)
```
```{r}
# Exploratory data analysis
str(or_type2_cleaned)
summary(or_type2_cleaned)
```
**Findings:** The dataset contains 1,946 observations for Operational Risk Type 2. All columns have appropriate data types. The descriptive statistics are as follows:
Minimum value: USD 3
Mean: USD 1,016.5
Median: USD 806
Maximum value: USD 3,424
The data has been cleaned to remove outliers.

#### Visualization of Operational Risk Type 2 after cleaning from outliers

```{r fig.align="center", fig.width=6, fig.height=4}
# Histogram of distribution of Operational Risk Losses type 2
ggplot(data = or_type2_cleaned, mapping = aes(x = Loss)) +
  geom_histogram(binwidth = 50, fill = "red", 
                 color = "black", alpha = 0.7) +
  labs(title = "Histogram of Operational Risk Type 2 after cleaning from outliers ", 
       x = "Loss amount (USD)", y = "Frequency") +
  theme_bw()
```
```{r fig.align="center", fig.width=6, fig.height=4}
# Boxplot of distribution of Operational Risk Losses type 2
ggplot(data = or_type2_cleaned, mapping = aes(x = Loss)) +
  geom_boxplot(fill = "red", 
               color = "black", alpha = 0.7) +
  labs(title = "Boxplot of Operational Risk Type 2 after cleaning from outliers", 
       x = "Loss amount (USD)") +
  theme_bw()
```
**Findings:** The histogram and boxplot suggest the absence of significant outliers, as evidenced by the minimal difference between the mean and the median.

```{r}
# Extracting 'Year' and 'Month' from the 'Date' column
or_type2_cleaned$Year <- year(or_type2_cleaned$Date)
or_type2_cleaned$Month <- month(or_type2_cleaned$Date)

# Grouping by 'Year' and 'Month', summing the 'Loss' column
or_loss_type2_monthly <- or_type2_cleaned %>%
  group_by(Year, Month) %>%
  summarise(Loss_2 = sum(Loss, na.rm = TRUE), .groups = "drop")
```

```{r}
# Printing the first 5 rows
head(or_loss_type2_monthly)

# Printing the last 5 rows
tail(or_loss_type2_monthly)

str(or_loss_type2_monthly)
```
```{r}
# Creating a 'Month_Group' column based on the specified month intervals 
# (3, 6, 9, 12 months)
or_loss_type2_monthly$Month_Group <- case_when(
  or_loss_type2_monthly$Month %in% c(1, 2, 3) ~ "Q1",
  or_loss_type2_monthly$Month %in% c(4, 5, 6) ~ "Q2",
  or_loss_type2_monthly$Month %in% c(7, 8, 9) ~ "Q3",
  or_loss_type2_monthly$Month %in% c(10, 11, 12) ~ "Q4",
  TRUE ~ "Other"
)

# Grouping by 'Year' and 'Month_Group', summing the 'Loss_1' column
grouped_by_month_type2 <- or_loss_type2_monthly %>%
  group_by(Year, Month_Group) %>%
  summarise(Total_Loss_2 = sum(Loss_2, na.rm = TRUE), .groups = "drop")
```

```{r}
# Checking the results
head(grouped_by_month_type2)
tail(grouped_by_month_type2)
```
```{r}
# Creating a 'Year-Quarter' column in the "YYYY-QX" format
grouped_by_month_type2$Year_Quarter <- paste0(grouped_by_month_type2$Year, 
                                              "-Q", gsub("Q", "", 
                                                         grouped_by_month_type2$Month_Group))

# Checking the results
head(grouped_by_month_type2)

```
```{r}
# Droping 'Year' and 'Month_Group' columns and reordering 
# the remaining columns
or_loss_type2_quarterly <- grouped_by_month_type2 %>% 
  dplyr::select(Year_Quarter, Total_Loss_2)
```

```{r}
# Checking data frame
head(or_loss_type2_quarterly)
```


#### Operational Risk Type 3

```{r}
# Downloading necessary files
# Operational losses type 3
or_type3 <- read_excel("C:\\Users\\user\\Documents\\Imir\\My Data Analysis Projects\\Data\\file3.xlsx")
head(or_type3)
tail(or_type3)
```
#### Exploratory Data Analysis of Operational Risk Type 3

```{r}
# Check for missing values
cat("\nMissing values per column:\n")
missing_values <- colSums(is.na(or_type3))
print(missing_values)

# Check for duplicated rows
cat("\nDuplicated rows:\n")
duplicated_rows <- or_type3[duplicated(or_type3), ]
if (nrow(duplicated_rows) > 0) {
  print(duplicated_rows)
} else {
  cat("No duplicated rows found.\n")
}
```
**Findings:** There are no null and duplicated values in Operational
Risk Type 3.

```{r}
# Exploratory data analysis
summary(or_type3)
glimpse(or_type3)
str(or_type3)
```
**Findings:** The dataset contains 1,995 observations for Operational Risk Type 3. All columns have appropriate data types. The descriptive statistics are as follows:
Minimum value: USD 48
Mean: USD 1,052
Median: USD 788
Maximum value: USD 12,092

#### Visualization of Operational Risk Type 3

```{r fig.align="center", fig.width=6, fig.height=4}
# Histogram of distribution of Operational Risk Losses type 3
ggplot(data = or_type3, mapping = aes(x = Loss)) +
  geom_histogram(binwidth = 50, fill = "green", 
                 color = "black", alpha = 0.7) +
  labs(title = "Histogram of Operational Risk Type 3", 
       x = "Loss amount (USD)", y = "Frequency") +
  theme_bw()
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Boxplot of distribution of Operational Risk Losses type 3
ggplot(data = or_type3, mapping = aes(x = Loss)) +
  geom_boxplot(fill = "green", 
               color = "black", alpha = 0.7) +
  labs(title = "Boxplot of Operational Risk Type 3", 
       x = "Loss amount (USD)") +
  theme_bw()
```
**Findings:** The histogram and boxplot reveal the presence of outliers, as confirmed by the significant difference between the mean and the median.

#### Data preprocessing for Operational Risk Type 3

```{r}
# Extracting outliers from dataframe
Quartile_1 <- quantile(or_type3$Loss, 0.25)
Quartile_3 <- quantile(or_type3$Loss, 0.75) 
IQR <- Quartile_3 - Quartile_1                
lower_bound <- Quartile_1 - 1.5 * IQR     
upper_bound <- Quartile_3 + 1.5 * IQR

# Identifying outliers
outliers_loss_3 <- or_type3$Loss[or_type3$Loss < lower_bound | or_type3$Loss > upper_bound]

# Print the outliers
print("Outliers (IQR method):")
print(outliers_loss_3)
```
```{r}
# Filtering the dataset to exclude outliers
or_type3_cleaned <- or_type3[or_type3$Loss >= lower_bound & 
                               or_type3$Loss <= upper_bound, ]

# Print the cleaned dataset
print("Dataset after removing outliers:")
head(or_type3_cleaned)
str(or_type3_cleaned)
```

```{r}
# Exploratory data analysis
str(or_type3_cleaned)
summary(or_type3_cleaned)
```

**Findings:** The dataset contains 1,888 observations for Operational Risk Type 3. All columns have appropriate data types. The descriptive statistics are as follows:
Minimum value: USD 48
Mean: USD 889.2
Median: USD 747
Maximum value: USD 2,614
The data has been cleaned to remove outliers.

#### Visualization of Operational Risk Type 3 after cleaning from outliers


```{r fig.align="center", fig.width=6, fig.height=4}
# Histogram of distribution of Operational Risk Losses type 3
ggplot(data = or_type3_cleaned, mapping = aes(x = Loss)) +
  geom_histogram(binwidth = 50, fill = "green", 
                 color = "black", alpha = 0.7) +
  labs(title = "Histogram of Operational Risk Type 3", 
       x = "Loss amount (USD)", y = "Frequency") +
  theme_bw()
```
```{r fig.align="center", fig.width=6, fig.height=4}
# Boxplot of distribution of Operational Risk Losses type 3
ggplot(data = or_type3_cleaned, mapping = aes(x = Loss)) +
  geom_boxplot(fill = "green", 
               color = "black", alpha = 0.7) +
  labs(title = "Boxplot of Operational Risk Type 3", 
       x = "Loss amount (USD)") +
  theme_bw()
```
**Findings:** The histogram and boxplot suggest the absence of significant outliers, as further confirmed by the minimal difference between the mean and the median.

```{r}
# Extracting 'Year' and 'Month' from the 'Date' column
or_type3_cleaned$Year <- year(or_type3_cleaned$Date)
or_type3_cleaned$Month <- month(or_type3_cleaned$Date)

# Grouping by 'Year' and 'Month', summing the 'Loss' column
or_loss_type3_monthly <- or_type3_cleaned %>%
  group_by(Year, Month) %>%
  summarise(Loss_3 = sum(Loss, na.rm = TRUE), .groups = "drop")
```

```{r}
# Printing the first 5 rows
head(or_loss_type3_monthly)

# Printing the last 5 rows
tail(or_loss_type3_monthly)

str(or_loss_type3_monthly)
```
```{r}
# Creating a 'Month_Group' column based on the specified month intervals 
# (3, 6, 9, 12 months)
or_loss_type3_monthly$Month_Group <- case_when(
  or_loss_type3_monthly$Month %in% c(1, 2, 3) ~ "Q1",
  or_loss_type3_monthly$Month %in% c(4, 5, 6) ~ "Q2",
  or_loss_type3_monthly$Month %in% c(7, 8, 9) ~ "Q3",
  or_loss_type3_monthly$Month %in% c(10, 11, 12) ~ "Q4",
  TRUE ~ "Other"
)

# Grouping by 'Year' and 'Month_Group', summing the 'Loss_1' column
grouped_by_month_type3 <- or_loss_type3_monthly %>%
  group_by(Year, Month_Group) %>%
  summarise(Total_Loss_3 = sum(Loss_3, na.rm = TRUE), .groups = "drop")
```

```{r}
# Checking the results
head(grouped_by_month_type3)
tail(grouped_by_month_type3)
```
```{r}
# Creating a 'Year-Quarter' column in the "YYYY-QX" format
grouped_by_month_type3$Year_Quarter <- paste0(grouped_by_month_type3$Year, 
                                              "-Q", gsub("Q", "", 
                                                         grouped_by_month_type3$Month_Group))

# Checking the results
head(grouped_by_month_type3)

```
```{r}
# Droping 'Year' and 'Month_Group' columns and reordering 
# the remaining columns
or_loss_type3_quarterly <- grouped_by_month_type3 %>% 
  dplyr::select(Year_Quarter, Total_Loss_3)
```

```{r}
# Checking data frame
head(or_loss_type3_quarterly)
```

#### Operational Risk Type 4

```{r}
# Downloading necessary files
# Operational losses type 4
or_type4 <- read_excel("C:\\Users\\user\\Documents\\Imir\\My Data Analysis Projects\\Data\\file4.xlsx")
head(or_type4)
tail(or_type4)
```
#### Exploratory Data Analysis of Operational Risk Type 4

```{r}
# Checking for missing values
cat("\nMissing values per column:\n")
missing_values <- colSums(is.na(or_type4))
print(missing_values)

# Checking for duplicated rows
cat("\nDuplicated rows:\n")
duplicated_rows <- or_type4[duplicated(or_type4), ]
if (nrow(duplicated_rows) > 0) {
  print(duplicated_rows)
} else {
  cat("No duplicated rows found.\n")
}
```
**Findings:** There are no null or duplicated values in Operational Risk Type 4.

```{r}
# Exploratory data analysis
summary(or_type4)
glimpse(or_type4)
str(or_type4)
```
**Findings:** The dataset contains 1,941 observations for Operational Risk Type 4. All columns have appropriate data types. The descriptive statistics are as follows:
Minimum value: USD 201
Mean: USD 969.1
Median: USD 717
Maximum value: USD 6,215

#### Visualization of Operational Risk Type 4

```{r fig.align="center", fig.width=6, fig.height=4}
# Histogram of distribution of Operational Risk Losses type 4
ggplot(data = or_type4, mapping = aes(x = Loss)) +
  geom_histogram(binwidth = 50, fill = "skyblue", 
                 color = "black", alpha = 0.7) +
  labs(title = "Histogram of Operational Risk Type 4", 
       x = "Loss amount (USD)", y = "Frequency") +
  theme_bw()
```
```{r fig.align="center", fig.width=6, fig.height=4}
# Boxplot of distribution of Operational Risk Losses type 4
ggplot(data = or_type4, mapping = aes(x = Loss)) +
  geom_boxplot(fill = "skyblue", color = "black", alpha = 0.7) +
  labs(title = "Boxplot of Operational Risk Type 4", 
       x = "Loss amount (USD)") +
  theme_bw()
```
**Findings:** The histogram and boxplot indicate the presence of outliers, as confirmed by the significant difference between the mean and the median.

#### Data preprocessing for Operational Risk Type 4

```{r}
# Extracting outliers from dataframe
Quartile_1 <- quantile(or_type4$Loss, 0.25) 
Quartile_3 <- quantile(or_type4$Loss, 0.75) 
IQR <- Quartile_3 - Quartile_1                
lower_bound <- Quartile_1 - 1.5 * IQR         
upper_bound <- Quartile_3 + 1.5 * IQR     

# Identifying outliers
outliers_loss_4 <- or_type4$Loss[or_type4$Loss < lower_bound | or_type4$Loss > upper_bound]

# Print the outliers
print("Outliers (IQR method):")
print(outliers_loss_4)
```
```{r}
# Filtering the dataset to exclude outliers
or_type4_cleaned <- or_type4[or_type4$Loss >= lower_bound & 
                               or_type4$Loss <= upper_bound, ]

# Print the cleaned dataset
print("Dataset after removing outliers:")
head(or_type4_cleaned)
str(or_type4_cleaned)
```

```{r}
# Exploratory data analysis
str(or_type4_cleaned)
summary(or_type4_cleaned)
```
**Findings:** The dataset contains 1,828 observations for Operational Risk Type 4. All columns have appropriate data types. The descriptive statistics are as follows:
Minimum value: USD 201
Mean: USD 829.5
Median: USD 681
Maximum value: USD 1,133.5
The data has been cleaned to remove outliers.

#### Visualization of Operational Risk Type 4 after cleaning from outliers

```{r fig.align="center", fig.width=6, fig.height=4}
# Histogram of distribution of Operational Risk Losses type 4
ggplot(data = or_type4_cleaned, mapping = aes(x = Loss)) +
  geom_histogram(binwidth = 50, fill = "skyblue", 
                 color = "black", alpha = 0.7) +
  labs(title = "Histogram of Operational Risk Type 4 after cleaning from outliers", 
       x = "Loss amount (USD)", y = "Frequency") +
  theme_bw()
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Boxplot of distribution of Operational Risk Losses type 4
ggplot(data = or_type4_cleaned, mapping = aes(x = Loss)) +
  geom_boxplot(fill = "skyblue", color = "black", alpha = 0.7) +
  labs(title = "Boxplot of Operational Risk Type 4 after cleaning from outliers", 
       x = "Loss amount (USD)") +
  theme_bw()
```
**Findings:** The histogram and boxplot suggest the absence of significant outliers, as further supported by the minimal difference between the mean and the median.

```{r}
# Extracting 'Year' and 'Month' from the 'Date' column
or_type4_cleaned$Year <- year(or_type4_cleaned$Date)
or_type4_cleaned$Month <- month(or_type4_cleaned$Date)

# Grouping by 'Year' and 'Month', summing the 'Loss' column
or_loss_type4_monthly <- or_type4_cleaned %>%
  group_by(Year, Month) %>%
  summarise(Loss_4 = sum(Loss, na.rm = TRUE), .groups = "drop")
```

```{r}
# Printing the first 5 rows
head(or_loss_type4_monthly)

# Printing the last 5 rows
tail(or_loss_type4_monthly)

str(or_loss_type4_monthly)
```

```{r}
# Creating a 'Month_Group' column based on the specified month intervals
# (3, 6, 9, 12 months)
or_loss_type4_monthly$Month_Group <- case_when(
  or_loss_type4_monthly$Month %in% c(1, 2, 3) ~ "Q1",
  or_loss_type4_monthly$Month %in% c(4, 5, 6) ~ "Q2",
  or_loss_type4_monthly$Month %in% c(7, 8, 9) ~ "Q3",
  or_loss_type4_monthly$Month %in% c(10, 11, 12) ~ "Q4",
  TRUE ~ "Other"
)

# Grouping by 'Year' and 'Month_Group', summing the 'Loss_1' column
grouped_by_month_type4 <- or_loss_type4_monthly %>%
  group_by(Year, Month_Group) %>%
  summarise(Total_Loss_4 = sum(Loss_4, na.rm = TRUE), .groups = "drop")
```

```{r}
# Checking the results
head(grouped_by_month_type4)
tail(grouped_by_month_type4)
```

```{r}
# Creating a 'Year-Quarter' column in the "YYYY-QX" format
grouped_by_month_type4$Year_Quarter <- paste0(grouped_by_month_type4$Year, 
                                              "-Q", gsub("Q", "", 
                                                         grouped_by_month_type4$Month_Group))

# Checking the results
head(grouped_by_month_type4)

```
```{r}
# Droping 'Year' and 'Month_Group' columns and reordering the remaining columns
or_loss_type4_quarterly <- grouped_by_month_type4 %>% 
  dplyr::select(Year_Quarter, Total_Loss_4)
```

```{r}
# Checking data frame
head(or_loss_type4_quarterly)
```

```{r}
# Filtering data for creation of combined data frame of Operational Risk Losses
or_type2_df <- or_loss_type2_quarterly %>% 
  dplyr:: select(Total_Loss_2)
head(or_type2_df)

or_type3_df <- or_loss_type3_quarterly %>% 
  dplyr:: select(Total_Loss_3)
head(or_type3_df)

or_type4_df <- or_loss_type4_quarterly %>% 
  dplyr:: select(Total_Loss_4)
head(or_type4_df)

```
```{r}
# Creating combined data frame of Operational Risk Losses
or_losses_total <- cbind(or_loss_type1_quarterly, or_type2_df, 
                         or_type3_df, or_type4_df)
or_losses_total$Total_or_losses <- or_losses_total$Total_Loss_1 + 
  or_losses_total$Total_Loss_2 + or_losses_total$Total_Loss_3 + 
  or_losses_total$Total_Loss_4
or_losses_total <- as.data.frame(or_losses_total)
head(or_losses_total)
tail(or_losses_total)
str(or_losses_total)


```
#### Visualization of total Operational Risk Losses

```{r fig.align="center", fig.width=6, fig.height=4}
# Histogram of total Operational Risk Losses
ggplot(data = or_losses_total, aes(x = Total_or_losses)) +
  geom_histogram(binwidth = 15000, 
                 fill = "yellow", color = "black", alpha = 0.7, aes(y = ..density..)) +
    labs(title = "Distribution of Total Operational Risk Losses", 
       x = "Operational loss (amount) in USD", y = "Frequency") +
  scale_x_continuous(labels = scales::label_number()) +
  scale_y_continuous(labels = scales::label_number()) +
  theme_minimal()
```
```{r fig.align="center", fig.width=6, fig.height=4}
# Boxplot of total Operational Risk Losses
ggplot(data = or_losses_total, mapping = aes(x = Total_or_losses)) +
  geom_boxplot(fill = "yellow", color = "black", alpha = 0.7) +
  labs(title = "Boxplot of Total Operational Risk Losses", x = "Loss amount (USD)") +
  scale_x_continuous(labels = scales::label_number()) +
  scale_y_continuous(labels = scales::label_number()) +
  theme_bw()
```
**Findings:** The distribution appears to be normally distributed, with no gaps in the distribution of the total amounts of Operational Risk Losses.



## Analysis of Independent (Macroeconomic) Variables

### Macroeconomic dataset from "AFR" R package

```{r}
# Downloading macroeconomic dataset from "AFR" package
head(macroKZ)
tail(macroKZ)
str(macroKZ)
```
**Findings:** The dataset is a time-series dataset consisting of 57 rows and 60 columns of macroeconomic data for Kazakhstan, covering the period from Q1-2010 to Q1-2024. All variables are expressed in quarters.

According to the project description of the "AFR" package (https://CRAN.R-project.org/package=AFR), the dataset includes the following data (50 macroeconomic and 10 financial parameters) for the 2010-2024 period:

real_gdp: Real GDP
GDD_Agr_R: Real gross value added – Agriculture
GDD_Min_R: Real gross value added – Mining
GDD_Man_R: Real gross value added – Manufacturing
GDD_Elc_R: Real gross value added – Electricity
GDD_Con_R: Real gross value added – Construction
GDD_Trd_R: Real gross value added – Trade
GDD_Trn_R: Real gross value added – Transportation
GDD_Inf_R: Real gross value added – Information
GDD_Est_R: Real gross value added – Real Estate
GDD_R: Real gross value added
GDP_DEF: GDP deflator
Rincpop_q: Real population average monthly income
Rexppop_q: Real population average monthly expenses
Rwage_q: Real population average monthly wage
imp: Import
exp: Export
cpi: Inflation
realest_resed_prim: Real price for estate in the primary market
realest_resed_sec: Real price for estate in the secondary market
realest_comm: Real price for commercial estate
index_stock_weighted: Change in stock value for traded companies
ntrade_Agr: Change in stock value for non-traded companies – Agriculture
ntrade_Min: Change in stock value for non-traded companies – Mining
ntrade_Man: Change in stock value for non-traded companies – Manufacturing
ntrade_Elc: Change in stock value for non-traded companies – Electricity
ntrade_Con: Change in stock value for non-traded companies – Construction
ntrade_Trd: Change in stock value for non-traded companies – Trade
ntrade_Trn: Change in stock value for non-traded companies – Transportation
ntrade_Inf: Change in stock value for non-traded companies – Information
fed_fund_rate: Federal Funds Rate
govsec_rate_kzt_3m: Return on government securities in KZT, 3 months
govsec_rate_kzt_1y: Return on government securities in KZT, 1 year
govsec_rate_kzt_7y: Return on government securities in KZT, 7 years
govsec_rate_kzt_10y: Return on government securities in KZT, 10 years
tonia_rate: TONIA
rate_kzt_mort_0y_1y: Weighted average mortgage lending rate for new loans, less than a year
rate_kzt_mort_1y_iy: Weighted average mortgage lending rate for new loans, more than a year
rate_kzt_corp_0y_1y: Weighted average mortgage lending rate for new loans to non-financial organizations in KZT, less than a year
rate_usd_corp_0y_1y: Weighted average mortgage lending rate for new loans to non-financial organizations in USD, less than a year
rate_kzt_corp_1y_iy: Weighted average mortgage lending rate for new loans to non-financial organizations in KZT, more than a year
rate_usd_corp_1y_iy: Weighted average mortgage lending rate for new loans to non-financial organizations in USD, more than a year
rate_kzt_indv_0y_1y: Weighted average mortgage lending rate for consumer loans in KZT, less than a year
rate_kzt_indv_1y_iy: Weighted average mortgage lending rate for consumer loans in KZT, more than a year
usdkzt: USD/KZT exchange rate
eurkzt: EUR/KZT exchange rate
rurkzt: RUB/KZT exchange rate
poil: Price for Brent crude oil
realest_resed_prim_rus: Real price for estate in the primary market in Russia
realest_resed_sec_rus: Real price for estate in the secondary market in Russia
cred_portfolio: Credit portfolio
coef_k1: K1 prudential coefficient
coef_k3: K3 prudential coefficient
provisions: Provisions
percent_margin: Percent margin
com_inc: Commissionary income
com_exp: Commissionary expenses
oper_inc: Operational income
oth_inc: Other income
DR: Default rate.


#### Data preprocessing

```{r}
# Converting macroeconomic dataset to a data frame
macrokz_df <- as.data.frame(macroKZ)
str(macrokz_df)
```
```{r}
# Checking for missing values
cat("\nMissing values per column:\n")
missing_values <- colSums(is.na(macrokz_df))
print(missing_values)

# Checking for duplicated rows
cat("\nDuplicated rows:\n")
duplicated_rows <- macrokz_df[duplicated(macrokz_df), ]
if (nrow(duplicated_rows) > 0) {
  print(duplicated_rows)
} else {
  cat("No duplicated rows found.\n")
}
```
**Findings:** There are no missing or duplicated values in the macroeconomic data frame.

```{r}
# Adding the time period as a new column to macroeconomic data frame
# Generating quarterly time periods from Q1 2010 to Q1 2024
time_period <- seq(from = as.Date("2010-04-01"), 
                   to = as.Date("2024-04-01"), 
                   by = "quarter")
macrokz_df$time_period <- time_period
str(macrokz_df)
```
**Findings:** The data frame contains irrelevant macroeconomic variables that should be excluded prior to modeling.


#### Data preprocessing

```{r}
# Filtering the data frame and excluding irrelevant variables
macro_df_filtered <- macrokz_df %>% 
  dplyr:: select(-imp, -exp, -GDP_DEF, -realest_resed_prim, -realest_resed_sec, 
         -realest_comm, -index_stock_weighted, -ntrade_Agr, -ntrade_Min, 
         -ntrade_Man, -ntrade_Elc, -ntrade_Con, -ntrade_Trd, -ntrade_Trn, 
         -ntrade_Inf, -fed_fund_rate, -govsec_rate_kzt_3m, govsec_rate_kzt_1y, 
         -govsec_rate_kzt_7y, -govsec_rate_kzt_10y, -tonia_rate, 
         -rate_kzt_mort_0y_1y, -rate_kzt_mort_1y_iy, -rate_kzt_corp_0y_1y, 
         -rate_usd_corp_0y_1y, - rate_kzt_corp_1y_iy, -rate_usd_corp_1y_iy, 
         -rate_kzt_indv_0y_1y, -rate_kzt_indv_1y_iy, -realest_resed_prim_rus, 
         -realest_resed_sec_rus, -cred_portfolio, -coef_k1, -coef_k3, 
         -provisions, -percent_margin, -com_inc, -com_exp, -oper_inc, -oth_inc, -DR)
head(macro_df_filtered)
```

#### Variables Transformation

The macroeconomic variables are reported quarterly and exhibit both increasing and decreasing trends throughout the year. These variables should be transformed and expressed in annual values for consistency and improved modeling.

```{r}
# Transformation of Real GDP variable
# Calculating yearly GDP sum (sum of every 4 quarters)
macro_df_filtered$Yearly_GDP_Sum <- c(
  sapply(1:(nrow(macro_df_filtered) - 3), 
         function(i) sum(macro_df_filtered$real_gdp[i:(i + 3)])), 
  rep(NA, 3) 
)

# Calculating growth rate as the percentage of current year's GDP 
# over the previous year's GDP
macro_df_filtered$real_gdp_y <- c(rep(NA, 4), 
                                  sapply(5:nrow(macro_df_filtered), 
                                         function(i) {
  previous_year_sum <- sum(macro_df_filtered$real_gdp[(i - 4):(i - 1)]) 
  current_year_sum <- sum(macro_df_filtered$real_gdp[(i):(i + 3)])      
  growth_rate <- (current_year_sum / previous_year_sum - 1) * 100
  return(round(growth_rate, 3))  
}))
```

```{r}
# Transformation of Real gross value added Agriculture variable
# Calculating yearly Real gross value added 
# Agriculture sum (sum of every 4 quarters)
macro_df_filtered$Yearly_GDD_Agr_R_Sum <- c(
  sapply(1:(nrow(macro_df_filtered) - 3), 
         function(i) sum(macro_df_filtered$GDD_Agr_R[i:(i + 3)])), 
  rep(NA, 3)  
)

# Calculating growth rate as the percentage of current year's 
# Real gross value added Agriculture over the previous year's 
# Real gross value added Agriculture
macro_df_filtered$GDD_Agr_R_y <- c(rep(NA, 4), 
                                   sapply(5:nrow(macro_df_filtered), 
                                          function(i) {
  previous_year_sum <- sum(macro_df_filtered$GDD_Agr_R[(i - 4):(i - 1)]) 
  current_year_sum <- sum(macro_df_filtered$GDD_Agr_R[(i):(i + 3)])      
  growth_rate <- (current_year_sum / previous_year_sum - 1) * 100
  return(round(growth_rate, 3))  
}))
```

```{r}
# Transformation of Real gross value added Mining variable
# Calculating yearly Real gross value added Mining 
# sum (sum of every 4 quarters)
macro_df_filtered$Yearly_GDD_Min_R_Sum <- c(
  sapply(1:(nrow(macro_df_filtered) - 3), 
         function(i) sum(macro_df_filtered$GDD_Min_R[i:(i + 3)])), 
  rep(NA, 3)
)

# Calculate growth rate as the percentage of current year's 
# Real gross value added Mining over the previous year's 
# Real gross value added Mining
macro_df_filtered$GDD_Min_R_y <- c(rep(NA, 4), 
                                   sapply(5:nrow(macro_df_filtered), 
                                          function(i) {
  previous_year_sum <- sum(macro_df_filtered$GDD_Min_R[(i - 4):(i - 1)]) 
  current_year_sum <- sum(macro_df_filtered$GDD_Min_R[(i):(i + 3)])      
  growth_rate <- (current_year_sum / previous_year_sum - 1) * 100
  return(round(growth_rate, 3))  
}))
```

```{r}
# Transformation of Real gross value added Manufacture variable
# Calculating yearly Real gross value added Manufacture 
# sum (sum of every 4 quarters)
macro_df_filtered$Yearly_GDD_Man_R_Sum <- c(
  sapply(1:(nrow(macro_df_filtered) - 3), 
         function(i) sum(macro_df_filtered$GDD_Man_R[i:(i + 3)])), 
  rep(NA, 3)  
)

# Calculating growth rate as the percentage of current year's 
# Real gross value added Manufacture over the previous year's 
# Real gross value added Manufacture
macro_df_filtered$GDD_Man_R_y <- c(rep(NA, 4), 
                                   sapply(5:nrow(macro_df_filtered), 
                                          function(i) {
  previous_year_sum <- sum(macro_df_filtered$GDD_Man_R[(i - 4):(i - 1)]) 
  current_year_sum <- sum(macro_df_filtered$GDD_Man_R[(i):(i + 3)])      
  growth_rate <- (current_year_sum / previous_year_sum - 1) * 100
  return(round(growth_rate, 3)) 
}))
```

```{r}
# Transformation of Real gross value added Electricity variable
# Calculating Real gross value added Electricity 
# sum (sum of every 4 quarters)
macro_df_filtered$Yearly_GDD_Elc_R_Sum <- c(
  sapply(1:(nrow(macro_df_filtered) - 3), 
         function(i) sum(macro_df_filtered$GDD_Elc_R[i:(i + 3)])), 
  rep(NA, 3) 
)

# Calculating growth rate as the percentage of current year's
# Real gross value added Electricity over the previous year's
# Real gross value added Electricity
macro_df_filtered$GDD_Elc_R_y <- c(rep(NA, 4), 
                                   sapply(5:nrow(macro_df_filtered), 
                                          function(i) {
  previous_year_sum <- sum(macro_df_filtered$GDD_Elc_R[(i - 4):(i - 1)])
  current_year_sum <- sum(macro_df_filtered$GDD_Elc_R[(i):(i + 3)])    
  growth_rate <- (current_year_sum / previous_year_sum - 1) * 100
  return(round(growth_rate, 3)) 
}))
```

```{r}
# Transformation of Real gross value added Construction variable
# Calculating yearly Real gross value added Construction 
# sum (sum of every 4 quarters)
macro_df_filtered$Yearly_GDD_Con_R_Sum <- c(
  sapply(1:(nrow(macro_df_filtered) - 3), 
         function(i) sum(macro_df_filtered$GDD_Con_R[i:(i + 3)])), 
  rep(NA, 3)  # To match length with original data
)

# Calculating growth rate as the percentage of current year's 
# Real gross value added Construction over the previous year's 
# Real gross value added Construction
macro_df_filtered$GDD_Con_R_y <- c(rep(NA, 4), 
                                   sapply(5:nrow(macro_df_filtered), 
                                          function(i) {
  previous_year_sum <- sum(macro_df_filtered$GDD_Con_R[(i - 4):(i - 1)]) 
  current_year_sum <- sum(macro_df_filtered$GDD_Con_R[(i):(i + 3)])    
  growth_rate <- (current_year_sum / previous_year_sum - 1) * 100
  return(round(growth_rate, 3)) 
}))
```

```{r}
# Transformation of Real gross value added Trade variable
# Calculating yearly Real gross value added Trade 
# sum (sum of every 4 quarters)
macro_df_filtered$Yearly_GDD_Trd_R_Sum <- c(
  sapply(1:(nrow(macro_df_filtered) - 3), 
         function(i) sum(macro_df_filtered$GDD_Trd_R[i:(i + 3)])), 
  rep(NA, 3)
)

# Calculating growth rate as the percentage of current year's 
# Real gross value added Trade over the previous year's 
# Real gross value added Trade
macro_df_filtered$GDD_Trd_R_y <- c(rep(NA, 4), 
                                   sapply(5:nrow(macro_df_filtered), 
                                          function(i) {
  previous_year_sum <- sum(macro_df_filtered$GDD_Trd_R[(i - 4):(i - 1)])
  current_year_sum <- sum(macro_df_filtered$GDD_Trd_R[(i):(i + 3)])    
  growth_rate <- (current_year_sum / previous_year_sum - 1) * 100
  return(round(growth_rate, 3))  
}))
```

```{r}
# Transformation of Real gross value added Transportation variable
# Calculating yearly Real gross value added Transportation 
# sum (sum of every 4 quarters)
macro_df_filtered$Yearly_GDD_Trn_R_Sum <- c(
  sapply(1:(nrow(macro_df_filtered) - 3), 
         function(i) sum(macro_df_filtered$GDD_Trn_R[i:(i + 3)])), 
  rep(NA, 3)  
)

# Calculating growth rate as the percentage of current year's 
# Real gross value added Transportation over the previous year's 
# Real gross value added Transportation
macro_df_filtered$GDD_Trn_R_y <- c(rep(NA, 4), 
                                   sapply(5:nrow(macro_df_filtered), 
                                          function(i) {
  previous_year_sum <- sum(macro_df_filtered$GDD_Trn_R[(i - 4):(i - 1)]) 
  current_year_sum <- sum(macro_df_filtered$GDD_Trn_R[(i):(i + 3)])     
  growth_rate <- (current_year_sum / previous_year_sum - 1) * 100
  return(round(growth_rate, 3)) 
}))
```

```{r}
# Transformation of Real gross value added Information variable
# Calculating yearly Real gross value added Information
# sum (sum of every 4 quarters)
macro_df_filtered$Yearly_GDD_Inf_R_Sum <- c(
  sapply(1:(nrow(macro_df_filtered) - 3), 
         function(i) sum(macro_df_filtered$GDD_Inf_R[i:(i + 3)])), 
  rep(NA, 3)  
)

# Calculating growth rate as the percentage of current year's 
# Real gross value added Information over the previous year's 
# Real gross value added Information
macro_df_filtered$GDD_Inf_R_y <- c(rep(NA, 4), 
                                   sapply(5:nrow(macro_df_filtered), 
                                          function(i) {
  previous_year_sum <- sum(macro_df_filtered$GDD_Inf_R[(i - 4):(i - 1)]) 
  current_year_sum <- sum(macro_df_filtered$GDD_Inf_R[(i):(i + 3)])      
  growth_rate <- (current_year_sum / previous_year_sum - 1) * 100
  return(round(growth_rate, 3))  
}))
```

```{r}
# Transformation of Real gross value added for Real estate variable
# Calculating yearly Real gross value added for Real estate
# sum (sum of every 4 quarters)
macro_df_filtered$Yearly_GDD_Est_R_Sum <- c(
  sapply(1:(nrow(macro_df_filtered) - 3), 
         function(i) sum(macro_df_filtered$GDD_Est_R[i:(i + 3)])), 
  rep(NA, 3)
)

# Calculating growth rate as the percentage of current year's 
# Real gross value added for Real estate over the previous year's 
# Real gross value added for Real estate
macro_df_filtered$GDD_Est_R_y <- c(rep(NA, 4), 
                                   sapply(5:nrow(macro_df_filtered), 
                                          function(i) {
  previous_year_sum <- sum(macro_df_filtered$GDD_Est_R[(i - 4):(i - 1)]) 
  current_year_sum <- sum(macro_df_filtered$GDD_Est_R[(i):(i + 3)])      
  growth_rate <- (current_year_sum / previous_year_sum - 1) * 100
  return(round(growth_rate, 3))  # Round to 3 decimal places
}))
```

```{r}
# Transformation of Real gross value added variable
# Calculating yearly Real gross value added 
# sum (sum of every 4 quarters)
macro_df_filtered$Yearly_GDD_R_Sum <- c(
  sapply(1:(nrow(macro_df_filtered) - 3), 
         function(i) sum(macro_df_filtered$GDD_R[i:(i + 3)])), 
  rep(NA, 3) 
)

# Calculating growth rate as the percentage of current year's 
# Real gross value added over the previous year's 
# Real gross value added
macro_df_filtered$GDD_R_y <- c(rep(NA, 4), 
                               sapply(5:nrow(macro_df_filtered), 
                                      function(i) {
  previous_year_sum <- sum(macro_df_filtered$GDD_R[(i - 4):(i - 1)])
  current_year_sum <- sum(macro_df_filtered$GDD_R[(i):(i + 3)]) 
  growth_rate <- (current_year_sum / previous_year_sum - 1) * 100
  return(round(growth_rate, 3)) 
}))
```

```{r}
# Transformation of Real population average monthly income variable
# Calculating yearly Real population average 
# monthly income sum (sum of every 4 quarters)
macro_df_filtered$Yearly_Rincpop_q_Sum <- c(
  sapply(1:(nrow(macro_df_filtered) - 3), 
         function(i) sum(macro_df_filtered$Rincpop_q[i:(i + 3)])), 
  rep(NA, 3)
)

# Calculating growth rate as the percentage of current year's 
# Real population average monthly income over the previous year's 
# Real population average monthly income
macro_df_filtered$Rincpop_q_y <- c(rep(NA, 4), 
                                   sapply(5:nrow(macro_df_filtered), 
                                          function(i) {
  previous_year_sum <- sum(macro_df_filtered$Rincpop_q[(i - 4):(i - 1)])
  current_year_sum <- sum(macro_df_filtered$Rincpop_q[(i):(i + 3)])    
  growth_rate <- (current_year_sum / previous_year_sum - 1) * 100
  return(round(growth_rate, 3))  
}))
```

```{r}
# Transformation of Real population average monthly expenses variable
# Calculating yearly Real population average monthly expenses 
# sum (sum of every 4 quarters)
macro_df_filtered$Yearly_Rexppop_q_Sum <- c(
  sapply(1:(nrow(macro_df_filtered) - 3), 
         function(i) sum(macro_df_filtered$Rexppop_q[i:(i + 3)])), 
  rep(NA, 3)  
)

# Calculating growth rate as the percentage of current year's 
# Real population average monthly expenses over the previous year's 
# Real population average monthly expenses
macro_df_filtered$Rexppop_q_y <- c(rep(NA, 4), 
                                   sapply(5:nrow(macro_df_filtered), 
                                          function(i) {
  previous_year_sum <- sum(macro_df_filtered$Rexppop_q[(i - 4):(i - 1)]) 
  current_year_sum <- sum(macro_df_filtered$Rexppop_q[(i):(i + 3)])    
  growth_rate <- (current_year_sum / previous_year_sum - 1) * 100
  return(round(growth_rate, 3))  
}))
```

```{r}
# Transformation of Real population average monthly wage variable
# Calculating yearly Real population average monthly wage 
# sum (sum of every 4 quarters)
macro_df_filtered$Yearly_Rwage_q_Sum <- c(
  sapply(1:(nrow(macro_df_filtered) - 3), 
         function(i) sum(macro_df_filtered$Rwage_q[i:(i + 3)])), 
  rep(NA, 3)  
)

# Calculating growth rate as the percentage of current year's 
# Real population average monthly wage over the previous year's 
# Real population average monthly wage
macro_df_filtered$Rwage_q_y <- c(rep(NA, 4), 
                                 sapply(5:nrow(macro_df_filtered), 
                                        function(i) {
  previous_year_sum <- sum(macro_df_filtered$Rwage_q[(i - 4):(i - 1)]) 
  current_year_sum <- sum(macro_df_filtered$Rwage_q[(i):(i + 3)])     
  growth_rate <- (current_year_sum / previous_year_sum - 1) * 100
  return(round(growth_rate, 3))  
}))
```

```{r}
# Transformation of Inflation variable
# Calculating quarterly growth of Inflation
macro_df_filtered$cpi_q <- c(NA, diff(macro_df_filtered$cpi) / 
                               head(macro_df_filtered$cpi, -1) * 100)

# Calculating yearly growth of Inflation
macro_df_filtered$cpi_y <- c(rep(NA, 4), 
                             sapply(5:nrow(macro_df_filtered), 
                                    function(i) {
  yearly_growth <- (macro_df_filtered$cpi[i] - macro_df_filtered$cpi[i - 4]) / 
    macro_df_filtered$cpi[i - 4] * 100
  return(round(yearly_growth, 2))  # Round to 2 decimal places
}))
```

```{r}
# Checking the macroeconomic variables data frame
str(macro_df_filtered)
```
**Findings:** New macroeconomic variables have been added to the data frame as a result of transforming the quarterly data into yearly values, thereby eliminating the increasing and decreasing trends.

```{r}
# Filtering macroeconomic data frame to exclude not transformed variables
macro_df_cleaned <- macro_df_filtered %>% 
  dplyr:: select(-real_gdp, -GDD_Agr_R, -GDD_Min_R, 
                 -GDD_Man_R, -GDD_Elc_R, 
                 -GDD_Con_R, -GDD_Trd_R, -GDD_Trn_R, 
                 -GDD_Inf_R, -GDD_Est_R, -GDD_R, 
                 -Rincpop_q, -Rexppop_q, -Rwage_q, 
                 -govsec_rate_kzt_1y, -Yearly_GDP_Sum,
                 -Yearly_GDD_Agr_R_Sum, -Yearly_GDD_Min_R_Sum, 
                 -Yearly_GDD_Man_R_Sum, -Yearly_GDD_Elc_R_Sum,
                 -Yearly_GDD_Con_R_Sum, -Yearly_GDD_Trd_R_Sum, 
                 -Yearly_GDD_Trn_R_Sum, -Yearly_GDD_Inf_R_Sum,
                 -Yearly_GDD_Est_R_Sum, -Yearly_GDD_R_Sum, 
                 -Yearly_Rincpop_q_Sum, -Yearly_Rexppop_q_Sum, 
                 -Yearly_Rwage_q_Sum)
```

```{r}
# Checking cleaned data frame
str(macro_df_cleaned)
```
**Findings:** There are 21 transformed variables in the macroeconomic data frame, and 1,330 possible combinations of macroeconomic variables can be generated from these 21 transformed variables.

## Creating the Final Data Frame for Modeling

## Processing the Final Data Frame for Modeling

#### Processing the Total Operational Risk Losses Data Frame

```{r}
# Checking Total Operational Risk Losses data frame
str(or_losses_total)
```
**Findings:** The data in the Total Operational Risk Losses data frame covers the period from Q1-2007 to Q4-2016, while the available macroeconomic variables span from Q1-2010 to Q1-2024. To align both datasets, both the Total Operational Risk Losses data frame and the macroeconomic variables data frame will be truncated to the period from Q1-2011 to Q4-2016.

```{r}
# Converting 'Year_Quarter' to a date for comparison
or_losses_total$Year_Quarter <- as.character(or_losses_total$Year_Quarter)

# Filtering the data from 2016 Q1 onwards
or_losses_filtered <- or_losses_total %>%
  filter(Year_Quarter >= "2011-Q1")
```

```{r}
# Checking the filtered data
head(or_losses_filtered)
tail(or_losses_filtered)
```
```{r}
# Converting Quarter to Date (assuming the first day of each quarter)
# Extracting Year and Quarter from Year_Quarter
or_losses_filtered$Year <- substr(or_losses_filtered$Year_Quarter, 1, 4)
or_losses_filtered$Quarter <- substr(or_losses_filtered$Year_Quarter, 6, 7)
or_losses_filtered$Date_2 <- as.Date(paste0(or_losses_filtered$Year, "-", 
                                            case_when(
                                              or_losses_filtered$Quarter == "Q1" ~ "01",
                                              or_losses_filtered$Quarter == "Q2" ~ "04",
                                              or_losses_filtered$Quarter == "Q3" ~ "07",
                                              or_losses_filtered$Quarter == "Q4" ~ "10"
                                            ), "-01"), format="%Y-%m-%d")

# Checking the result
head(or_losses_filtered)
```
```{r}
# Defining the KZT/USD exchange rates for each year
usd_kzt_exchange_rates <- c(
  `2016` = 342.16,
  `2015` = 221.73,
  `2014` = 179.19,
  `2013` = 152.13,
  `2012` = 149.11,
  `2011` = 146.62,
  `2010` = 147.35
)

# Defining function to convert Operational Risk Losses to KZT based on the year
convert_to_kzt <- function(year, value) {
  exchange_rate <- usd_kzt_exchange_rates[as.character(year)]
  if (!is.null(exchange_rate)) {
    return(value * exchange_rate)
  } else {
    return(NA)
  }
}

# Appling the conversion for each relevant column
or_losses_filtered$Total_loss_1_KZT <- mapply(convert_to_kzt, 
                                              as.numeric(format(or_losses_filtered$Date_2, 
                                                                "%Y")), 
                                              or_losses_filtered$Total_Loss_1)

or_losses_filtered$Total_loss_2_KZT <- mapply(convert_to_kzt, 
                                              as.numeric(format(or_losses_filtered$Date_2, 
                                                                "%Y")), 
                                              or_losses_filtered$Total_Loss_2)

or_losses_filtered$Total_loss_3_KZT <- mapply(convert_to_kzt, 
                                              as.numeric(format(or_losses_filtered$Date_2, 
                                                                "%Y")), 
                                              or_losses_filtered$Total_Loss_3)

or_losses_filtered$Total_loss_4_KZT <- mapply(convert_to_kzt, 
                                              as.numeric(format(or_losses_filtered$Date_2, 
                                                                "%Y")), 
                                              or_losses_filtered$Total_Loss_4)

or_losses_filtered$Total_or_losses_KZT <- mapply(convert_to_kzt, 
                                                 as.numeric(format(or_losses_filtered$Date_2, 
                                                                   "%Y")), 
                                                 or_losses_filtered$Total_or_losses)

```

```{r}
# Checking the first few rows of the updated data frame
head(or_losses_filtered)
tail(or_losses_filtered)
```
#### Processing Banking statistics data frame

```{r}
# Converting the 'Date' column to Date format
banking_stats_filtered$Date <- as.Date(banking_stats_filtered$Date)

# Defining the date range for filtering
start_date <- as.Date("2011-03-01")
end_date <- as.Date("2016-12-01")

# Filtering the data between the specified range
banking_stats_filtered_filtered <- banking_stats_filtered %>%
  filter(Date >= start_date & Date <= end_date)
```

```{r}
# Checking the first and last few rows of the filtered data
head(banking_stats_filtered_filtered)
tail(banking_stats_filtered_filtered)
```

```{r}
# Creating comdined data frame of banking statistics
bank_x <- cbind(banking_stats_filtered_filtered, or_losses_filtered)
```

```{r}
# Checking combined data frame
str(bank_x)
head(bank_x)
tail(bank_x)
```


```{r fig.align="center", fig.width=6, fig.height=4}
# Creating comparison chart for Total Assets and Total Operational Risk Losses
bank_x$Date <- as.factor(bank_x$Date)

p <- ggplot(bank_x, aes(x = Date)) +
  geom_line(aes(y = Value / 1000000000, color = "Total Assets"), 
            linewidth = 1, group = 1) +
  geom_point(aes(y = Value / 1000000000, color = "Total Assets"), 
             size = 3) +
  geom_line(aes(y = (Total_or_losses_KZT / 1000) * scale_factor, 
                color = "Total Losses"), linewidth = 1, group = 1) +
  geom_point(aes(y = (Total_or_losses_KZT / 1000) * scale_factor, 
                 color = "Total Losses"), size = 3) +
  
  scale_color_manual(values = c("Total Assets" = "blue", 
                                "Total Losses" = "red")) +
  scale_y_continuous(
    name = "Total Assets (Billion KZT)",  
    labels = comma,
    sec.axis = sec_axis(
      ~ . / scale_factor, 
      name = "Total Losses (Thousands KZT)", 
      labels = comma
    )
  ) +
  labs(
    title = "Comparison of Total Assets to Operational Risk Losses",
    x = "Yearly",
    color = ""
  ) +
  theme_minimal() +
  theme(
    axis.title.y.left = element_text(color = "blue"),
    axis.text.y.left = element_text(color = "blue"),
    axis.title.y.right = element_text(color = "red"),
    axis.text.y.right = element_text(color = "red"),
    legend.position = "top",
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

scale_factor <- max(bank_x$Value / 1000000000) / 
  max(bank_x$Total_or_losses_KZT / 1000)

print(p)
```
**Findings:** Despite the rapid fluctuations in Operational Risk Losses, an increasing trend has been observed in the data since 2015. However, it is important to note that the data on Operational Risk Losses is sourced from the open "OpVaR" package for R and is not specific to the Kazakhstan banking system. As such, it does not reflect the actual Operational Risk exposure of Kazakhstan's banks.

#### Data processing

The data for Operational Risk Losses is expressed in KZT millions, while the data for macroeconomic variables is in KZT trillions. If these values are input into the Regression Model without being standardized to comparable units, it will result in incorrect calculations. To address this, the dependent variable will be expressed as the share (portion) of Total Operational Risk Losses relative to the Total Assets of bank "X" for the Linear Regression Model.

```{r}
# Calculation of share (portion) of Total Operational Risk Losses 
# in Total Assets of the bank "X"
bank_x$OR_Loss_in_assets <- bank_x$Total_or_losses_KZT / bank_x$Value
bank_x$OR_Loss_1_in_assets <- bank_x$Total_loss_1_KZT / bank_x$Value
bank_x$OR_Loss_2_in_assets <- bank_x$Total_loss_2_KZT / bank_x$Value
bank_x$OR_Loss_3_in_assets <- bank_x$Total_loss_3_KZT / bank_x$Value
bank_x$OR_Loss_4_in_assets <- bank_x$Total_loss_4_KZT / bank_x$Value
```

```{r}
# Checking data frame
head(bank_x)
```

```{r}
# Checking macroeconomic variables data frame
head(macro_df_cleaned)
tail(macro_df_cleaned)
```
```{r}
# Filtering macroeconomic data for the period 2011-04-01 and 2017-01-01
macro_df_final <- macro_df_cleaned %>%
  filter(time_period >= as.Date("2011-04-01") & 
           time_period <= as.Date("2017-01-01")) %>% 
  dplyr:: select(time_period, everything())
```

```{r}
# Checking macroeconomic variables data frame
head(macro_df_final)
tail(macro_df_final)
```
```{r}
# Creating combined data frame of macroeconomic variables 
# and banking statistics
model_data <- cbind(macro_df_final, bank_x)
str(model_data)
```
```{r}
# Checking for missing values
cat("\nMissing values per column:\n")
missing_values <- colSums(is.na(model_data))
print(missing_values)

# Checking for duplicated rows
cat("\nDuplicated rows:\n")
duplicated_rows <- model_data[duplicated(model_data), ]
if (nrow(duplicated_rows) > 0) {
  print(duplicated_rows)
} else {
  cat("No duplicated rows found.\n")
}
```
**Findings:** There are no missing or duplicated values in the data frame for modeling.

### Interim conclusion
The Dependent and Independent Variables are processed for modelling purposes, have no missing and duplicated values.
All variables have proper data formats. Final data frame are cleaned from irrelevant macroeconomic variables.

# Regression Model

## Model Construction

## Multiple Linear Regression Model Construction

The Multiple Linear Regression Model will be used for stress-testing Operational Risk. The R programming code will automatically select the optimal parameters by iterating through the 1,330 possible combinations of independent variables (regressors). Statistical tests for multicollinearity, stationarity, and statistical significance will be applied to ensure the robustness of the model.

```{r}
# Creating data frame for modelling
final_df <- as.data.frame(model_data)
```

### Multiple Linear Regression Model Fitting

#### Hypothesis Formulation:
Null Hypothesis (H0): The macroeconomic variables are not related to Operational Risk Losses.
Alternative Hypothesis (Ha): The macroeconomic variables are related to Operational Risk Losses.
The alpha level is set to 0.1 (90% confidence level), and the acceptable R² (Coefficient of Determination) threshold is set to 0.35 (35%).

```{r warning=FALSE}
# Function to check stationarity and significance for Model 1
check_stationarity_significance_model_1 <- function(X, y) {
  X <- as.data.frame(cbind(1, X))  
  colnames(X)[1] <- "(Intercept)"  
  model1 <- lm(y ~ ., data = X)  
  p_values <- summary(model1)$coefficients[, 4][-1]  
  adf_test <- adf.test(resid(model1)) 
  return(list(p_values = p_values, adf_test = adf_test))
}

# Function to calculate Variance Inflation Factor (VIF) for Model 1
calculate_vif_model_1 <- function(X, y) {
  
  data <- as.data.frame(cbind(X, y = y))
  vif_data <- vif(lm(y ~ ., data = data))
  return(data.frame(feature = names(vif_data), 
                    VIF = vif_data))
}

# Function to find the best model for Model 1 
# based on feature combinations
find_best_model_model_1 <- function(final_df) {

  excluded_columns <- c("time_period", "Year_Quarter", 
                        "Date", "Date_2", "Value",
                        "Total_Loss_1", "Total_Loss_2", 
                        "Total_Loss_3", "Total_Loss_4",
                        "OR_Loss_in_assets", "Value_billion", 
                        "Total_or_losses",
                        "Total_or_losses_KZT", "Total_loss_1_KZT", 
                        "Total_loss_2_KZT",
                        "Total_loss_3_KZT", "Total_loss_4_KZT", 
                        "OR_Loss_1_in_assets",
                        "OR_Loss_2_in_assets", "OR_Loss_3_in_assets", 
                        "OR_Loss_4_in_assets", "Year", "Quarter")
  X <- final_df[, !colnames(final_df) %in% excluded_columns]
  y <- final_df$OR_Loss_in_assets
  
  best_r2 <- -Inf
  best_model1 <- NULL
  best_features1 <- NULL
  valid_combinations <- 0 
  total_combinations <- choose(ncol(X), 3)
  combination_count <- 0
  
  # Generating combinations of 3 independent variables
  combinations <- combn(names(X), 3, simplify = FALSE)
  
  # Initializing a list to store valid combinations that passed tests
  valid_combinations_list <- list()

  for (i in 1:length(combinations)) {
    combination_count <- combination_count + 1
    selected_features <- X[, combinations[[i]], drop = FALSE] 
    
    # Checking stationarity and significance for Model 1
    test_result <- check_stationarity_significance_model_1(selected_features, 
                                                           y)
    p_values <- test_result$p_values
    adf_test <- test_result$adf_test
    
    # Skipping combinations that don't pass the statistical tests
    if (any(p_values > 0.1) || adf_test$p.value > 0.1) {
      next  # Skip this combination
    }
    
    # Checking VIF for Model 1
    vif_test <- calculate_vif_model_1(selected_features, y)
    if (max(vif_test$VIF) > 10) {
      next  # Skip this combination
    }

    # Fitting the model for Model 1
    selected_features <- as.data.frame(cbind(1, selected_features))  
    colnames(selected_features)[1] <- "(Intercept)"  
    model1 <- lm(y ~ ., data = selected_features)  
    r2 <- summary(model1)$r.squared
    
    # Checking if this model is the best
    if (r2 > best_r2) {
      best_r2 <- r2
      best_model1 <- model1
      best_features1 <- combinations[[i]]
    }
    
    # Adding valid combination to the list
    valid_combinations <- valid_combinations + 1
    valid_combinations_list[[valid_combinations]] <- list(
      combination = combinations[[i]],
      p_values = p_values,
      adf_p_value = adf_test$p.value,
      r2 = r2
    )
  }
  
  # Returning the best model, best features, and valid combinations
  return(list(best_model1 = best_model1, 
              best_features1 = best_features1,
              best_r2 = best_r2,
              valid_combinations_list = valid_combinations_list,
              valid_combinations = valid_combinations,
              total_combinations = total_combinations))
}

# Finding the best model for Model 1
best_result_1 <- find_best_model_model_1(final_df)
best_model_1 <- best_result_1$best_model1
best_features_1 <- best_result_1$best_features1
valid_combinations_list <- best_result_1$valid_combinations_list
valid_combinations <- best_result_1$valid_combinations
total_combinations <- best_result_1$total_combinations

# Printing the results
cat("Total number of combinations:", total_combinations, "\n")
cat("Number of valid combinations that passed the statistical tests:", 
    valid_combinations, "\n")

# Printing each valid combination with its details
cat("Valid combinations that passed the statistical tests:\n")
for (i in 1:length(valid_combinations_list)) {
  cat("Combination", i, ":", paste(valid_combinations_list[[i]]$combination, 
                                   collapse = ", "), "\n")
  cat("p-values: ", paste(valid_combinations_list[[i]]$p_values, 
                          collapse = ", "), "\n")
  cat("ADF test p-value: ", valid_combinations_list[[i]]$adf_p_value, 
      "\n")
  cat("R^2: ", valid_combinations_list[[i]]$r2, "\n\n")
}

# Printing the best model and features
cat("Best independent variables for Model 1:", 
    paste(best_features_1, collapse = ", "), "\n")
cat("R^2 of the best model for Model 1:", best_result_1$best_r2, 
    "\n")
print(summary(best_model_1))

```

A total of 4 combinations passed statistical tests and were selected after iterating through 1,330 generated combinations of macroeconomic variables. These selected combinations are as follows:

Combination 1:
poil (Price for Brent)
real_gdp_y (Real GDP, transformed)
GDD_Elc_R_y (Real Gross Value Added - Electricity, transformed)
R^2: 0.4314054.

Combination 2:
poil (Price for Brent)
GDD_Elc_R_y (Real Gross Value Added - Electricity, transformed)
GDD_R_y (Real Gross Value Added, transformed)
R^2: 0.4305061.

Combination 3:
GDD_Agr_R_y (Real Gross Value Added - Agriculture, transformed)
GDD_Trn_R_y (Real Gross Value Added - Transportation, transformed)
GDD_Est_R_y (Real Gross Value Added - Real Estate, transformed)
R^2: 0.4162206.

Combination 4:
GDD_Trn_R_y (Real Gross Value Added - Transportation, transformed)
GDD_Inf_R_y (Real Gross Value Added - Information, transformed)
Rincpop_q_y (Real Population Average Monthly Income, transformed)
R^2: 0.4426457.

The best Multiple Linear Regression model for predicting the amounts (impact/severity) of Operational Risk Losses includes the following macroeconomic variables with the highest R^2:
GDD_Trn_R_y (Real Gross Value Added - Transportation)
GDD_Inf_R_y (Real Gross Value Added - Information)
Rincpop_q_y (Real Population Average Monthly Income).

The R^2 (Coefficient of Determination) for the best model is 0.44, with an Adjusted R^2 of 0.36. The p-values for the variables are below the alpha level of 0.1, indicating statistical significance.

Therefore, the Null Hypothesis is rejected, and the Alternative Hypothesis is accepted, confirming that the selected macroeconomic variables are significantly related to the frequency (number) of Operational Risk Losses.


#### Checking Modelling Assumptions for Multiple Linear Regression Model

#### Multiple Linear Model 1

```{r}
# Multiple linear regression model construction
mfl_model_or <- lm(OR_Loss_in_assets ~ GDD_Trn_R_y + 
                     GDD_Inf_R_y + Rincpop_q_y, 
                   data = model_data)
summary(mfl_model_or)
```
#### Creating correlation matrix

```{r}
kendall_corr <- model_data %>% 
  dplyr:: select(GDD_Trn_R_y, GDD_Inf_R_y, 
                 Rincpop_q_y, OR_Loss_in_assets)

# Calculating Kendall's correlation matrix
kendall_corr1 <- cor(kendall_corr, method = "kendall", 
                    use = "complete.obs")
print(kendall_corr1)
```
```{r fig.align="center", fig.width=6, fig.height=4}
# Visualization Kendall's correlation matrix by correlation plot
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", 
                          "#77AADD", "#4477AA"))
corrplot(kendall_corr1, method = "color", col = col(200),
         type = "upper", order = "hclust",
         addCoef.col = "black", 
         tl.col = "black", tl.srt = 45,
         
)
```
**Findings:** The analysis of correlation between the independent and dependent variables reveals a moderate negative correlation. This suggests an inverse relationship between the macroeconomic variables (independent variables) and Operational Risk Losses (dependent variable), indicating that as certain macroeconomic indicators increase, the corresponding Operational Risk Losses tend to decrease, and vice versa. This finding will be important for interpreting the model results and understanding the dynamics between macroeconomic factors and Operational Risk Losses.

#### Linearity Assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = model_data, aes(x = GDD_Trn_R_y, y = OR_Loss_in_assets)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "red") +
  labs(title = "Scatterplot of GDD_Trn_R_y vs. OR_Loss_in_assets", 
       x = "GDD_Trn_R_y", y = "OR_Loss_in_assets") +
  theme_minimal()
```
```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = model_data, aes(x = GDD_Inf_R_y, y = OR_Loss_in_assets)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "green") +
  labs(title = "Scatterplot of GDD_Inf_R_y vs. OR_Loss_in_assets", 
       x = "GDD_Inf_R_y", y = "OR_Loss_in_assets") +
  theme_minimal()
```
```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable
# and the dependent variable
ggplot(data = model_data, aes(x = Rincpop_q_y, y = OR_Loss_in_assets)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "blue") +
  labs(title = "Scatterplot of Rincpop_q_y vs. OR_Loss_in_assets", 
       x = "Rincpop_q_y", y = "OR_Loss_in_assets") +
  theme_minimal()
```
**Findings:** It is difficult to confirm the presence of linear relationships between the independent and dependent variables. The linearity assumption assumes that the relationship between predictors (macroeconomic variables) and the response variable (Operational Risk Losses) is linear. If this assumption is violated, the model may fail to capture the true relationship, resulting in biased or inefficient predictions. In the context of Operational Risk forecasting, where the relationships between macroeconomic factors and risk losses are likely complex, ignoring non-linear relationships can lead to inaccurate risk assessments. Stress testing based on linear models in such cases may produce misleading conclusions about the potential impact or severity of Operational Risk Losses, affecting decision-making and risk management strategies.

#### Normality Assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Calculating model residuals
residuals <- resid(mfl_model_or)

# Creating a 1x2 grid of plots (histogram and Q-Q plot)
par(mfrow = c(1, 2), mar = c(5, 4, 4, 2))

# Histogram of residuals with adjusted bins and axis formatting
hist(
  residuals,
  breaks = 5,  # Increase the number of bins
  main = "Histogram of Residuals",
  xlab = "Residual Value",
  col = "lightblue",
  border = "black",
  xaxt = "n"
)

# Customize x-axis to remove scientific notation
axis(1, at = pretty(residuals), labels = format(pretty(residuals), 
                                                scientific = FALSE))

# Q-Q plot of residuals
qqnorm(residuals, main = "Normal Q-Q Plot")
qqline(residuals, col = "red")

# Reset plotting layout to default
par(mfrow = c(1, 1))
```
**Findings:** The histogram of the residuals shows a distribution that does not appear to be normally distributed, with noticeable gaps in the residuals' distribution. This observation confirms that the normality assumption is not met for this model. Additionally, the Q-Q plot does not follow a straight line, further indicating that the normality assumption is violated.
The normality assumption is crucial, particularly for statistical inference, including hypothesis testing and confidence intervals. When the residuals are not normally distributed, the accuracy of p-values and confidence intervals can be compromised. If the normality assumption is violated, the model's ability to reliably predict Operational Risks could be affected, especially in cases where uncertainty (such as constructing prediction intervals) needs to be quantified. While the model may still provide useful predictions, these predictions should be approached with more caution due to the violation of the normality assumption.

#### Constant Variance Assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Calculating fitted values and residuals
fitted_values <- fitted(mfl_model_or)
residuals <- resid(mfl_model_or)

# Creating a scatterplot of fitted values vs residuals
plot(fitted_values, residuals, 
     xlab = "Fitted Values", 
     ylab = "Residuals", 
     main = "Fitted Values vs Residuals", 
     pch = 19, col = "blue")
abline(h = 0, col = "red", lty = 2)
```
**Findings:** The fitted values of variance appear to be similarly distributed, which confirms that the assumption of homoscedasticity (constant variance) is met. This is a positive outcome for the model, as it suggests that the variability in the residuals is consistent across all levels of the fitted values, allowing for more reliable parameter estimates and valid statistical inference.

#### No Multicollinearity Assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Checking for no multicollinearity assumption
columns <- c('GDD_Trn_R_y', 'GDD_Inf_R_y', 
             'Rincpop_q_y', 'OR_Loss_in_assets')

# Creating a pair plot for the selected columns
ggpairs(model_data[, columns])


# Calculating VIF for the model
vif_result <- vif(mfl_model_or)

# Converting the VIF results to a data frame
df_vif <- data.frame(VIF = vif_result)
df_vif
```
**Findings:** The Variance Inflation Factor (VIF) is less than 5, indicating low to moderate multicollinearity, which is within acceptable levels. This suggests that the independent variables in the model are not highly collinear with each other, ensuring that the estimates of the regression coefficients are stable and reliable. As a result, the model's predictions are less likely to be distorted by multicollinearity, and the statistical significance of individual variables can be interpreted more confidently.

#### Multiple Linear Model 2

```{r}
# Multiple linear regression model construction
mfl_model_or2 <- lm(OR_Loss_in_assets ~ poil + real_gdp_y 
                    + GDD_Elc_R_y, data = model_data)
summary(mfl_model_or2)
```
#### Creating correlation matrix

```{r}
kendall_corr2 <- model_data %>% 
  dplyr:: select(poil, real_gdp_y, GDD_Elc_R_y, OR_Loss_in_assets)

# Calculating Kendall's correlation matrix
kendall_corr2 <- cor(kendall_corr2, method = "kendall", 
                    use = "complete.obs")
print(kendall_corr2)
```
```{r fig.align="center", fig.width=6, fig.height=4}
# Visualization Kendall's correlation matrix by correlation plot
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", 
                          "#77AADD", "#4477AA"))
corrplot(kendall_corr2, method = "color", col = col(200),
         type = "upper", order = "hclust",
         addCoef.col = "black", 
         tl.col = "black", tl.srt = 45,
         
)
```
**Findings:** The analysis of correlation between the independent and dependent variables reveals a moderate negative correlation. This suggests an inverse relationship between the macroeconomic variables (independent variables) and Operational Risk Losses (dependent variable). As certain macroeconomic indicators increase, the corresponding Operational Risk Losses tend to decrease, and vice versa. This relationship may indicate that improvements in the macroeconomy (such as higher GDP or lower inflation) are associated with lower risk losses, potentially due to more favorable business conditions and lower financial strain. Understanding this dynamic will be crucial for interpreting the model results and for making informed decisions based on macroeconomic trends in stress-testing Operational Risk.

#### Linearity Assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = model_data, aes(x = poil, y = OR_Loss_in_assets)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "red") +
  labs(title = "Scatterplot of poil vs. OR_Loss_in_assets", 
       x = "poil", y = "OR_Loss_in_assets") +
  theme_minimal()
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = model_data, aes(x = real_gdp_y, y = OR_Loss_in_assets)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "green") +
  labs(title = "Scatterplot of real_gdp_y vs. OR_Loss_in_assets", 
       x = "real_gdp_y", y = "OR_Loss_in_assets") +
  theme_minimal()
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = model_data, aes(x = GDD_Elc_R_y, y = OR_Loss_in_assets)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "blue") +
  labs(title = "Scatterplot of GDD_Elc_R_y vs. OR_Loss_in_assets", 
       x = "GDD_Elc_R_y", y = "OR_Loss_in_assets") +
  theme_minimal()
```
**Findings:** It is challenging to confirm the presence of linear relationships between the independent and dependent variables. The linearity assumption posits that the relationship between predictors (macroeconomic variables) and the response variable (Operational Risk Losses) is linear. However, if this assumption is violated, the model might fail to capture the true dynamics, resulting in biased or inefficient predictions. In the context of forecasting Operational Risk, where relationships between macroeconomic factors and risk losses are likely complex and non-linear, ignoring these non-linear dynamics could lead to inaccurate risk assessments. Stress testing using linear models in such cases may yield misleading conclusions about the impact or severity of Operational Risk Losses, potentially compromising decision-making and risk management strategies. It is crucial to explore non-linear modeling approaches to better capture these relationships and enhance the robustness of stress-testing analyses.

#### Normality Assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Calculating model residuals
residuals2 <- resid(mfl_model_or2)

# Creating a 1x2 grid of plots (histogram and Q-Q plot)
par(mfrow = c(1, 2), mar = c(5, 4, 4, 2))

# Histogram of residuals with adjusted bins and axis formatting
hist(
  residuals2,
  breaks = 5,  # Increase the number of bins
  main = "Histogram of Residuals",
  xlab = "Residual Value",
  col = "lightblue",
  border = "black",
  xaxt = "n"
)

# Customize x-axis to remove scientific notation
axis(1, at = pretty(residuals2), labels = format(pretty(residuals2), 
                                                scientific = FALSE))

# Q-Q plot of residuals
qqnorm(residuals2, main = "Normal Q-Q Plot")
qqline(residuals2, col = "red")

# Reset plotting layout to default
par(mfrow = c(1, 1))
```
**Findings:** The histogram of the residuals shows a distribution that does not appear to be normally distributed, but without noticeable gaps in the residuals' distribution. This observation confirms that the normality assumption is not fully met for this model. Additionally, the Q-Q plot does not follow a straight line, further indicating that the normality assumption is violated.
The normality assumption is crucial, especially for statistical inference, including hypothesis testing and confidence intervals. When the residuals are not normally distributed, the accuracy of p-values and confidence intervals can be compromised. If this assumption is violated, the model's ability to reliably predict Operational Risk could be affected, particularly when estimating uncertainty, such as in the construction of prediction intervals. While the model may still provide valuable insights and predictions, these predictions should be interpreted with caution due to the violation of the normality assumption. To improve the model's reliability, alternative techniques such as non-parametric models or transformation of variables might be considered to better meet the normality assumption.

#### Constant Variance Assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Calculating fitted values and residuals
fitted_values <- fitted(mfl_model_or2)
residuals2 <- resid(mfl_model_or2)

# Creating a scatterplot of fitted values vs residuals
plot(fitted_values, residuals2, 
     xlab = "Fitted Values", 
     ylab = "Residuals", 
     main = "Fitted Values vs Residuals", 
     pch = 19, col = "blue")
abline(h = 0, col = "red", lty = 2)
```
**Findings:** The fitted values of variance appear to be similarly distributed, confirming that the assumption of homoscedasticity (constant variance) is met. This indicates that the spread of the residuals is consistent across all levels of the independent variables, which is a desirable property in regression models. As a result, the model is likely to produce reliable estimates, and heteroscedasticity is not a concern in this case. Therefore, the assumption of homoscedasticity holds, enhancing the validity of the model's predictions and inferences.

#### No Multicollinearity Assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Checking for no multicollinearity assumption
columns2 <- c('poil', 'real_gdp_y', 
             'GDD_Elc_R_y', 'OR_Loss_in_assets')

# Creating a pair plot for the selected columns
ggpairs(model_data[, columns2])


# Calculating VIF for the model
vif_result2 <- vif(mfl_model_or2)

# Converting the VIF results to a data frame
df_vif2 <- data.frame(VIF = vif_result2)
df_vif2
```
**Findings:** The Variance Inflation Factor (VIF) analysis shows that the VIF for poil and GDD_Elc_R_y is less than 5, indicating low to moderate multicollinearity, which is within acceptable levels. However, real_gdp_y exhibits high multicollinearity, suggesting that it is highly correlated with one or more of the other independent variables. This could potentially affect the stability and interpretability of the regression coefficients, as multicollinearity can inflate standard errors and make it difficult to determine the individual effect of each variable.

#### Multiple Linear Model 3

```{r}
# Multiple linear regression model construction
mfl_model_or3 <- lm(OR_Loss_in_assets ~ poil + 
                      GDD_Elc_R_y + GDD_R_y, data = model_data)
summary(mfl_model_or3)
```
#### Creating correlation matrix

```{r}
kendall_corr3 <- model_data %>% 
  dplyr:: select(poil, GDD_Elc_R_y, GDD_R_y, OR_Loss_in_assets)

# Calculating Kendall's correlation matrix
kendall_corr3 <- cor(kendall_corr3, method = "kendall", 
                    use = "complete.obs")
print(kendall_corr3)
```
```{r fig.align="center", fig.width=6, fig.height=4}
# Visualization Kendall's correlation matrix by correlation plot
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", 
                          "#77AADD", "#4477AA"))
corrplot(kendall_corr3, method = "color", col = col(200),
         type = "upper", order = "hclust",
         addCoef.col = "black", 
         tl.col = "black", tl.srt = 45,
         
)
```
**Findings:** The moderate negative correlation between the independent variables (macroeconomic factors) and the dependent variable (Operational Risk Losses) indicates an inverse relationship. This suggests that when certain macroeconomic indicators increase, Operational Risk Losses tend to decrease, and vice versa. This inverse relationship could reflect how improved economic conditions or certain macroeconomic variables (such as GDP growth, low inflation, or stable financial markets) might reduce operational risks by enhancing the stability of financial institutions.
Interpreting this finding is important for understanding the dynamics between macroeconomic factors and operational risk, especially when developing predictive models. It could imply that in times of economic growth or stability, operational risks may be less severe, whereas economic downturns or instability could increase operational risks. This understanding will be crucial for making more informed decisions and strategies related to stress-testing and risk management.

#### Linearity Assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = model_data, aes(x = poil, y = OR_Loss_in_assets)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "red") +
  labs(title = "Scatterplot of poil vs. OR_Loss_in_assets", 
       x = "poil", y = "OR_Loss_in_assets") +
  theme_minimal()
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = model_data, aes(x = GDD_Elc_R_y, y = OR_Loss_in_assets)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "green") +
  labs(title = "Scatterplot of GDD_Elc_R_y vs. OR_Loss_in_assets", 
       x = "GDD_Elc_R_y", y = "OR_Loss_in_assets") +
  theme_minimal()
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = model_data, aes(x = GDD_R_y, y = OR_Loss_in_assets)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "blue") +
  labs(title = "Scatterplot of GDD_R_y vs. OR_Loss_in_assets", 
       x = "GDD_R_y", y = "OR_Loss_in_assets") +
  theme_minimal()
```
**Findings:** The difficulty in confirming the presence of linear relationships between the independent variables (macroeconomic factors) and the dependent variable (Operational Risk Losses) suggests a potential violation of the linearity assumption. In linear regression, the assumption is that there is a linear relationship between the predictors and the response variable. If this assumption does not hold, the model may produce biased or inefficient predictions, leading to less accurate forecasts.
In the context of forecasting Operational Risk, where macroeconomic factors can interact in complex ways, non-linear relationships may better capture the true dynamics. Ignoring these potential non-linearities could result in a misrepresentation of the relationship between economic conditions and risk losses. This would affect the reliability of stress tests and impact risk management strategies, potentially leading to misleading conclusions about the severity of Operational Risk Losses under different economic conditions.
To improve model accuracy, exploring non-linear models or transforming the data might be necessary, ensuring that the relationships are appropriately captured and that stress testing reflects a more accurate picture of risk exposure.

#### Normality Assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Calculating model residuals
residuals3 <- resid(mfl_model_or3)

# Creating a 1x2 grid of plots (histogram and Q-Q plot)
par(mfrow = c(1, 2), mar = c(5, 4, 4, 2))

# Histogram of residuals with adjusted bins and axis formatting
hist(
  residuals3,
  breaks = 5,  # Increase the number of bins
  main = "Histogram of Residuals",
  xlab = "Residual Value",
  col = "lightblue",
  border = "black",
  xaxt = "n"
)

# Customize x-axis to remove scientific notation
axis(1, at = pretty(residuals3), labels = format(pretty(residuals3), 
                                                scientific = FALSE))

# Q-Q plot of residuals
qqnorm(residuals3, main = "Normal Q-Q Plot")
qqline(residuals3, col = "red")

# Reset plotting layout to default
par(mfrow = c(1, 1))
```
**Findings:** The histogram of the residuals appears to show a distribution that seems normally distributed and without noticeable gaps, which typically supports the normality assumption for the model. However, the Q-Q plot does not follow a straight line, which generally indicates that the normality assumption is not fully met.
It seems there's a contradiction in the findings: if the Q-Q plot does not follow a straight line, it suggests that the residuals are not normally distributed, which would not typically support the normality assumption. The discrepancy between the histogram and Q-Q plot needs to be considered carefully. While histograms are useful for visualizing overall distribution, Q-Q plots are a more reliable tool for assessing normality.
Given that the Q-Q plot does not indicate normality, it's likely that the residuals does not meet the assumption of normality for this model.


#### Constant Variance Assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Calculating fitted values and residuals
fitted_values3 <- fitted(mfl_model_or3)
residuals3 <- resid(mfl_model_or3)

# Creating a scatterplot of fitted values vs residuals
plot(fitted_values3, residuals3, 
     xlab = "Fitted Values", 
     ylab = "Residuals", 
     main = "Fitted Values vs Residuals", 
     pch = 19, col = "blue")
abline(h = 0, col = "red", lty = 2)
```
**Findings:** The distribution of the fitted values of variance appears to be consistent, which supports the assumption of homoscedasticity (constant variance) in the model. This means that the variability in the residuals is roughly the same across all levels of the independent variables, indicating that the model is likely to be well-specified with respect to the assumption of equal variance.
The assumption of homoscedasticity is crucial for making reliable statistical inferences, such as accurate p-values and confidence intervals. Since this assumption is met, the results of the model, including predictions and hypothesis tests, are likely to be more reliable and robust.

#### No Multicollinearity Assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Checking for no multicollinearity assumption
columns3 <- c('poil', 'GDD_Elc_R_y', 
             'GDD_R_y', 'OR_Loss_in_assets')

# Creating a pair plot for the selected columns
ggpairs(model_data[, columns3])


# Calculating VIF for the model
vif_result3 <- vif(mfl_model_or3)

# Converting the VIF results to a data frame
df_vif3 <- data.frame(VIF = vif_result3)
df_vif3
```
**Findings:** The Variance Inflation Factor (VIF) values indicate that there is low to moderate multicollinearity between the macroeconomic variables poil (Price for Brent) and GDD_Elc_R_y (Real Gross Value Added - Electricity), which is within acceptable levels. However, GDD_R_y (Real Gross Value Added) exhibits high multicollinearity, which could potentially cause issues in interpreting the model and its coefficients.
High multicollinearity between independent variables can inflate standard errors and make it difficult to assess the individual impact of each variable on the dependent variable. To address this issue, one potential solution would be to remove or combine highly correlated predictors or use techniques like Ridge Regression or Principal Component Analysis (PCA) to mitigate the effects of multicollinearity while maintaining predictive accuracy.

#### Multiple Linear Model 4

```{r}
# Multiple linear regression model construction
mfl_model_or4 <- lm(OR_Loss_in_assets ~ GDD_Agr_R_y + 
                      GDD_Trn_R_y + GDD_Est_R_y, data = model_data)
summary(mfl_model_or4)
```
#### Creating correlation matrix

```{r}
kendall_corr4 <- model_data %>% 
  dplyr:: select(GDD_Agr_R_y, GDD_Trn_R_y, GDD_Est_R_y, OR_Loss_in_assets)

# Calculating Kendall's correlation matrix
kendall_corr4 <- cor(kendall_corr4, method = "kendall", 
                    use = "complete.obs")
print(kendall_corr4)
```
```{r fig.align="center", fig.width=6, fig.height=4}
# Visualization Kendall's correlation matrix by correlation plot
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", 
                          "#77AADD", "#4477AA"))
corrplot(kendall_corr4, method = "color", col = col(200),
         type = "upper", order = "hclust",
         addCoef.col = "black", 
         tl.col = "black", tl.srt = 45,
         
)
```
**Findings:** The analysis of correlation between the independent and dependent variables reveals a moderate negative correlation, suggesting an inverse relationship between the macroeconomic variables and Operational Risk Losses. Specifically, as certain macroeconomic indicators (such as GDP, inflation, or oil prices) increase, the corresponding Operational Risk Losses tend to decrease, and vice versa.
This inverse relationship is an important insight for interpreting the results of the model. It indicates that favorable macroeconomic conditions, such as higher economic growth or lower inflation, may be associated with lower Operational Risk Losses. Understanding this dynamic can be crucial for predicting how changes in the macroeconomic environment may impact the risk profile of the organization, and for developing strategies to mitigate these risks. However, it is also important to explore further whether this relationship holds in different economic contexts or over different time periods.

#### Linearity Assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = model_data, aes(x = GDD_Agr_R_y, y = OR_Loss_in_assets)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "red") +
  labs(title = "Scatterplot of GDD_Agr_R_y vs. OR_Loss_in_assets", 
       x = "GDD_Agr_R_y", y = "OR_Loss_in_assets") +
  theme_minimal()
```
```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = model_data, aes(x = GDD_Trn_R_y, y = OR_Loss_in_assets)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "green") +
  labs(title = "Scatterplot of GDD_Trn_R_y vs. OR_Loss_in_assets", 
       x = "GDD_Trn_R_y", y = "OR_Loss_in_assets") +
  theme_minimal()
```
```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = model_data, aes(x = GDD_Est_R_y, y = OR_Loss_in_assets)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "blue") +
  labs(title = "Scatterplot of GDD_Est_R_y vs. OR_Loss_in_assets", 
       x = "GDD_Est_R_y", y = "OR_Loss_in_assets") +
  theme_minimal()
```
**Findings:** The difficulty in confirming the presence of linear relationships between the independent variables (macroeconomic indicators) and the dependent variable (Operational Risk Losses) suggests that the linearity assumption may be violated. The assumption of linearity requires that the relationship between predictors and the response variable be linear, and when this assumption is not met, the model may not accurately capture the true relationship.
Given that relationships between macroeconomic factors and Operational Risk Losses are likely to be complex and potentially non-linear, relying on linear models may lead to biased or inefficient predictions. In this context, stress testing using linear models could produce misleading results about the potential impact or severity of Operational Risk Losses, which could negatively affect decision-making and risk management strategies.
To address this, alternative modeling approaches (e.g., non-linear models, machine learning techniques) may be considered to better capture the complexity of the relationships and provide more accurate risk assessments.

#### Normality Assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Calculating model residuals
residuals4 <- resid(mfl_model_or4)

# Creating a 1x2 grid of plots (histogram and Q-Q plot)
par(mfrow = c(1, 2), mar = c(5, 4, 4, 2))

# Histogram of residuals with adjusted bins and axis formatting
hist(
  residuals4,
  breaks = 5,  # Increase the number of bins
  main = "Histogram of Residuals",
  xlab = "Residual Value",
  col = "lightblue",
  border = "black",
  xaxt = "n"
)

# Customize x-axis to remove scientific notation
axis(1, at = pretty(residuals4), labels = format(pretty(residuals4), 
                                                scientific = FALSE))

# Q-Q plot of residuals
qqnorm(residuals4, main = "Normal Q-Q Plot")
qqline(residuals4, col = "red")

# Reset plotting layout to default
par(mfrow = c(1, 1))
```
**Findings:** The histogram of the residuals appears to show a distribution that is almost normally distributed, with no noticeable gaps in the residuals' distribution, which suggests that the normality assumption may be reasonably met. However, the Q-Q plot, which should follow a straight line for normally distributed data, indicates that the normality assumption is violated.
This contradiction between the histogram and Q-Q plot suggests that while the residuals may seem nearly normal at a glance, there are still deviations from normality that could affect statistical inference, such as p-values and confidence intervals. If the normality assumption is violated, the reliability of hypothesis tests and predictions may be compromised, especially when constructing prediction intervals or assessing uncertainty in the model.
It is important to carefully consider the implications of this violation when interpreting the model's results and use caution when making decisions based on these predictions. Further diagnostic checks or alternative modeling approaches could help mitigate these issues.


#### Constant Variance Assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Calculating fitted values and residuals
fitted_values4 <- fitted(mfl_model_or4)
residuals4 <- resid(mfl_model_or4)

# Creating a scatterplot of fitted values vs residuals
plot(fitted_values4, residuals4, 
     xlab = "Fitted Values", 
     ylab = "Residuals", 
     main = "Fitted Values vs Residuals", 
     pch = 19, col = "blue")
abline(h = 0, col = "red", lty = 2)
```
**Findings:** The analysis of the fitted values of variance reveals that they are not similarly distributed, which indicates that the assumption of homoscedasticity (constant variance) is not fully met. In other words, the variance of the residuals is not consistent across all levels of the independent variables, which suggests the presence of heteroscedasticity.
Heteroscedasticity can lead to inefficient estimates of the regression coefficients and can affect the reliability of statistical tests, such as hypothesis testing. When this assumption is violated, the standard errors of the regression coefficients may be biased, potentially resulting in misleading conclusions. This can make confidence intervals wider or narrower than they should be and affect the interpretation of p-values.
To address this issue, it may be necessary to transform the dependent variable, use weighted least squares regression, or apply robust standard errors to account for the heteroscedasticity and ensure more reliable inference.

#### No Multicollinearity Assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Checking for no multicollinearity assumption
columns4 <- c('GDD_Agr_R_y', 'GDD_Trn_R_y', 
             'GDD_Est_R_y', 'OR_Loss_in_assets')

# Creating a pair plot for the selected columns
ggpairs(model_data[, columns4])


# Calculating VIF for the model
vif_result4 <- vif(mfl_model_or4)

# Converting the VIF results to a data frame
df_vif4 <- data.frame(VIF = vif_result4)
df_vif4
```
**Findings:** The Variance Inflation Factor (VIF) is less than 2, indicating low multicollinearity among the independent variables, which is well within acceptable levels. This suggests that there is no significant redundancy between the predictors, meaning the model should be able to estimate the effects of each independent variable on the dependent variable without issues related to multicollinearity.
Low multicollinearity ensures that the coefficients estimated by the regression model are stable and reliable, allowing for more precise interpretations of the relationships between the predictors and the response variable. Therefore, no further action is needed in terms of multicollinearity in this model.

### Comparative Analysis of Model Performances

```{r}
# Checking Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) 
# for Multiple Regression Model 1
options(scipen = 999)
mse_mfl_model_or <- mean(mfl_model_or$residuals^2)
rmse_mfl_model_or <- sqrt(mse_mfl_model_or)
r_squared <- summary(mfl_model_or)$r.squared
adj_r_squared <- summary(mfl_model_or)$adj.r.squared
cat("Mean Squared Error (MSE):", 
    mse_mfl_model_or, "\n")
cat("Root Mean Squared Error (RMSE):", 
    rmse_mfl_model_or, "\n")
cat("R squared (Coefficient of Determination):", 
    r_squared, "\n")
cat("Adjusted R squared (Coefficient of Determination):", 
    adj_r_squared, "\n")
```

```{r}
# Checking Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) 
# for Multiple Regression Model 2
options(scipen = 999)
mse_mfl_model_or2 <- mean(mfl_model_or2$residuals^2)
rmse_mfl_model_or2 <- sqrt(mse_mfl_model_or2)
r_squared2 <- summary(mfl_model_or2)$r.squared
adj_r_squared2 <- summary(mfl_model_or2)$adj.r.squared
cat("Mean Squared Error (MSE):", 
    mse_mfl_model_or2, "\n")
cat("Root Mean Squared Error (RMSE):", 
    rmse_mfl_model_or2, "\n")
cat("R squared (Coefficient of Determination):", 
    r_squared2, "\n")
cat("Adjusted R squared (Coefficient of Determination):", 
    adj_r_squared2, "\n")
```

```{r}
# Checking Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) 
# for Multiple Regression Model 3
options(scipen = 999)
mse_mfl_model_or3 <- mean(mfl_model_or3$residuals^2)
rmse_mfl_model_or3 <- sqrt(mse_mfl_model_or3)
r_squared3 <- summary(mfl_model_or3)$r.squared
adj_r_squared3 <- summary(mfl_model_or3)$adj.r.squared
cat("Mean Squared Error (MSE):", 
    mse_mfl_model_or3, "\n")
cat("Root Mean Squared Error (RMSE):", 
    rmse_mfl_model_or3, "\n")
cat("R squared (Coefficient of Determination):", 
    r_squared3, "\n")
cat("Adjusted R squared (Coefficient of Determination):", 
    adj_r_squared3, "\n")
```

```{r}
# Checking Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) 
# for Multiple Regression Model 4
options(scipen = 999)
mse_mfl_model_or4 <- mean(mfl_model_or4$residuals^2)
rmse_mfl_model_or4 <- sqrt(mse_mfl_model_or4)
r_squared4 <- summary(mfl_model_or4)$r.squared
adj_r_squared4 <- summary(mfl_model_or4)$adj.r.squared
cat("Mean Squared Error (MSE):", 
    mse_mfl_model_or4, "\n")
cat("Root Mean Squared Error (RMSE):", 
    rmse_mfl_model_or4, "\n")
cat("R squared (Coefficient of Determination):", 
    r_squared4, "\n")
cat("Adjusted R squared (Coefficient of Determination):", 
    adj_r_squared4, "\n")
```

```{r}
# Creating a data frame with model performance metrics
mfl_model_results <- data.frame(
  Model = c("Multiple Regression Model 1", "Multiple Regression Model 2", 
            "Multiple Regression Model 3", "Multiple Regression Model 4"),
  MSE = c(0.0000001254494, 0.0000001279794, 0.0000001281818, 0.0000001313972),
  RMSE = c(0.0003541884, 0.0003577421, 0.0003580249, 0.0003624875),
  R_squared = c(0.4426, 0.4314, 0.4305, 0.4162),
  Adjusted_R_squared = c(0.3590, 0.3461, 0.3451, 0.3451)
)

kable(mfl_model_results, format = "markdown", digits = 10, 
      caption = "Linear Model Performance Metrics")
```

### Interim conclusion

Model 1, which includes the macroeconomic variables:

GDD_Trn_R_y (Real Gross Value Added - Transportation)
GDD_Inf_R_y (Real Gross Value Added - Information)
Rincpop_q_y (Real Population Average Monthly Income)
performs best with the lowest prediction error (MSE: 0.0000001254494, RMSE: 0.0003541884), the highest R^2 (0.4426), and Adjusted R^2 0.3590). These metrics suggest that Model 1 explains the greatest variance in the target variable, making it the most effective for predicting Operational Risk Losses among the models tested.

On the other hand, Model 4 performs the worst with the highest MSE and RMSE, and the lowest R^2, indicating its ineffectiveness in capturing the relationship between the macroeconomic variables and Operational Risk Losses.

Despite its good performance, Model 1 does not fully meet key regression assumptions, specifically linearity and normality. Given the violation of these assumptions, non-linear models will be explored to improve performance and better capture the underlying complexities of the relationship. These models include:

Multiple Polynomial Regression: To capture higher-order relationships between predictors and the response variable.
Generalized Additive Models (GAM): To allow for flexible, non-linear relationships between variables without imposing strict linearity.
After implementing these non-linear approaches, the most suitable model will be selected based on its ability to better satisfy assumptions, reduce prediction error, and improve scenario forecasting.


## Multiple Polynomial Regression Model Construction

To further enhance the model's performance and check the validity of the modeling assumptions, Multiple Polynomial Regression will be applied to the best combination of macroeconomic variables identified in Model 1:
GDD_Trn_R_y (Real Gross Value Added - Transportation)
GDD_Inf_R_y (Real Gross Value Added - Information)
Rincpop_q_y (Real Population Average Monthly Income).

The application of polynomial terms will allow us to capture potential non-linear relationships between these macroeconomic variables and Operational Risk Losses. Following this, we will assess the model's performance in terms of:
Prediction accuracy (MSE, RMSE, R^2, Adjusted R^2)
Key regression assumptions (linearity, normality, and homoscedasticity)
This approach will provide a more flexible framework to better explain the relationship between macroeconomic factors and Operational Risk Losses, and identify if a non-linear model leads to a better fit for the data. After evaluating the results, we can determine whether polynomial regression improves model assumptions and predictive performance.

### Multiple Polynomial Regression Model Fitting

#### Hypothesis Formulation:
Null Hypothesis (H0): The macroeconomic variables are not related to Operational Risk Losses.
Alternative Hypothesis (Ha): The macroeconomic variables are related to Operational Risk Losses.
The alpha level is set to 0.1 (90% confidence level), and the acceptable R² (Coefficient of Determination) threshold is set to 0.35 (35%).

#### Multiple Polynomial Regression Model of the second-degree polynomial transformation

```{r}
# Multiple polynomial regression model construction
poly_model_or <- lm(OR_Loss_in_assets ~ poly(GDD_Trn_R_y, 2) + 
                                        poly(GDD_Inf_R_y, 2) + 
                                        poly(Rincpop_q_y, 2), 
                     data = model_data)

summary(poly_model_or)
```
**Findings:** The Intercept term in the polynomial regression model is highly significant, with a p-value of less than 0.001, suggesting that the constant term in the model is important for predicting Operational Risk Losses.
The Null hypothesis (H0) is rejected and Alternative hypothesis (Ha) is accepted.
But the polynomial terms for the independent variables (GDD_Trn_R_y, GDD_Inf_R_y, and Rincpop_q_y) are not statistically significant, with p-values greater than 0.1. This implies that the inclusion of higher-order polynomial terms for these variables does not provide a meaningful improvement in model performance, and the model may be overly complex for the data.
The Multiple R^2 of 0.449 indicates that the model explains about 44.9% of the variance in Operational Risk Losses (OR_Loss_in_assets), which is a relatively strong fit, though not perfect.
The Adjusted R^2 of 0.2546 is notably lower than the R^2, which suggests that the model may suffer from overfitting. This indicates that while the model fits the data well, it may not generalize as effectively to new data, due to the inclusion of unnecessary predictors.

#### Visualization of the second-degree Polynomial Regression
```{r fig.align="center", fig.width=6, fig.height=4}
# Plotting polynomial regression scatter plot
ggplot(data = model_data, aes(x = GDD_Trn_R_y, y = OR_Loss_in_assets)) +
    geom_point() +
    geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = TRUE) +
    labs(title = "Polynomial Regression: OR_Loss_in_assets vs. GDD_Trn_R_y")
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Plotting polynomial regression scatter plot
ggplot(data = model_data, aes(x = GDD_Inf_R_y, y = OR_Loss_in_assets)) +
    geom_point() +
    geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = TRUE) +
    labs(title = "Polynomial Regression: OR_Loss_in_assets vs. GDD_Inf_R_y")
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Plotting polynomial regression scatter plot
ggplot(data = model_data, aes(x = Rincpop_q_y, y = OR_Loss_in_assets)) +
    geom_point() +
    geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = TRUE) +
    labs(title = "Polynomial Regression: OR_Loss_in_assets vs. Rincpop_q_y")
```
**Findings:** The second-degree polynomial regression has been fitted to the data, and the resulting smooth curve captures some potential non-linear patterns. However, the curve appears to be relatively flat, with only slight curvature, indicating that the non-linear relationship between the independent and dependent variables is minimal.
Despite capturing some non-linearity, the polynomial regression does not show a strong non-linear relationship between the variables, suggesting that the second-degree polynomial may not be the best fit for these variables.
Given that the model only shows slight curvature, it is likely that a higher-order polynomial might be necessary to better capture more complex relationships. Alternatively, other non-linear models, such as Generalized Additive Models (GAM), could be explored to better represent potential non-linear dynamics in the data.


#### Multiple Polynomial Regression Model of the third-degree polynomial transformation

```{r}
# Multiple polynomial regression model construction
poly_model_or2 <- lm(OR_Loss_in_assets ~ poly(GDD_Trn_R_y, 3) + 
                                        poly(GDD_Inf_R_y, 3) + 
                                        poly(Rincpop_q_y, 3), 
                     data = model_data)

summary(poly_model_or2)
```
**Findings:** The Intercept in the polynomial regression is highly significant, with a p-value less than 0.001, and an estimate of 0.0019989, indicating that it plays an important role in explaining the dependent variable.
The Null hypothesis (H0) is rejected and Alternative hypothesis (Ha) is accepted.
But the polynomial terms for GDD_Trn_R_y, GDD_Inf_R_y, and Rincpop_q_y are not statistically significant (all p-values > 0.1). This suggests that adding higher-order polynomial terms for these variables does not significantly improve the model’s predictive ability.
The Multiple R^2 value is 0.5622, meaning that the model explains approximately 56.2% of the variance in the dependent variable (OR_Loss_in_assets), which indicates a decent fit.
However, the Adjusted R^2 is 0.2807, significantly lower than the R^2 value. This difference suggests that the model might be suffering from overfitting, where the model fits the training data well but may not generalize effectively to new data. The large gap between R^2 and Adjusted R^2 indicates that the model's performance is likely inflated due to the inclusion of too many predictors.

#### Visualization of the third-degree Polynomial Regression
```{r fig.align="center", fig.width=6, fig.height=4}
# Plotting polynomial regression scatter plot
ggplot(data = model_data, aes(x = GDD_Trn_R_y, y = OR_Loss_in_assets)) +
    geom_point() +
    geom_smooth(method = "lm", formula = y ~ poly(x, 3), se = TRUE) +
    labs(title = "Polynomial Regression: OR_Loss_in_assets vs. GDD_Trn_R_y")
```
```{r fig.align="center", fig.width=6, fig.height=4}
# Plotting polynomial regression scatter plot
ggplot(data = model_data, aes(x = GDD_Inf_R_y, y = OR_Loss_in_assets)) +
    geom_point() +
    geom_smooth(method = "lm", formula = y ~ poly(x, 3), se = TRUE) +
    labs(title = "Polynomial Regression: OR_Loss_in_assets vs. GDD_Inf_R_y")
```
```{r fig.align="center", fig.width=6, fig.height=4}
# Plotting polynomial regression scatter plot
ggplot(data = model_data, aes(x = Rincpop_q_y, y = OR_Loss_in_assets)) +
    geom_point() +
    geom_smooth(method = "lm", formula = y ~ poly(x, 3), se = TRUE) +
    labs(title = "Polynomial Regression: OR_Loss_in_assets vs. Rincpop_q_y")
```
**Findings:** The third-degree polynomial regression line has been fitted to the data, attempting to capture potential non-linear relationships between the independent variables and the dependent variable. However, the curve appears to be relatively flat, with only slight curvature, suggesting that the non-linear relationship between the variables is weak.
The lack of pronounced curvature in the third-degree polynomial indicates that this model might not effectively capture significant non-linear patterns in the data. While it does attempt to fit a more complex relationship, the model may not provide substantial improvements over lower-degree polynomials.
This observation reinforces the idea that the third-degree polynomial may not be the optimal choice for modeling the relationship between the macroeconomic variables and Operational Risk Losses. Further exploration with higher-order polynomials or alternative non-linear models (such as Generalized Additive Models (GAM)) will be be considered to better capture complex relationships if they exist.

#### Multiple Polynomial Regression Model of the sixth-degree polynomial transformation

```{r}
# Multiple polynomial regression model construction
poly_model_or3 <- lm(OR_Loss_in_assets ~ poly(GDD_Trn_R_y, 6) + 
                                        poly(GDD_Inf_R_y, 6) + 
                                        poly(Rincpop_q_y, 6), 
                     data = model_data)

summary(poly_model_or3)
```
**Findings:** Intercept Significance: The intercept is highly significant (p-value < 0.001), suggesting that the baseline level of Operational Risk Losses (OR_Loss_in_assets) is statistically meaningful in the model.
The Null hypothesis (H0) is rejected and Alternative hypothesis (Ha) is accepted.
Polynomial Terms: The polynomial terms for GDD_Trn_R_y, GDD_Inf_R_y, and Rincpop_q_y are not statistically significant (all p-values > 0.1). This implies that the inclusion of higher-order polynomial terms does not substantially improve the model's predictive power, and these terms do not add meaningful information to the model.
The Multiple R^2 is 0.8669, indicating that about 86.7% of the variance in OR_Loss_in_assets is explained by the model, which is a strong fit.
The Adjusted R^2 is 0.2656, much lower than the R-squared, which raises concerns about overfitting.

#### Visualization of the sixth-degree Polynomial Regression
```{r fig.align="center", fig.width=6, fig.height=4}
# Plotting polynomial regression scatter plot
ggplot(data = model_data, aes(x = GDD_Trn_R_y, y = OR_Loss_in_assets)) +
    geom_point() +
    geom_smooth(method = "lm", formula = y ~ poly(x, 6), se = TRUE) +
    labs(title = "Polynomial Regression: OR_Loss_in_assets vs. GDD_Trn_R_y")
```
```{r fig.align="center", fig.width=6, fig.height=4}
# Plotting polynomial regression scatter plot
ggplot(data = model_data, aes(x = GDD_Inf_R_y, y = OR_Loss_in_assets)) +
    geom_point() +
    geom_smooth(method = "lm", formula = y ~ poly(x, 6), se = TRUE) +
    labs(title = "Polynomial Regression: OR_Loss_in_assets vs. GDD_Inf_R_y")
```
```{r fig.align="center", fig.width=6, fig.height=4}
# Plotting polynomial regression scatter plot
ggplot(data = model_data, aes(x = Rincpop_q_y, y = OR_Loss_in_assets)) +
    geom_point() +
    geom_smooth(method = "lm", formula = y ~ poly(x, 6), se = TRUE) +
    labs(title = "Polynomial Regression: OR_Loss_in_assets vs. Rincpop_q_y")
```
**Findings:** Sixth-Degree Polynomial Fit: The sixth-degree polynomial regression model fits the data with a smooth curve that captures intricate patterns. However, the curve shows significant fluctuations, suggesting that the model is highly sensitive to minor variations in the data.
Overfitting Risk: The complexity introduced by the sixth-degree polynomial may be causing overfitting. The model is likely capturing noise or random fluctuations in the data rather than just the underlying relationship, leading to poor generalization when applied to new data.
Model Complexity vs. Predictive Performance: While the sixth-degree polynomial fits the data well, the degree of complexity may be excessive. 


## Multiple Generalized Additive Model (GAM) Construction

### Multiple Generalized Additive Model (GAM) Fitting

#### Hypothesis Formulation:
Null Hypothesis (H0): The macroeconomic variables are not related to Operational Risk Losses.
Alternative Hypothesis (Ha): The macroeconomic variables are related to Operational Risk Losses.
The alpha level is set to 0.1 (90% confidence level), and the acceptable R² (Coefficient of Determination) threshold is set to 0.35 (35%).

```{r}
# Multiple Generalized Additive Model (GAM) construction
gam_model_or <- gam(OR_Loss_in_assets ~ s(GDD_Trn_R_y) + 
                      s(GDD_Inf_R_y) + s(Rincpop_q_y), data = model_data)
summary(gam_model_or)
```
**Findings:** The Intercept in the Generalized Additive Model (GAM) regression is highly significant, with a p-value less than 0.001, and an estimate of 0.0019989, indicating that it plays an important role in explaining the dependent variable.
The Null hypothesis (H0) is rejected and Alternative hypothesis (Ha) is accepted.
Model Fit: The Generalized Additive Model (GAM) explains about 35.9% of the variance in the target variable (Operational Risk Losses) based on the Adjusted R-squared. This indicates a reasonable fit, with a better explanation of variance compared to some earlier models. The Deviance Explained value of 44.3% further suggests that the model accounts for a significant proportion of the unexplained variability in the data.
Non-Linear Effects: The smooth terms for GDD_Trn_R_y (Real Gross Value Added - Transportation) and Rincpop_q_y (Real Population Average Monthly Income) show significant non-linear relationships with Operational Risk Losses, highlighting that these variables influence the target variable in a non-linear fashion. The ability of GAM to capture these non-linearities provides an advantage over simpler linear models.
Statistical Significance: Despite the non-linear relationships observed in the model, the independent variables are statistically significant (all p-values below the chosen threshold of 0.1). This confirms that the variables included in the model are related to the outcome variable.

#### Smoothness and Overfitting
```{r fig.align="center", fig.width=6, fig.height=4}
# Plotting the smooth terms
par(mfrow = c(1, 3))  # Arrange plots in a row
plot(gam_model_or, shade = TRUE, seWithMean = TRUE, 
     main = "GAM Smooth Terms")
```
**Findings:** GDD_Trn_R_y (Real Gross Value Added - Transportation, Transformed):
The smooth, non-linear relationship with Operational Risk Losses (OR_Loss_in_assets) suggests a decreasing trend at certain ranges of GDD_Trn_R_y. This implies that as the transportation sector's contribution to the economy increases, Operational Risk Losses tend to decrease, at least for specific ranges of GDD_Trn_R_y.
GDD_Inf_R_y (Real Gross Value Added - Information, Transformed):
The relationship here is more complex, with slight variations across different values. The increasing trend in Operational Risk Losses with higher GDD_Inf_R_y values suggests that a growing information sector could be associated with increasing operational risks at certain levels.
Rincpop_q_y (Real Population Average Monthly Income, Transformed):
The plot reveals a significant non-linear effect, with Operational Risk Losses decreasing as income levels rise. This suggests that at higher income levels, the associated operational risks might reduce, possibly reflecting better economic stability or lower susceptibility to operational failures in wealthier populations.

#### Normality Assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Calculating model residuals
residuals_gam <- resid(gam_model_or)

# Creating a 1x2 grid of plots (histogram and Q-Q plot)
par(mfrow = c(1, 2), mar = c(5, 4, 4, 2))

# Histogram of residuals with adjusted bins and axis formatting
hist(
  residuals_gam,
  breaks = 5,  # Increase the number of bins
  main = "Histogram of Residuals",
  xlab = "Residual Value",
  col = "lightgreen",
  border = "black",
  xaxt = "n"
)

# Customize x-axis to remove scientific notation
axis(1, at = pretty(residuals_gam), labels = format(pretty(residuals_gam), 
                                                scientific = FALSE))

# Q-Q plot of residuals
qqnorm(residuals_gam, main = "Normal Q-Q Plot")
qqline(residuals_gam, col = "red")

# Reset plotting layout to default
par(mfrow = c(1, 1))
```
**Findings:** Similar to the Multiple Regression Model, the Generalized Additive Model (GAM) exhibits a noticeable gap in the residuals' distribution, which suggests that the residuals do not follow a normal distribution.
The Q-Q plot does not align with a straight line, reinforcing the conclusion that the normality assumption is violated in this model.
The normality assumption is vital, particularly for conducting statistical inference (e.g., hypothesis testing and confidence intervals).
When residuals deviate from normality the p-values and confidence intervals may become unreliable, leading to potential misinterpretation of model significance. The predictive accuracy of the model, especially in cases involving uncertainty quantification (such as prediction intervals), may be compromised.


#### Constant Variance Assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Calculating fitted values and residuals
fitted_gam <- fitted(gam_model_or)
residuals_gam <- resid(gam_model_or)

# Creating a scatterplot of fitted values vs residuals
plot(fitted_gam, residuals_gam, 
     xlab = "Fitted Values", 
     ylab = "Residuals", 
     main = "Fitted Values vs Residuals", 
     pch = 19, col = "blue")
abline(h = 0, col = "red", lty = 2)
```
**Findings:** The distribution of the fitted values' variance is consistent, confirming that the assumption of homoscedasticity (constant variance) is met. The residuals are randomly scattered with no apparent pattern, further supporting the validity of homoscedasticity.

#### Independence of Residuals (Autocorrelation)

```{r}
# Application of the Durbin-Watson test is used to check 
# for the presence of autocorrelation in the residuals of a regression model
dwtest(gam_model_or)
```
**Findings:** The Durbin-Watson test for autocorrelation in the residuals of the Generalized Additive Model (GAM) yielded a test statistic of DW = 2.4683, with a p-value of 0.7032. A DW statistic close to 2 suggests the absence of significant autocorrelation in the residuals. The p-value of 0.7032, which is much higher than the typical significance level of 0.05, indicates that we fail to reject the null hypothesis of no autocorrelation. Therefore, we conclude that there is no significant autocorrelation in the residuals, and the assumption of independent residuals is satisfied. This suggests that the model is appropriate for reliable predictions without concerns regarding autocorrelation affecting the results.

### Comparative Analysis of Model Performances
```{r}
# Checking Mean Squared Error (MSE) and Root Mean Squared Error (RMSE)
# for Multiple Polynomial Regression Model 1
options(scipen = 999)
mse_poly_model_or <- mean(poly_model_or$residuals^2)
rmse_poly_model_or <- sqrt(mse_poly_model_or)
r_squared5 <- summary(poly_model_or)$r.squared
adj_r_squared5 <- summary(poly_model_or)$adj.r.squared
cat("Mean Squared Error (MSE):", 
    mse_poly_model_or, "\n")
cat("Root Mean Squared Error (RMSE):", 
    rmse_poly_model_or, "\n")
cat("R squared (Coefficient of Determination):", 
    r_squared5, "\n")
cat("Adjusted R squared (Coefficient of Determination):", 
    adj_r_squared5, "\n")
```

```{r}
# Checking Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) 
# for Multiple Polynomial Regression Model 2
options(scipen = 999)
mse_poly_model_or2 <- mean(poly_model_or2$residuals^2)
rmse_poly_model_or2 <- sqrt(mse_poly_model_or2)
r_squared6 <- summary(poly_model_or2)$r.squared
adj_r_squared6 <- summary(poly_model_or2)$adj.r.squared
cat("Mean Squared Error (MSE):", 
    mse_poly_model_or2, "\n")
cat("Root Mean Squared Error (RMSE):", 
    rmse_poly_model_or2, "\n")
cat("R squared (Coefficient of Determination):", 
    r_squared6, "\n")
cat("Adjusted R squared (Coefficient of Determination):", 
    adj_r_squared6, "\n")
```

```{r}
# Checking Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) 
# for Multiple Polynomial Regression Model 3
options(scipen = 999)
mse_poly_model_or3 <- mean(poly_model_or3$residuals^2)
rmse_poly_model_or3 <- sqrt(mse_poly_model_or3)
r_squared7 <- summary(poly_model_or3)$r.squared
adj_r_squared7 <- summary(poly_model_or3)$adj.r.squared
cat("Mean Squared Error (MSE):", 
    mse_poly_model_or3, "\n")
cat("Root Mean Squared Error (RMSE):", 
    rmse_poly_model_or3, "\n")
cat("R squared (Coefficient of Determination):", 
    r_squared7, "\n")
cat("Adjusted R squared (Coefficient of Determination):", 
    adj_r_squared7, "\n")
```

```{r}
# Checking Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) 
# for Multiple Generalized Additive Model (GAM)
options(scipen = 999)
mse_gam_model_or <- mean(gam_model_or$residuals^2)
rmse_gam_model_or <- sqrt(mse_gam_model_or)
deviance_explained <- summary(gam_model_or)$dev.explained
adj_r_squared8 <- (summary(gam_model_or)$r.sq)
cat("Mean Squared Error (MSE):", 
    mse_gam_model_or, "\n")
cat("Root Mean Squared Error (RMSE):", 
    rmse_gam_model_or, "\n")
cat("Adjusted R squared (Coefficient of Determination):", 
    adj_r_squared8, "\n")
```

```{r}
# Creating a data frame with model performance metrics
total_model_results_or <- data.frame(
  Model = c("Multiple Regression Model 1", "Multiple Regression Model 2", 
            "Multiple Regression Model 3", "Multiple Regression Model 4", 
            "Multiple Polynomial Model 1", "Multiple Polynomial Model 2", 
            "Multiple Polynomial Model 3", "Generalized Additive Model"),
  MSE = c(0.0000001254494, 0.0000001279794, 0.0000001281818, 
          0.0000001313972, 0.0000000692838, 0.00000009855074, 
          0.00000002995745, 0.00000002995745),
  RMSE = c(0.0003541884, 0.0003577421, 0.0003580249, 0.0003624875, 
           0.0002632182, 0.0003139279, 0.0001730822, 0.0003541881),
  R_squared = c(0.4426, 0.4314, 0.4305, 0.4162, 0.6921818, 
                0.5621529, 0.8669032, 0.4426469),
  Adjusted_R_squared = c(0.3590, 0.3461, 0.3451, 0.3451, 0.1150226,
                         0.2806797, 0.3877549, 0.3590417)
)

kable(total_model_results_or, format = "markdown", digits = 10, 
      caption = "Linear and Non-Linear Models Performance Metrics - Comparison")
```

### Interim conclusion

In comparing different models for the following macroeconomic variables:
GDD_Trn_R_y (Real Gross Value Added - Transportation),
GDD_Inf_R_y (Real Gross Value Added - Information),
Rincpop_q_y (Real Population Average Monthly Income),
the following key metrics were observed:

Model Performance Metrics:

MSE (Mean Squared Error) and RMSE (Root Mean Squared Error): Lower values suggest better model performance. Both Multiple Polynomial Model 3 and the Generalized Additive Model (GAM) exhibit the lowest MSE and RMSE values, indicating better predictive accuracy in terms of error.

R-squared: A higher R-squared value indicates a better model fit. Multiple Polynomial Model 3 achieves the highest R-squared (0.8669), while the GAM shows a significantly lower value (0.4426).

Adjusted R-squared: This metric accounts for the number of predictors, offering a more reliable measure for comparing models of varying complexity. Multiple Polynomial Model 3 has the highest adjusted R-squared (0.3878), suggesting a better balance between model complexity and fit compared to Multiple Polynomial Models 1 and 2, which have lower adjusted R-squared values.

Best Model Selection:

Multiple Polynomial Model 3 is the top performer in terms of predictive accuracy, with the lowest MSE, highest R-squared, and strong adjusted R-squared. However, its variables' statistical significance exceeds alpha = 0.1, which raises concerns about the reliability of the model's predictors.

On the other hand, the Generalized Additive Model (GAM) demonstrates more solid performance, with an adjusted R-squared value above 0.35 (35%), though it falls short of the polynomial models in R-squared and adjusted R-squared. Notably, the statistical significance of the variables in the GAM model is below alpha = 0.1, which makes it more statistically robust than the polynomial models.

**Conclusion:**
Considering both statistical significance and model performance, the Generalized Additive Model (GAM) emerges as the optimal choice. It offers a balanced trade-off between predictive power, error metrics, and model interpretability, ensuring reliable predictions while maintaining statistical significance.

## Multiple Poisson Model Construction

### Operational Risk Frequency (number) data preprocessing

#### Operational Risk Type 1
```{r}
# Grouping Operational Risk Type 1 by months
or_type1_bymonths <- or_type1 %>% 
  mutate(YearMonth = format(Date, "%Y-%m")) %>%
  group_by(YearMonth) %>% 
  summarise(Frequency_Monthly = n())
print(or_type1_bymonths)
or_type1_bymonths <- as.data.frame(or_type1_bymonths)
head(or_type1_bymonths)
```
```{r}
# Grouping and formatting as "YYYY-MM-DD" 
# for the last day of the quarter
or_type1_byquarters <- or_type1_bymonths %>%
  mutate(
    Date = ym(YearMonth),                               
    Year = year(Date),                                
    Quarter = quarter(Date),                            
    EndOfQuarter = case_when(                            
      Quarter == 1 ~ make_date(Year, 3, 31),
      Quarter == 2 ~ make_date(Year, 6, 30),
      Quarter == 3 ~ make_date(Year, 9, 30),
      Quarter == 4 ~ make_date(Year, 12, 31)
    )
  ) %>%
  group_by(EndOfQuarter) %>%
  summarize(Frequency_Quarterly = sum(Frequency_Monthly), 
            .groups = "drop")
```

```{r}
# Checking the data
print(or_type1_byquarters)
head(or_type1_byquarters)
tail(or_type1_byquarters)
```

#### Operational Risk Type 2

```{r}
# Grouping Operational Risk Type 2 by months
or_type2_bymonths <- or_type2 %>% 
  mutate(YearMonth = format(Date, "%Y-%m")) %>%
  group_by(YearMonth) %>% 
  summarise(Frequency_Monthly = n())
print(or_type2_bymonths)
or_type2_bymonths <- as.data.frame(or_type2_bymonths)
head(or_type2_bymonths)
```
```{r}
# Grouping and formatting as "YYYY-MM-DD" 
# for the last day of the quarter
or_type2_byquarters <- or_type2_bymonths %>%
  mutate(
    Date = ym(YearMonth),                               
    Year = year(Date),                                  
    Quarter = quarter(Date),                             
    EndOfQuarter = case_when(                           
      Quarter == 1 ~ make_date(Year, 3, 31),
      Quarter == 2 ~ make_date(Year, 6, 30),
      Quarter == 3 ~ make_date(Year, 9, 30),
      Quarter == 4 ~ make_date(Year, 12, 31)
    )
  ) %>%
  group_by(EndOfQuarter) %>%
  summarize(Frequency_Quarterly = sum(Frequency_Monthly), 
            .groups = "drop")
or_type2_byquarters <- or_type2_byquarters %>% 
  dplyr:: select(-EndOfQuarter)
```

```{r}
# Checking the data
print(or_type2_byquarters)
head(or_type2_byquarters)
tail(or_type2_byquarters)
```
#### Operational Risk Type 3

```{r}
# Grouping Operational Risk Type 3 by months
or_type3_bymonths <- or_type3 %>% 
  mutate(YearMonth = format(Date, "%Y-%m")) %>%
  group_by(YearMonth) %>% 
  summarise(Frequency_Monthly = n())
print(or_type3_bymonths)
or_type3_bymonths <- as.data.frame(or_type3_bymonths)
head(or_type3_bymonths)
```
```{r}
# Grouping and formatting as "YYYY-MM-DD" 
# for the last day of the quarter
or_type3_byquarters <- or_type3_bymonths %>%
  mutate(
    Date = ym(YearMonth),                                
    Year = year(Date),                                  
    Quarter = quarter(Date),                             
    EndOfQuarter = case_when(                            
      Quarter == 1 ~ make_date(Year, 3, 31),
      Quarter == 2 ~ make_date(Year, 6, 30),
      Quarter == 3 ~ make_date(Year, 9, 30),
      Quarter == 4 ~ make_date(Year, 12, 31)
    )
  ) %>%
  group_by(EndOfQuarter) %>%
  summarize(Frequency_Quarterly = sum(Frequency_Monthly), 
            .groups = "drop")

or_type3_byquarters <- or_type3_byquarters %>% 
  dplyr:: select(-EndOfQuarter)
```

```{r}
# Checking the data
print(or_type3_byquarters)
head(or_type3_byquarters)
tail(or_type3_byquarters)
```
#### Operational Risk Type 4

```{r}
# Grouping Operational Risk Type 4 by months
or_type4_bymonths <- or_type4 %>% 
  mutate(YearMonth = format(Date, "%Y-%m")) %>%
  group_by(YearMonth) %>% 
  summarise(Frequency_Monthly = n())
print(or_type4_bymonths)
or_type4_bymonths <- as.data.frame(or_type4_bymonths)
head(or_type4_bymonths)
```

```{r}
# Grouping and formatting as "YYYY-MM-DD" 
# for the last day of the quarter
or_type4_byquarters <- or_type4_bymonths %>%
  mutate(
    Date = ym(YearMonth),                                
    Year = year(Date),                                   
    Quarter = quarter(Date),                           
    EndOfQuarter = case_when(                          
      Quarter == 1 ~ make_date(Year, 3, 31),
      Quarter == 2 ~ make_date(Year, 6, 30),
      Quarter == 3 ~ make_date(Year, 9, 30),
      Quarter == 4 ~ make_date(Year, 12, 31)
    )
  ) %>%
  group_by(EndOfQuarter) %>%
  summarize(Frequency_Quarterly = sum(Frequency_Monthly), .groups = "drop")

or_type4_byquarters <- or_type4_byquarters %>% 
  dplyr:: select(-EndOfQuarter)
```

```{r}
# Checking the data
print(or_type4_byquarters)
head(or_type4_byquarters)
tail(or_type4_byquarters)
```

#### Creating combined data frame of Operational Risk Frequencies (numbers)

```{r}
# Creating combined data frame of 
# Operational Risk Frequencies (numbers)
freq_or_losses <- cbind(or_type1_byquarters, or_type2_byquarters, 
                        or_type3_byquarters, or_type4_byquarters)
colnames(freq_or_losses) <- make.unique(colnames(freq_or_losses))
str(freq_or_losses)
```
```{r}
# Creating "Total_freq" column and calculating total frequencies 
# of all types of Operational Risks
freq_or_losses$Total_freq <- freq_or_losses$Frequency_Quarterly + 
  freq_or_losses$Frequency_Quarterly.1 + 
  freq_or_losses$Frequency_Quarterly.2 + 
  freq_or_losses$Frequency_Quarterly.3
str(freq_or_losses)
```
```{r}
# Filtering data for period Q1-2011 to Q4-2016
freq_or_losses_filtered <- freq_or_losses %>%
  filter(EndOfQuarter >= as.Date("2011-03-31") & 
           EndOfQuarter <= as.Date("2016-12-31"))
head(freq_or_losses_filtered)
tail(freq_or_losses_filtered)

freq_model_data <- cbind(model_data, freq_or_losses_filtered)
```
### Multiple Poisson Regression Model Fitting

The Multiple Poisson Regression Model is an effective method for stress-testing Operational Risk, particularly when the dependent variable represents count data or rates, as it assumes a Poisson distribution. It is essential to assess multicollinearity among the regressors (e.g., using the Variance Inflation Factor, VIF) and verify stationarity (for time-series data) to prevent biased results. Through the application of statistical tests for significance and iterative exploration of independent variable combinations, the model can be fine-tuned to identify the key drivers of Operational Risk.

```{r}
# Creating data frame for modelling
freq_final_df <-as.data.frame(freq_model_data)
```
#### Hypothesis Formulation:
Null Hypothesis (H0): The macroeconomic variables do not have relationships with Operational Risk Losses.
Alternative Hypothesis (Ha): The macroeconomic variables have relationships with Operational Risk Losses.
Setting alpha level = 0.1 (90% confidence level).
Setting acceptable Pseudo R^2 (Coefficient of determination) = 0.35 (35%).


```{r warning=FALSE}
# Function to check stationarity and significance for Model 2 
# using Poisson regression
check_stationarity_significance_model_2 <- function(X, y) {
  # Add constant for the intercept
  X <- as.data.frame(cbind(1, X))  
  colnames(X)[1] <- "(Intercept)"  
  model2 <- glm(y ~ ., data = X, family = poisson()) 
  p_values <- summary(model2)$coefficients[, 4][-1] 
  adf_test <- adf.test(resid(model2)) 
  return(list(p_values = p_values, adf_test = adf_test))
}

# Function to calculate Variance Inflation Factor (VIF) for Model 2
# using Poisson regression
calculate_vif_model_2 <- function(X, y) {
  
  data <- as.data.frame(cbind(X, y = y))
  vif_data <- vif(glm(y ~ ., data = data, family = poisson()))
  return(data.frame(feature = names(vif_data), VIF = vif_data))
}

# Function to find the best model for Model 2 based on feature 
# combinations (Poisson regression)
find_best_model_model_2 <- function(freq_final_df) {
  
  excluded_columns <- c("time_period", "Year_Quarter", 
                        "Date", "Date_2", "Value",
                        "Total_Loss_1", "Total_Loss_2", 
                        "Total_Loss_3", "Total_Loss_4",
                        "OR_Loss_in_assets", "Value_billion", 
                        "Total_or_losses",
                        "Total_or_losses_KZT", "Total_loss_1_KZT", 
                        "Total_loss_2_KZT",
                        "Total_loss_3_KZT", "Total_loss_4_KZT", 
                        "OR_Loss_1_in_assets",
                        "OR_Loss_2_in_assets", "OR_Loss_3_in_assets", 
                        "OR_Loss_4_in_assets", 
                        "Year", "EndOfQuarter", "Quarter", 
                        "Frequency_Quarterly", 
                        "Frequency_Quarterly.1", "Frequency_Quarterly.2",
                        "Frequency_Quarterly.3", "Total_freq")
  X <- freq_final_df[, !colnames(freq_final_df) %in% excluded_columns]
  y <- freq_final_df$Total_freq
  
  best_deviance <- Inf  
  best_model2 <- NULL
  best_features2 <- NULL
  total_combinations <- choose(ncol(X), 3)  
  combination_count <- 0
  
  # Generating combinations of 3 independent variables
  combinations <- combn(names(X), 3, simplify = FALSE)
  
  # Initializing a list to store valid combinations that passed tests
  valid_combinations_list <- list()

  for (i in 1:length(combinations)) {
    combination_count <- combination_count + 1
    selected_features <- X[, combinations[[i]], drop = FALSE]  
    
    # Checking stationarity and significance for Model 2
    test_result <- check_stationarity_significance_model_2(selected_features, y)
    p_values <- test_result$p_values
    adf_test <- test_result$adf_test
    
    # Skipping combinations that don't pass the statistical tests
    if (any(p_values > 0.1) || adf_test$p.value > 0.1) {
      next  
    }
    
    # Checking VIF for Model 2
    vif_test <- calculate_vif_model_2(selected_features, y)
    if (max(vif_test$VIF) > 10) {
      next  
    }
    
    # Fitting the Poisson regression model for Model 2
    selected_features <- as.data.frame(cbind(1, selected_features))  
    colnames(selected_features)[1] <- "(Intercept)" 
    model2 <- glm(y ~ ., data = selected_features, family = poisson())
    deviance <- model2$deviance
    
    # Checking if this model is the best (lowest deviance)
    if (deviance < best_deviance) {
      best_deviance <- deviance
      best_model2 <- model2
      best_features2 <- combinations[[i]]
    }
    
    # Adding valid combination to the list
    valid_combinations_list[[length(valid_combinations_list) + 1]] <- list(
      combination = combinations[[i]],
      p_values = p_values,
      adf_p_value = adf_test$p.value,
      deviance = deviance
    )
  }
  
  # Returning the best model, best features, and valid combinations
  return(list(best_model2 = best_model2, 
              best_features2 = best_features2,
              best_deviance = best_deviance,
              valid_combinations_list = valid_combinations_list,
              valid_combinations = length(valid_combinations_list),
              total_combinations = total_combinations))
}

# Finding the best model for Model 2
best_result_2 <- find_best_model_model_2(freq_final_df)
best_model_2 <- best_result_2$best_model2
best_features_2 <- best_result_2$best_features2
valid_combinations_list <- best_result_2$valid_combinations_list
valid_combinations <- best_result_2$valid_combinations
total_combinations <- best_result_2$total_combinations

# Printing the results
cat("Total number of combinations:", total_combinations, "\n")
cat("Number of valid combinations that passed the statistical tests:", 
    valid_combinations, "\n")

# Printing each valid combination with its details
cat("Valid combinations that passed the statistical tests:\n")
for (i in 1:length(valid_combinations_list)) {
  cat("Combination", i, ":", paste(valid_combinations_list[[i]]$combination, 
                                   collapse = ", "), 
      "\n")
  cat("p-values: ", paste(valid_combinations_list[[i]]$p_values, 
                          collapse = ", "), 
      "\n")
  cat("ADF test p-value: ", valid_combinations_list[[i]]$adf_p_value, 
      "\n")
  cat("Deviance: ", valid_combinations_list[[i]]$deviance, 
      "\n\n")
}

# Printing the best model and features
cat("Best independent variables for Model 2:", 
    paste(best_features_2, collapse = ", "), "\n")
cat("Deviance of the best model for Model 2:", 
    best_result_2$best_deviance, "\n")
print(summary(best_model_2))

```
**Findings:** After generating 1,330 different combinations of macroeconomic variables, 11 combinations of the Multiple Poisson Regression model successfully passed statistical tests and were selected. These models are as follows:

Combination 1:
Variables: USD/KZT exchange rate, Real GDP (transformed), Real Gross Value Added - Electricity (transformed)
Deviance: 21.11691

Combination 2:
Variables: USD/KZT exchange rate, Real Gross Value Added - Electricity (transformed), Real Gross Value Added - Trade (transformed)
Deviance: 21.29723

Combination 3:
Variables: USD/KZT exchange rate, Real Gross Value Added - Electricity (transformed), Real Gross Value Added - Information (transformed)
Deviance: 19.97724

Combination 4:
Variables: USD/KZT exchange rate, Real Gross Value Added - Electricity (transformed), Real Gross Value Added (transformed)
Deviance: 21.29074

Combination 5:
Variables: EUR/KZT exchange rate, Real Gross Value Added - Electricity (transformed), Real Gross Value Added - Information (transformed)
Deviance: 19.70323

Combination 6:
Variables: RUB/KZT exchange rate, Real Gross Value Added (transformed), Real Population Average Monthly Income
Deviance: 15.71598

Combination 7:
Variables: RUB/KZT exchange rate, Real Population Average Monthly Income (transformed), Real Population Average Monthly Expenses (transformed)
Deviance: 15.50418
Combination 8:

Variables: Price for Brent, Real Gross Value Added - Electricity (transformed), Real Gross Value Added - Trade (transformed)
Deviance: 21.95006

Combination 9:
Variables: Price for Brent, Real Gross Value Added - Trade (transformed), Real Population Average Monthly Expenses (transformed)
Deviance: 22.39317

Combination 10:
Variables: Inflation (CPI), Real Gross Value Added - Electricity (transformed), Real Gross Value Added - Information (transformed)
Deviance: 19.96472

Combination 11:
Variables: Inflation (CPI), Real Gross Value Added - Information (transformed), Real Population Average Monthly Expenses (transformed)
Deviance: 21.32715

Best Model Selection
The optimal Multiple Poisson Regression model for predicting the amounts (impact/severity) of Operational Risk Losses is Combination 7, which has the lowest deviance (15.50418) and the highest R². The selected variables are:
RUB/KZT exchange rate
Real Population Average Monthly Income (transformed)
Real Population Average Monthly Expenses (transformed)
All p-values are below the alpha threshold (0.1), confirming the statistical significance of these variables.

**Conclusion:**
Since the null hypothesis is rejected and the alternative hypothesis is accepted, the results indicate that macroeconomic variables significantly impact the frequency (number) of Operational Risk Losses. The selected model provides the most robust and reliable predictions based on statistical performance.

#### Checking Modelling Assumptions of Multiple Poisson Regression Model

#### Multiple Poisson Regression Model 1

```{r}
# Multiple Poisson regression model construction
X <- freq_final_df
y <- freq_final_df$Total_freq

# Fitting a Poisson regression model
mf_poiss_model <- glm(y ~ rurkzt + Rincpop_q_y + Rexppop_q_y, 
                      data = X, family = poisson())

# Calculating pseudo R-squared values
pseudo_r2_values <- pR2(mf_poiss_model)

# Printing the results
summary(mf_poiss_model)
pseudo_r2_values

```
**Findings:** McFadden's R^2 = 0.0767 indicates that the model explains approximately 7.67% of the variance relative to the null model. While this suggests some improvement in model fit, it also highlights potential areas for further enhancement. In contrast, the r²ML (Maximum-likelihood pseudo-R^2) = 0.4754 and r^2CU (Cragg-Uhler/Nagelkerke pseudo-R^2) = 0.4755 offer a more optimistic view, suggesting that about 47.5% of the variation in the frequency of Operational Risk Losses is explained by the selected macroeconomic variables. These latter metrics indicate a more favorable overall fit of the model.

#### Creating correlation matrix

```{r}
kendall_corr5 <- freq_final_df %>% 
  dplyr:: select(rurkzt , Rincpop_q_y, Rexppop_q_y, Total_freq)

# Calculating Kendall's correlation matrix
kendall_corr5 <- cor(kendall_corr5, method = "kendall", 
                    use = "complete.obs")
print(kendall_corr5)
```
```{r fig.align="center", fig.width=6, fig.height=4}
# Visualization Kendall's correlation matrix by correlation plot
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", 
                          "#77AADD", "#4477AA"))
corrplot(kendall_corr5, method = "color", col = col(200),
         type = "upper", order = "hclust",
         addCoef.col = "black", 
         tl.col = "black", tl.srt = 45,
         
)
```
**Findings:**  The independent and dependent variables show moderate negative correlations, implying that as some macroeconomic variables increase, the frequency or severity of Operational Risk Losses tends to decrease, or the reverse. Although the correlation is not strong enough to establish a direct causal relationship, it suggests a moderate inverse relationship. This finding may warrant further investigation and model refinement to achieve more accurate predictions.


#### Linearity Assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = freq_final_df, aes(x = Rincpop_q_y, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "red") +
  labs(title = "Scatterplot of Rincpop_q_y vs. Total_freq", 
       x = "Rincpop_q_y", y = "Total_freq") +
  theme_minimal()
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = freq_final_df, aes(x = rurkzt, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "green") +
  labs(title = "Scatterplot of rurkzt vs. Total_freq", 
       x = "rurkzt", y = "Total_freq") +
  theme_minimal()
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = freq_final_df, aes(x = Rexppop_q_y, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "blue") +
  labs(title = "Scatterplot of Rexppop_q_y  vs. Total_freq", 
       x = "Rexppop_q_y", y = "Total_freq") +
  theme_minimal()
```

**Findings:** It is challenging to confirm the presence of linear relationships between the independent and dependent variables. The linearity assumption assumes a direct, proportional relationship between the predictors (macroeconomic variables) and the response variable (Operational Risk Losses). If this assumption is violated, the model might overlook more complex, non-linear relationships, potentially leading to biased or inefficient predictions. For forecasting Operational Risk, where macroeconomic factors could interact in complex ways with risk losses, disregarding non-linear relationships might result in inaccurate assessments. Stress testing based on a linear model in such cases could produce misleading conclusions about the potential impact and severity of Operational Risk Losses. Further exploration of non-linear models or feature transformations may be required to improve prediction accuracy.

#### Independence assumption

```{r}
# Using Durbin-Watson test (requires car package)
dwtest(mf_poiss_model)
```
**Findings:** The Durbin-Watson (DW) statistic is 1.9546, which is close to 2, indicating that there is no significant autocorrelation in the residuals of the model. The p-value of 0.304 further supports this conclusion, as it provides insufficient evidence to suggest autocorrelation. This suggests that the residuals are independent over time, confirming that the assumption of no autocorrelation holds, which is essential for ensuring the reliability of the model's predictions.

#### Poisson Distribution assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Checking for Poisson Distribution assumption: 
# Plot residuals vs. fitted values
ggplot(data = data.frame(fitted = mf_poiss_model$fitted.values, 
                         residuals = residuals(mf_poiss_model)), 
       aes(x = fitted, y = residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(title = "Residuals vs. Fitted Values (Poisson Distribution Check)", 
       x = "Fitted Values", y = "Residuals") +
  theme_minimal()
```
**Findings:** The residuals are randomly scattered around the horizontal line at 0 in the residual plot, suggesting that the model assumptions are likely met and the model provides a good fit. This lack of any obvious pattern in the residuals is a strong indicator of a well-fitted model, further validating its suitability for stress-testing Operational Risk Losses.

#### Overdispersion assumption

```{r}
# Checking for overdispersion: Comparing the residual deviance
# to the degrees of freedom
deviance <- mf_poiss_model$deviance
df <- mf_poiss_model$df.residual
dispersion <- deviance / df
dispersion
```
**Findings:** The dispersion statistic is approximately 1, indicating that the variance of the residuals aligns with the assumptions of the Poisson model. This suggests that the model is well-suited for the data and that the assumptions regarding the distribution of the dependent variable (Operational Risk Losses frequency) are satisfied. This is crucial for ensuring the reliability of the stress-testing results.


#### Multicollinearity assumption

```{r}
# Checking for Multicollinearity: Variance Inflation Factor (VIF)
vif(mf_poiss_model)
```
**Findings:** The VIF values range from 1 to 8, suggesting moderate multicollinearity. While there is some correlation among the independent variables, the levels are not high enough to severely impact the reliability or interpretation of the regression model. However, it is advisable to monitor multicollinearity in future modeling or predictions to ensure that it does not introduce significant bias or instability.

#### Normality Assumption. Goodness of fit using Pearson residuals

```{r fig.align="center", fig.width=6, fig.height=4}
# Calculating model residuals
pearson_residuals <- residuals(mf_poiss_model, type = "pearson")
qqnorm(pearson_residuals)
qqline(pearson_residuals)

# Creating a 1x2 grid of plots (histogram and Q-Q plot)
par(mfrow = c(1, 2), mar = c(5, 4, 4, 2))

# Histogram of residuals with adjusted bins and axis formatting
hist(
  pearson_residuals,
  breaks = 5,  # Increase the number of bins
  main = "Histogram of Residuals",
  xlab = "Residual Value",
  col = "skyblue",
  border = "black",
  xaxt = "n"
)

# Customize x-axis to remove scientific notation
axis(1, at = pretty(residuals), 
     labels = format(pretty(residuals), 
                                                scientific = FALSE))

# Q-Q plot of residuals
qqnorm(pearson_residuals, main = "Normal Q-Q Plot")
qqline(pearson_residuals, col = "red")

# Reset plotting layout to default
par(mfrow = c(1, 1))
```
**Findings:** The histogram of the residuals appears to follow a normal distribution, confirming that the normality assumption is satisfied for this model. Moreover, the Q-Q plot shows the residuals aligning closely with a straight line, further supporting the validity of the normality assumption. This suggests that the residuals do not exhibit significant deviations from normality, enhancing the reliability of statistical inferences such as hypothesis testing and confidence intervals.

#### Multiple Poisson Regression Model 2

```{r}
# Multiple Poisson regression model construction
X <- freq_final_df
y <- freq_final_df$Total_freq

# Fitting a Poisson regression model
mf_poiss_model2 <- glm(y ~ usdkzt + real_gdp_y + GDD_Elc_R_y, 
                      data = X, family = poisson())

# Calculating pseudo R-squared values
pseudo_r2_values2 <- pR2(mf_poiss_model2)

# Printing the results
summary(mf_poiss_model2)
pseudo_r2_values2

```
**Findings:** McFadden's R^2 = 0.0489 suggests that the model explains about 4.89% of the variance relative to the null model, indicating a slight improvement in fit but leaving room for further refinement. However, the r^2ML (Maximum-likelihood pseudo-R^2) = 0.337 and r^2CU (Cragg-Uhler/Nagelkerke pseudo-R^2) = 0.337 offer a more promising perspective, indicating that approximately 33.7% of the variation in the frequency of Operational Risk Losses can be explained by the selected macroeconomic variables. These metrics suggest that the model provides a better overall fit.

#### Creating correlation matrix

```{r}
kendall_corr6 <- freq_final_df %>% 
  dplyr:: select(usdkzt, real_gdp_y, GDD_Elc_R_y, Total_freq)

# Calculating Kendall's correlation matrix
kendall_corr6 <- cor(kendall_corr6, method = "kendall", 
                    use = "complete.obs")
print(kendall_corr6)
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Visualization Kendall's correlation matrix by correlation plot
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", 
                          "#77AADD", "#4477AA"))
corrplot(kendall_corr6, method = "color", col = col(200),
         type = "upper", order = "hclust",
         addCoef.col = "black", 
         tl.col = "black", tl.srt = 45,
         
)
```
**Findings:**  The independent and dependent variables show moderate negative correlations for real_gdp_y and GDD_Elc_R_y, suggesting that as these macroeconomic variables increase, the frequency or severity of Operational Risk Losses tends to decrease. In contrast, a positive correlation is observed with usdkzt, indicating that as the USD/KZT exchange rate increases, the frequency or severity of Operational Risk Losses tends to rise. While the correlations are not strong enough to establish direct causality, they highlight a moderate inverse relationship that may require further exploration or model adjustments to improve predictive accuracy.

#### Linearity Assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = freq_final_df, aes(x = usdkzt, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "red") +
  labs(title = "Scatterplot of usdkzt vs. Total_freq", 
       x = "usdkzt", y = "Total_freq") +
  theme_minimal()
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = freq_final_df, aes(x = real_gdp_y, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "green") +
  labs(title = "Scatterplot of real_gdp_y vs. Total_freq", 
       x = "real_gdp_y", y = "Total_freq") +
  theme_minimal()
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = freq_final_df, aes(x = GDD_Elc_R_y, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "blue") +
  labs(title = "Scatterplot of GDD_Elc_R_y  vs. Total_freq", 
       x = "GDD_Elc_R_y", y = "Total_freq") +
  theme_minimal()
```

**Findings:** It is challenging to confirm the existence of linear relationships between the independent and dependent variables. The linearity assumption presupposes a simple, proportional relationship between the predictors (macroeconomic variables) and the response variable (Operational Risk Losses). If this assumption is violated, the model may fail to capture more complex, non-linear relationships, potentially leading to biased or inefficient predictions. In the context of Operational Risk forecasting, where macroeconomic factors may interact in intricate ways with risk losses, overlooking non-linear relationships could result in inaccurate predictions. Stress testing based on a linear model in such scenarios may produce misleading conclusions about the potential impact and severity of Operational Risk Losses. Further investigation into non-linear models or feature transformations may be required to improve prediction accuracy.

#### Independence assumption

```{r}
# Using Durbin-Watson test (requires car package)
dwtest(mf_poiss_model2)
```
**Findings:** The Durbin-Watson (DW) statistic is 2.5634, which is close to 2, indicating no significant autocorrelation in the residuals of the model. The p-value of 0.775 further supports this conclusion, as it provides no strong evidence to suggest autocorrelation is present. This suggests that the residuals are not correlated over time, validating the assumption of no autocorrelation. This is crucial for ensuring the reliability and accuracy of the model's predictions.

#### Poisson Distribution assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Checking for Poisson Distribution assumption: 
# Plot residuals vs. fitted values
ggplot(data = data.frame(fitted = mf_poiss_model2$fitted.values, 
                         residuals = residuals(mf_poiss_model2)), 
       aes(x = fitted, y = residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "green") +
  labs(title = "Residuals vs. Fitted Values (Poisson Distribution Check)", 
       x = "Fitted Values", y = "Residuals") +
  theme_minimal()
```
**Findings:** The residuals are randomly scattered around the horizontal line at 0 in the residual plot, suggesting that the model assumptions are likely met and that the model fits the data well. The absence of any clear pattern in the residuals further supports the idea of a well-fitted model. This strengthens the validity of the model and confirms its appropriateness for stress-testing Operational Risk Losses.

#### Overdispersion assumption

```{r}
# Checking for overdispersion: Comparing the residual deviance 
# to the degrees of freedom
deviance <- mf_poiss_model2$deviance
df <- mf_poiss_model2$df.residual
dispersion <- deviance / df
dispersion
```
**Findings:** The dispersion statistic is approximately 1, indicating that the variance of the residuals aligns with the assumptions of the Poisson model. This suggests that the model is well-suited for the data, and the assumptions about the distribution of the dependent variable (Operational Risk Losses frequency) are satisfied. This consistency is crucial for ensuring the reliability and accuracy of the stress-testing results.


#### Multicollinearity assumption

```{r}
# Checking for Multicollinearity: Variance Inflation Factor (VIF)
vif(mf_poiss_model2)
```
**Findings:** The VIF values range from 2 to 7, indicating moderate multicollinearity. While there is some correlation among the independent variables, the values remain within acceptable limits, suggesting that multicollinearity is not strong enough to significantly impact the reliability or interpretation of the regression model. Nevertheless, it is important to continue monitoring potential multicollinearity issues in future modeling or predictions.

#### Normality Assumption. Goodness of fit using Pearson residuals

```{r fig.align="center", fig.width=6, fig.height=4}
# Calculating model residuals
pearson_residuals <- residuals(mf_poiss_model2, type = "pearson")
qqnorm(pearson_residuals)
qqline(pearson_residuals)

# Creating a 1x2 grid of plots (histogram and Q-Q plot)
par(mfrow = c(1, 2), mar = c(5, 4, 4, 2))

# Histogram of residuals with adjusted bins and axis formatting
hist(
  pearson_residuals,
  breaks = 5,  # Increase the number of bins
  main = "Histogram of Residuals",
  xlab = "Residual Value",
  col = "skyblue",
  border = "black",
  xaxt = "n"
)

# Customize x-axis to remove scientific notation
axis(1, at = pretty(residuals), 
     labels = format(pretty(residuals), 
                                                scientific = FALSE))

# Q-Q plot of residuals
qqnorm(pearson_residuals, main = "Normal Q-Q Plot")
qqline(pearson_residuals, col = "red")

# Reset plotting layout to default
par(mfrow = c(1, 1))
```
**Findings:** The histogram of the residuals appears to follow a normal distribution, confirming that the normality assumption is satisfied for this model. Additionally, the residuals in the Q-Q plot align closely with a straight line, further supporting the normality assumption. This indicates that the model's residuals do not significantly deviate from a normal distribution, which enhances the reliability of statistical inference, including hypothesis testing and confidence intervals.

#### Multiple Poisson Regression Model 3

```{r}
# Multiple Poisson regression model construction
X <- freq_final_df
y <- freq_final_df$Total_freq

# Fitting a Poisson regression model
mf_poiss_model3 <- glm(y ~ usdkzt + GDD_Elc_R_y + GDD_Trd_R_y, 
                      data = X, family = poisson())

# Calculating pseudo R-squared values
pseudo_r2_values3 <- pR2(mf_poiss_model3)

# Printing the results
summary(mf_poiss_model3)
pseudo_r2_values3

```
**Findings:** McFadden's R^2 = 0.048 indicates that the model explains about 4.8% of the variance compared to the null model, showing some improvement in fit but suggesting there is still room for enhancement. In contrast, the r^2ML (Maximum-likelihood pseudo-R^2) = 0.332 and r^2CU (Cragg-Uhler/Nagelkerke pseudo-R^2) = 0.332 provide a more favorable assessment, indicating that approximately 33.2% of the variation in the frequency of Operational Risk Losses is explained by the selected macroeconomic variables. These metrics suggest a better overall fit for the model.

#### Creating correlation matrix

```{r}
kendall_corr7 <- freq_final_df %>% 
  dplyr:: select(usdkzt, GDD_Elc_R_y, GDD_Trd_R_y, Total_freq)

# Calculating Kendall's correlation matrix
kendall_corr7 <- cor(kendall_corr7, method = "kendall", 
                    use = "complete.obs")
print(kendall_corr7)
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Visualization Kendall's correlation matrix by correlation plot
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", 
                          "#77AADD", "#4477AA"))
corrplot(kendall_corr7, method = "color", col = col(200),
         type = "upper", order = "hclust",
         addCoef.col = "black", 
         tl.col = "black", tl.srt = 45,
         
)
```
**Findings:**  The independent and dependent variables exhibit moderate negative correlations for GDD_Trd_R_y and GDD_Elc_R_y, while showing a positive correlation with usdkzt. This suggests that as certain macroeconomic variables increase, the frequency or severity of Operational Risk Losses tends to decrease, and vice versa. Although the correlation is not strong enough to establish a direct causal relationship, it indicates a moderate inverse association, which may require further investigation or refinements in the model to improve prediction accuracy.

#### Linearity Assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = freq_final_df, aes(x = usdkzt, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "red") +
  labs(title = "Scatterplot of usdkzt vs. Total_freq", 
       x = "usdkzt", y = "Total_freq") +
  theme_minimal()
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = freq_final_df, aes(x = GDD_Elc_R_y, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "green") +
  labs(title = "Scatterplot of GDD_Elc_R_y vs. Total_freq", 
       x = "GDD_Elc_R_y", y = "Total_freq") +
  theme_minimal()
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = freq_final_df, aes(x = GDD_Trd_R_y, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "blue") +
  labs(title = "Scatterplot of GDD_Trd_R_y  vs. Total_freq", 
       x = "GDD_Trd_R_y", y = "Total_freq") +
  theme_minimal()
```

**Findings:** It is challenging to confirm the presence of linear relationships between the independent and dependent variables. The linearity assumption posits a straightforward, proportional relationship between the predictors (macroeconomic variables) and the response variable (Operational Risk Losses). If this assumption is violated, the model may fail to capture more complex, non-linear relationships, leading to biased or inefficient predictions. In the context of Operational Risk forecasting, where macroeconomic factors might interact in complex ways with risk losses, overlooking non-linear relationships could result in inaccurate assessments. Stress testing based on a linear model under these conditions could lead to misleading conclusions about the potential impact and severity of Operational Risk Losses. Further exploration of non-linear models or feature transformations may be needed to improve prediction accuracy.

#### Independence assumption

```{r}
# Using Durbin-Watson test (requires car package)
dwtest(mf_poiss_model3)
```
**Findings:** The Durbin-Watson (DW) statistic is 2.5936, which is close to 2, indicating that there is no significant autocorrelation in the residuals of the model. The p-value of 0.7953 further supports this conclusion, as it provides insufficient evidence to suggest the presence of autocorrelation. This suggests that the residuals are not correlated over time, and the assumption of no autocorrelation holds, which is important for ensuring the reliability and accuracy of the model's predictions.

#### Poisson Distribution assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Checking for Poisson Distribution assumption: 
# Plot residuals vs. fitted values
ggplot(data = data.frame(fitted = mf_poiss_model3$fitted.values, 
                         residuals = residuals(mf_poiss_model3)), 
       aes(x = fitted, y = residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "green") +
  labs(title = "Residuals vs. Fitted Values (Poisson Distribution Check)", 
       x = "Fitted Values", y = "Residuals") +
  theme_minimal()
```
**Findings:** The residuals are randomly scattered around the horizontal line at 0 in the residual plot, indicating that the model assumptions are likely met, and the model provides a good fit. This lack of any obvious pattern in the residuals is a key indicator of a well-fitted model. It helps confirm the validity of the model and supports its appropriateness for stress-testing Operational Risk Losses.

#### Overdispersion assumption

```{r}
# Checking for overdispersion: Comparing the residual deviance 
# to the degrees of freedom
deviance <- mf_poiss_model3$deviance
df <- mf_poiss_model3$df.residual
dispersion <- deviance / df
dispersion
```
**Findings:** The dispersion statistic is approximately 1, indicating that the variance of the residuals aligns with the assumptions of the Poisson model. This suggests that the model is appropriate for the data and that the assumptions regarding the distribution of the dependent variable (frequency of Operational Risk Losses) are met. This is crucial for ensuring the reliability of the stress-testing results.


#### Multicollinearity assumption

```{r}
# Checking for Multicollinearity: Variance Inflation Factor (VIF)
vif(mf_poiss_model3)
```
**Findings:** The VIF values range from 1 to 4, indicating moderate multicollinearity. While there is some correlation between the independent variables, the values remain within acceptable thresholds, suggesting that multicollinearity is not severe enough to significantly impact the regression model's reliability or interpretation. However, it remains important to monitor and address potential issues in future modeling or predictions.

#### Normality Assumption. Goodness of fit using Pearson residuals

```{r fig.align="center", fig.width=6, fig.height=4}
# Calculating model residuals
pearson_residuals <- residuals(mf_poiss_model3, type = "pearson")
qqnorm(pearson_residuals)
qqline(pearson_residuals)

# Creating a 1x2 grid of plots (histogram and Q-Q plot)
par(mfrow = c(1, 2), mar = c(5, 4, 4, 2))

# Histogram of residuals with adjusted bins and axis formatting
hist(
  pearson_residuals,
  breaks = 5,  # Increase the number of bins
  main = "Histogram of Residuals",
  xlab = "Residual Value",
  col = "skyblue",
  border = "black",
  xaxt = "n"
)

# Customize x-axis to remove scientific notation
axis(1, at = pretty(residuals), 
     labels = format(pretty(residuals), 
                                                scientific = FALSE))

# Q-Q plot of residuals
qqnorm(pearson_residuals, main = "Normal Q-Q Plot")
qqline(pearson_residuals, col = "red")

# Reset plotting layout to default
par(mfrow = c(1, 1))
```
**Findings:** The histogram of the residuals appears approximately normally distributed, confirming that the normality assumption holds for this model. Furthermore, the residuals in the Q-Q plot closely align along a straight line, providing further evidence that the normality assumption is valid. This suggests that the model's residuals do not significantly deviate from a normal distribution, supporting the robustness of statistical inferences, such as hypothesis testing and confidence intervals.

#### Multiple Poisson Regression Model 4

```{r}
# Multiple Poisson regression model construction
X <- freq_final_df
y <- freq_final_df$Total_freq

# Fitting a Poisson regression model
mf_poiss_model4 <- glm(y ~ usdkzt + GDD_Elc_R_y + GDD_Inf_R_y, 
                      data = X, family = poisson())

# Calculating pseudo R-squared values
pseudo_r2_values4 <- pR2(mf_poiss_model4)

# Printing the results
summary(mf_poiss_model4)
pseudo_r2_values4

```
**Findings:** McFadden's R^2 = 0.0545 indicates that the model explains approximately 5.5% of the variance compared to the null model, suggesting some improvement in the model's fit but also highlighting potential for further refinement. In contrast, the r^2ML (Maximum-likelihood pseudo-R^2) = 0.368 and r^2CU (Cragg-Uhler/Nagelkerke pseudo-R^2) = 0.368 provide a more favorable assessment, suggesting that around 33.7% of the variation in the frequency of Operational Risk Losses can be explained by the selected macroeconomic variables. These latter metrics indicate a stronger overall fit of the model.

#### Creating correlation matrix

```{r}
kendall_corr8 <- freq_final_df %>% 
  dplyr:: select(usdkzt, GDD_Elc_R_y, GDD_Inf_R_y, Total_freq)

# Calculating Kendall's correlation matrix
kendall_corr8 <- cor(kendall_corr8, method = "kendall", 
                    use = "complete.obs")
print(kendall_corr8)
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Visualization Kendall's correlation matrix by correlation plot
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", 
                          "#77AADD", "#4477AA"))
corrplot(kendall_corr8, method = "color", col = col(200),
         type = "upper", order = "hclust",
         addCoef.col = "black", 
         tl.col = "black", tl.srt = 45,
         
)
```
**Findings:** The independent and dependent variables show moderate negative correlations for GDD_Elc_R_y and GDD_Inf_R_y, and a positive correlation with usdkzt. This suggests that as certain macroeconomic variables increase, the frequency or severity of Operational Risk Losses tends to decrease, and vice versa. While the correlation is not strong enough to imply a direct causal relationship, it indicates a moderate inverse association. This warrants further investigation and potential refinements to the model to improve predictive accuracy.

#### Linearity Assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = freq_final_df, aes(x = usdkzt, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "red") +
  labs(title = "Scatterplot of usdkzt vs. Total_freq", 
       x = "usdkzt", y = "Total_freq") +
  theme_minimal()
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = freq_final_df, aes(x = GDD_Elc_R_y, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "green") +
  labs(title = "Scatterplot of GDD_Elc_R_y vs. Total_freq", 
       x = "GDD_Elc_R_y", y = "Total_freq") +
  theme_minimal()
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = freq_final_df, aes(x = GDD_Inf_R_y, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "blue") +
  labs(title = "Scatterplot of GDD_Inf_R_y  vs. Total_freq", 
       x = "GDD_Inf_R_y", y = "Total_freq") +
  theme_minimal()
```

**Findings:** The linearity assumption, which posits a direct, proportional relationship between the independent variables (macroeconomic factors) and the dependent variable (Operational Risk Losses), is difficult to confirm. If this assumption is violated, the model may fail to capture more intricate, non-linear relationships, leading to biased or inefficient predictions. Given the potential complexity of interactions between macroeconomic factors and risk losses, relying solely on a linear model might produce misleading conclusions. Therefore, further exploration into non-linear models or feature transformations is recommended to improve prediction accuracy and ensure a more reliable assessment of Operational Risk Losses.

#### Independence assumption

```{r}
# Using Durbin-Watson test (requires car package)
dwtest(mf_poiss_model4)
```
**Findings:** The Durbin-Watson (DW) statistic is 2.5248, which is close to 2, suggesting that there is no significant autocorrelation in the residuals of the model. The p-value of 0.7472 further supports this finding, as it indicates that there is no sufficient evidence to suggest the presence of autocorrelation. This means the residuals are not correlated over time, and the assumption of no autocorrelation holds true, which is essential for ensuring the reliability and validity of the model’s predictions.

#### Poisson Distribution assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Checking for Poisson Distribution assumption: 
# Plot residuals vs. fitted values
ggplot(data = data.frame(fitted = mf_poiss_model4$fitted.values, 
                         residuals = residuals(mf_poiss_model4)), 
       aes(x = fitted, y = residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "green") +
  labs(title = "Residuals vs. Fitted Values (Poisson Distribution Check)", 
       x = "Fitted Values", y = "Residuals") +
  theme_minimal()
```
**Findings:** The residuals are randomly scattered around the horizontal line at 0 in the residual plot, suggesting that the model assumptions are likely met. This lack of an obvious pattern in the residuals is an important indicator of a well-fitted model. It supports the validity of the model and its appropriateness for stress-testing Operational Risk Losses, as it shows that the model is capturing the relationship between the predictors and the response variable effectively.

#### Overdispersion assumption

```{r}
# Checking for overdispersion: Comparing the residual deviance
# to the degrees of freedom
deviance <- mf_poiss_model4$deviance
df <- mf_poiss_model4$df.residual
dispersion <- deviance / df
dispersion
```
**Findings:** The dispersion statistic of approximately 1 indicates that the variance of the residuals aligns with the assumptions of the Poisson model. This suggests that the model is well-suited for the data and that the assumptions regarding the distribution of the dependent variable (Operational Risk Losses frequency) are satisfied. This consistency with the Poisson distribution is crucial for ensuring the reliability and accuracy of the stress-testing results, supporting the validity of the model's predictions.


#### Multicollinearity assumption

```{r}
# Checking for Multicollinearity: Variance Inflation Factor (VIF)
vif(mf_poiss_model4)
```
**Findings:** The VIF values ranging between 1 and 4 indicate moderate multicollinearity, which suggests that while there is some correlation between the independent variables, it is not severe enough to significantly impact the reliability or interpretation of the regression model. However, it remains important to monitor these correlations in future modeling and predictions, as even moderate multicollinearity can sometimes affect the stability of regression coefficients or lead to overfitting. Further analysis or potential adjustments may be necessary for refining the model.

#### Normality Assumption. Goodness of fit using Pearson residuals

```{r fig.align="center", fig.width=6, fig.height=4}
# Calculating model residuals
pearson_residuals <- residuals(mf_poiss_model4, type = "pearson")
qqnorm(pearson_residuals)
qqline(pearson_residuals)

# Creating a 1x2 grid of plots (histogram and Q-Q plot)
par(mfrow = c(1, 2), mar = c(5, 4, 4, 2))

# Histogram of residuals with adjusted bins and axis formatting
hist(
  pearson_residuals,
  breaks = 5,  # Increase the number of bins
  main = "Histogram of Residuals",
  xlab = "Residual Value",
  col = "skyblue",
  border = "black",
  xaxt = "n"
)

# Customize x-axis to remove scientific notation
axis(1, at = pretty(residuals), 
     labels = format(pretty(residuals), 
                                                scientific = FALSE))

# Q-Q plot of residuals
qqnorm(pearson_residuals, main = "Normal Q-Q Plot")
qqline(pearson_residuals, col = "red")

# Reset plotting layout to default
par(mfrow = c(1, 1))
```
**Findings:** The histogram of the residuals being normally distributed, but the residuals in the Q-Q plot forming a not straight line, confirms that the normality assumption does not hold for the model. This indicates that the residuals deviate from a normal distribution, which is crucial for ensuring the validity of statistical inference, such as hypothesis testing and confidence intervals.


#### Multiple Poisson Regression Model 5

```{r}
# Multiple Poisson regression model construction
X <- freq_final_df
y <- freq_final_df$Total_freq

# Fitting a Poisson regression model
mf_poiss_model5 <- glm(y ~ usdkzt +GDD_Elc_R_y + GDD_R_y, 
                      data = X, family = poisson())

# Calculating pseudo R-squared values
pseudo_r2_values5 <- pR2(mf_poiss_model5)

# Printing the results
summary(mf_poiss_model5)
pseudo_r2_values5

```
**Findings:** McFadden's R^2 of 0.048 indicates that the model explains only about 4.8% of the variance, showing some improvement over the null model but suggesting that there is substantial room for further refinement. However, the r^2ML (Maximum-likelihood pseudo-R^2) of 0.332 and r^2CU (Cragg-Uhler/Nagelkerke pseudo-R^2) of 0.332 indicate a more favorable outcome, explaining about 33.2% of the variation in the frequency of Operational Risk Losses. These latter metrics imply a better overall fit of the model, suggesting that the selected macroeconomic variables account for a significant portion of the variation in the response.

#### Creating correlation matrix

```{r}
kendall_corr9 <- freq_final_df %>% 
  dplyr:: select(usdkzt, GDD_Elc_R_y, GDD_R_y, Total_freq)

# Calculating Kendall's correlation matrix
kendall_corr9 <- cor(kendall_corr9, method = "kendall", 
                    use = "complete.obs")
print(kendall_corr9)
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Visualization Kendall's correlation matrix by correlation plot
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", 
                          "#77AADD", "#4477AA"))
corrplot(kendall_corr9, method = "color", col = col(200),
         type = "upper", order = "hclust",
         addCoef.col = "black", 
         tl.col = "black", tl.srt = 45,
         
)
```
**Findings:** The independent and dependent variables exhibit moderate negative correlations for variables such as GDD_Elc_R_y and GDD_R_y, indicating that as these macroeconomic variables increase, the frequency or severity of Operational Risk Losses tends to decrease. On the other hand, there is a positive correlation with usdkzt, suggesting that as the value of usdkzt rises, the frequency or severity of Operational Risk Losses may increase. Although these correlations are not strong enough to infer direct causality, the observed inverse associations may require further exploration. Refining the model and investigating potential underlying factors could help improve predictive accuracy.

#### Linearity Assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = freq_final_df, aes(x = usdkzt, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "red") +
  labs(title = "Scatterplot of usdkzt vs. Total_freq", 
       x = "usdkzt", y = "Total_freq") +
  theme_minimal()
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = freq_final_df, aes(x = GDD_Elc_R_y, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "green") +
  labs(title = "Scatterplot of GDD_Elc_R_y vs. Total_freq", 
       x = "GDD_Elc_R_y", y = "Total_freq") +
  theme_minimal()
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = freq_final_df, aes(x = GDD_R_y, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "blue") +
  labs(title = "Scatterplot of GDD_R_y  vs. Total_freq", 
       x = "GDD_R_y", y = "Total_freq") +
  theme_minimal()
```

**Findings:** It is challenging to confirm linear relationships between the independent and dependent variables in this model. The assumption of linearity presupposes a direct, proportional relationship between the predictors (macroeconomic variables) and the response variable (Operational Risk Losses). If this assumption does not hold, the model may fail to capture more complex, non-linear relationships, potentially leading to biased or inefficient predictions. Given the complexity of Operational Risk forecasting, where macroeconomic factors may interact in intricate ways with risk losses, ignoring non-linearity could result in inaccurate conclusions. Relying solely on a linear model for stress testing may yield misleading insights into the potential impacts and severity of Operational Risk Losses. Further exploration of non-linear models, feature transformations, or interactions between variables may be needed to enhance prediction accuracy and provide more robust assessments.

#### Independence assumption

```{r}
# Using Durbin-Watson test (requires car package)
dwtest(mf_poiss_model5)
```
**Findings:** The Durbin-Watson (DW) statistic is 2.5736, which is close to 2, indicating that there is no significant autocorrelation in the residuals of the model. The p-value of 0.7847 reinforces this conclusion, as it provides insufficient evidence to suggest the presence of autocorrelation. This suggests that the residuals are not correlated over time, and the assumption of no autocorrelation holds, which is crucial for ensuring the reliability and accuracy of the model's predictions in stress-testing Operational Risk Losses.

#### Poisson Distribution assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Checking for Poisson Distribution assumption: 
# Plot residuals vs. fitted values
ggplot(data = data.frame(fitted = mf_poiss_model5$fitted.values, 
                         residuals = residuals(mf_poiss_model5)), 
       aes(x = fitted, y = residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "green") +
  labs(title = "Residuals vs. Fitted Values (Poisson Distribution Check)", 
       x = "Fitted Values", y = "Residuals") +
  theme_minimal()
```
**Findings:** The residuals are randomly scattered around the horizontal line at 0 in the residual plot, which suggests that the model assumptions are likely met and that the model provides a good fit. The lack of any obvious pattern in the residuals is an important indicator of a well-fitted model. This strengthens the confidence in the validity of the model and its appropriateness for accurately stress-testing Operational Risk Losses.

#### Overdispersion assumption

```{r}
# Checking for overdispersion: Comparing the residual deviance 
# to the degrees of freedom
deviance <- mf_poiss_model5$deviance
df <- mf_poiss_model5$df.residual
dispersion <- deviance / df
dispersion
```
**Findings:** The dispersion statistic being approximately 1 indicates that the variance of the residuals aligns with the assumptions of the Poisson model. This suggests that the model is appropriate for the data and that the assumptions regarding the distribution of the dependent variable (Operational Risk Losses frequency) are met. This consistency is crucial for ensuring the reliability and accuracy of the stress-testing results.


#### Multicollinearity assumption

```{r}
# Checking for Multicollinearity: Variance Inflation Factor (VIF)
vif(mf_poiss_model5)
```
**Findings:** The VIF values ranging from 2 to 6 suggest moderate multicollinearity among the independent variables. While this level of multicollinearity is not severe enough to compromise the reliability or interpretation of the regression model, it is important to monitor the situation. If multicollinearity increases in future iterations, it could affect the stability of the model and the significance of individual predictors. It might be useful to explore methods such as variable selection or regularization if multicollinearity becomes a more significant concern.

#### Normality Assumption. Goodness of fit using Pearson residuals

```{r fig.align="center", fig.width=6, fig.height=4}
# Calculating model residuals
pearson_residuals <- residuals(mf_poiss_model5, type = "pearson")
qqnorm(pearson_residuals)
qqline(pearson_residuals)

# Creating a 1x2 grid of plots (histogram and Q-Q plot)
par(mfrow = c(1, 2), mar = c(5, 4, 4, 2))

# Histogram of residuals with adjusted bins and axis formatting
hist(
  pearson_residuals,
  breaks = 5,  # Increase the number of bins
  main = "Histogram of Residuals",
  xlab = "Residual Value",
  col = "skyblue",
  border = "black",
  xaxt = "n"
)

# Customize x-axis to remove scientific notation
axis(1, at = pretty(residuals), 
     labels = format(pretty(residuals), 
                                                scientific = FALSE))

# Q-Q plot of residuals
qqnorm(pearson_residuals, main = "Normal Q-Q Plot")
qqline(pearson_residuals, col = "red")

# Reset plotting layout to default
par(mfrow = c(1, 1))
```
**Findings:** The histogram of the residuals and the Q-Q plot both indicate that the residuals are approximately normally distributed. This confirms that the normality assumption is satisfied for the model. As a result, the model's residuals do not exhibit significant deviations from a normal distribution, which is important for the validity of statistical inferences such as hypothesis testing and the construction of confidence intervals. This provides additional support for the reliability of the model and its appropriateness for making predictions and drawing conclusions in the context of stress-testing Operational Risk Losses.

#### Multiple Poisson Regression Model 6

```{r}
# Multiple Poisson regression model construction
X <- freq_final_df
y <- freq_final_df$Total_freq

# Fitting a Poisson regression model
mf_poiss_model6 <- glm(y ~ eurkzt + GDD_Elc_R_y + GDD_Inf_R_y, 
                      data = X, family = poisson())

# Calculating pseudo R-squared values
pseudo_r2_values6 <- pR2(mf_poiss_model6)

# Printing the results
summary(mf_poiss_model6)
pseudo_r2_values6

```
**Findings:** McFadden's R^2 = 0.056 suggests that the model explains about 5.6% of the variance in comparison to the null model, which indicates modest improvement in the model fit but also highlights the potential for further refinement. However, the r^2ML (Maximum-likelihood pseudo-R^2) = 0.375 and r^2CU (Cragg-Uhler/Nagelkerke pseudo-R^2) = 0.375 offer a more promising outlook, suggesting that about 37.5% of the variation in the frequency of Operational Risk Losses is explained by the selected macroeconomic variables. These higher pseudo-R^2 values suggest that the model provides a much better fit overall and that the macroeconomic variables have a meaningful impact on predicting Operational Risk Losses.

#### Creating correlation matrix

```{r}
kendall_corr10 <- freq_final_df %>% 
  dplyr:: select(eurkzt, GDD_Elc_R_y, GDD_Inf_R_y, Total_freq)

# Calculating Kendall's correlation matrix
kendall_corr10 <- cor(kendall_corr10, method = "kendall", 
                    use = "complete.obs")
print(kendall_corr10)
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Visualization Kendall's correlation matrix by correlation plot
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", 
                          "#77AADD", "#4477AA"))
corrplot(kendall_corr10, method = "color", col = col(200),
         type = "upper", order = "hclust",
         addCoef.col = "black", 
         tl.col = "black", tl.srt = 45,
         
)
```
**Findings:** The independent and dependent variables show moderate negative correlations between GDD_Elc_R_y and GDD_Inf_R_y with Operational Risk Losses, while there is a positive correlation with eurkzt. This suggests that as certain macroeconomic factors (such as GDD_Elc_R_y and GDD_Inf_R_y) increase, the frequency or severity of Operational Risk Losses tends to decrease, while the opposite might occur for eurkzt. While the correlation is not strong enough to establish a direct causal relationship, it does indicate a moderate inverse association. This could be an area worth exploring further or refining in the model to improve predictive accuracy and better understand the dynamics between these variables and Operational Risk Losses.

#### Linearity Assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable
# and the dependent variable
ggplot(data = freq_final_df, aes(x = eurkzt, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "red") +
  labs(title = "Scatterplot of eurkzt vs. Total_freq", 
       x = "eurkzt", y = "Total_freq") +
  theme_minimal()
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable
# and the dependent variable
ggplot(data = freq_final_df, aes(x = GDD_Elc_R_y, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "green") +
  labs(title = "Scatterplot of GDD_Elc_R_y vs. Total_freq", 
       x = "GDD_Elc_R_y", y = "Total_freq") +
  theme_minimal()
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = freq_final_df, aes(x = GDD_Inf_R_y, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "blue") +
  labs(title = "Scatterplot of GDD_Inf_R_y  vs. Total_freq", 
       x = "GDD_Inf_R_y", y = "Total_freq") +
  theme_minimal()
```

**Findings:** The linearity assumption, which posits a straightforward proportional relationship between the macroeconomic variables and Operational Risk Losses, seems difficult to confirm. If this assumption is violated, the model may fail to capture more intricate, non-linear relationships, potentially leading to biased or inefficient predictions. In the context of Operational Risk forecasting, where macroeconomic factors might interact in complex ways with risk losses, disregarding non-linear dynamics could lead to inaccurate risk assessments. Stress testing with a linear model under such circumstances may yield misleading results regarding the impact and severity of Operational Risk Losses. Exploring non-linear models or applying feature transformations could enhance prediction accuracy and provide more reliable insights for stress-testing and forecasting.

#### Independence assumption

```{r}
# Using Durbin-Watson test (requires car package)
dwtest(mf_poiss_model6)
```
**Findings:** The Durbin-Watson (DW) statistic is 2.5196, which is close to 2, indicating no significant autocorrelation in the residuals. The p-value of 0.745 further supports this conclusion, as it provides insufficient evidence to suggest the presence of autocorrelation. This suggests that the residuals are not correlated over time, confirming that the assumption of no autocorrelation holds. This is crucial for ensuring that the model's predictions are reliable and that the model’s assumptions are properly met.

#### Poisson Distribution assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Checking for Poisson Distribution assumption: 
# Plot residuals vs. fitted values
ggplot(data = data.frame(fitted = mf_poiss_model6$fitted.values, 
                         residuals = residuals(mf_poiss_model6)), 
       aes(x = fitted, y = residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "green") +
  labs(title = "Residuals vs. Fitted Values (Poisson Distribution Check)", 
       x = "Fitted Values", y = "Residuals") +
  theme_minimal()
```
**Findings:** The residuals are randomly scattered around the horizontal line at 0 in the residual plot, suggesting that the model assumptions are likely met. This random distribution without any obvious pattern indicates that the model fits the data well. It confirms the validity of the model and its appropriateness for stress-testing Operational Risk Losses, as there is no evidence of model misspecification or underlying issues.

#### Overdispersion assumption

```{r}
# Checking for overdispersion: Comparing the residual deviance 
# to the degrees of freedom
deviance <- mf_poiss_model6$deviance
df <- mf_poiss_model6$df.residual
dispersion <- deviance / df
dispersion
```
**Findings:** The dispersion statistic being approximately 1 indicates that the variance of the residuals aligns with the assumptions of the Poisson model. This confirms that the model is suitable for the data, and the assumptions regarding the distribution of the dependent variable (frequency of Operational Risk Losses) are satisfied. This consistency ensures the reliability of the stress-testing results, supporting the validity of the model's predictions.


#### Multicollinearity assumption

```{r}
# Checking for Multicollinearity: Variance Inflation Factor (VIF)
vif(mf_poiss_model6)
```
**Findings:** The VIF values ranging from 1 to 4 suggest moderate multicollinearity, indicating that while some correlation exists between the independent variables, it is not severe enough to materially impact the reliability or interpretation of the regression model. This level of multicollinearity is generally acceptable, but it’s still advisable to monitor for potential issues in future modeling or predictions. Ensuring that collinearity doesn't escalate in more complex models will help maintain the model's robustness and accuracy.

#### Normality Assumption. Goodness of fit using Pearson residuals

```{r fig.align="center", fig.width=6, fig.height=4}
# Calculating model residuals
pearson_residuals <- residuals(mf_poiss_model6, type = "pearson")
qqnorm(pearson_residuals)
qqline(pearson_residuals)

# Creating a 1x2 grid of plots (histogram and Q-Q plot)
par(mfrow = c(1, 2), mar = c(5, 4, 4, 2))

# Histogram of residuals with adjusted bins and axis formatting
hist(
  pearson_residuals,
  breaks = 5,  # Increase the number of bins
  main = "Histogram of Residuals",
  xlab = "Residual Value",
  col = "skyblue",
  border = "black",
  xaxt = "n"
)

# Customize x-axis to remove scientific notation
axis(1, at = pretty(residuals), 
     labels = format(pretty(residuals), 
                                                scientific = FALSE))

# Q-Q plot of residuals
qqnorm(pearson_residuals, main = "Normal Q-Q Plot")
qqline(pearson_residuals, col = "red")

# Reset plotting layout to default
par(mfrow = c(1, 1))
```
**Findings:** The histogram of the residuals being normally distributed, but the residuals not forming a straight line in the Q-Q plot, confirms that the normality assumption is not fully met for this model. It suggests that the model’s residuals exhibit deviations, not supporting the overall validity and accuracy of the model's predictions and conclusions.

#### Multiple Poisson Regression Model 7

```{r}
# Multiple Poisson regression model construction
X <- freq_final_df
y <- freq_final_df$Total_freq

# Fitting a Poisson regression model
mf_poiss_model7 <- glm(y ~ rurkzt + GDD_R_y + Rincpop_q_y, 
                      data = X, family = poisson())

# Calculating pseudo R-squared values
pseudo_r2_values7 <- pR2(mf_poiss_model7)

# Printing the results
summary(mf_poiss_model7)
pseudo_r2_values7
```
**Findings:** McFadden's R^2 of 0.0756 suggests that the model explains only 7.6% of the variance relative to the null model, showing some improvement but still indicating potential for further refinement. However, the r^2ML (Maximum-likelihood pseudo-R^2) and r^2CU (Cragg-Uhler/Nagelkerke pseudo-R^2) values of 0.47 indicate that around 47% of the variation in Operational Risk Losses is explained by the macroeconomic variables included in the model. These metrics suggest a stronger fit and a more meaningful explanatory power for the chosen variables in understanding the frequency of Operational Risk Losses, though improvements could still be made for higher predictive accuracy.

#### Creating correlation matrix

```{r}
kendall_corr11 <- freq_final_df %>% 
  dplyr:: select(rurkzt, GDD_R_y, Rincpop_q_y, Total_freq)

# Calculating Kendall's correlation matrix
kendall_corr11 <- cor(kendall_corr11, method = "kendall", 
                    use = "complete.obs")
print(kendall_corr11)
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Visualization Kendall's correlation matrix by correlation plot
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", 
                          "#77AADD", "#4477AA"))
corrplot(kendall_corr11, method = "color", col = col(200),
         type = "upper", order = "hclust",
         addCoef.col = "black", 
         tl.col = "black", tl.srt = 45,
         
)
```
**Findings:** The moderate negative correlations observed between the independent and dependent variables suggest that as certain macroeconomic variables increase, the frequency or severity of Operational Risk Losses tends to decrease, and vice versa. While the correlation is not strong enough to confirm a direct causal relationship, this inverse association warrants further investigation. Refining the model could help clarify the nature of these relationships and potentially enhance the predictive accuracy for Operational Risk Losses.

#### Linearity Assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable
# and the dependent variable
ggplot(data = freq_final_df, aes(x = rurkzt, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "red") +
  labs(title = "Scatterplot of rurkzt vs. Total_freq", 
       x = "rurkzt", y = "Total_freq") +
  theme_minimal()
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable
# and the dependent variable
ggplot(data = freq_final_df, aes(x = GDD_R_y, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "green") +
  labs(title = "Scatterplot of GDD_R_y vs. Total_freq", 
       x = "GDD_R_y", y = "Total_freq") +
  theme_minimal()
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = freq_final_df, aes(x = Rincpop_q_y, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "blue") +
  labs(title = "Scatterplot of Rincpop_q_y  vs. Total_freq", 
       x = "Rincpop_q_y", y = "Total_freq") +
  theme_minimal()
```

**Findings:** The difficulty in confirming the presence of linear relationships between the independent and dependent variables suggests that the linearity assumption might not hold. The assumption of linearity presumes a proportional relationship between the predictors (macroeconomic variables) and the response variable (Operational Risk Losses). If violated, the model may fail to capture complex, non-linear relationships, leading to biased or inefficient predictions. For Operational Risk forecasting, where macroeconomic factors might interact non-linearly with risk losses, relying solely on linear models could result in inaccurate forecasts. To improve prediction accuracy and more effectively stress-test Operational Risk Losses, it may be worthwhile to explore non-linear models or consider feature transformations to better capture these complex relationships.

#### Independence assumption

```{r}
# Using Durbin-Watson test (requires car package)
dwtest(mf_poiss_model7)
```
**Findings:** The Durbin-Watson (DW) statistic of 2.1286, which is close to 2, suggests that there is no significant autocorrelation in the residuals of the model. The p-value of 0.4345 further supports this conclusion, indicating that there is insufficient evidence to suggest the presence of autocorrelation. This implies that the residuals are not correlated over time, confirming that the assumption of no autocorrelation holds. This is an important result, as it suggests the model's predictions are reliable and free from the bias that could be introduced by autocorrelated residuals.

#### Poisson Distribution assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Checking for Poisson Distribution assumption:
# Plot residuals vs. fitted values
ggplot(data = data.frame(fitted = mf_poiss_model7$fitted.values, 
                         residuals = residuals(mf_poiss_model7)), 
       aes(x = fitted, y = residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "green") +
  labs(title = "Residuals vs. Fitted Values (Poisson Distribution Check)", 
       x = "Fitted Values", y = "Residuals") +
  theme_minimal()
```
**Findings:** The residuals being randomly scattered around the horizontal line at 0 in the residual plot suggest that the model assumptions are likely met. This indicates that the model provides a good fit and that there is no obvious pattern in the residuals, which is a key indicator of a well-fitted model. This random scatter suggests that the model is capturing the underlying relationships without overfitting or systematic errors, helping to confirm the validity and appropriateness of the model for stress-testing Operational Risk Losses.

#### Overdispersion assumption

```{r}
# Checking for overdispersion: Comparing the residual deviance
# to the degrees of freedom
deviance <- mf_poiss_model7$deviance
df <- mf_poiss_model7$df.residual
dispersion <- deviance / df
dispersion
```
**Findings:** The dispersion statistic of 0.7858, which is less than 1, suggests underdispersion in the model. This could indicate that the model is overfitting or that there are excess zero counts in the data. Underdispersion occurs when the variance of the residuals is smaller than expected under the assumed distribution (in this case, the Poisson distribution). This might imply that the model is not capturing some important aspects of the data, and further exploration is needed to check for overfitting or to consider adjustments to better account for zero-inflation or other patterns in the data.


#### Multicollinearity assumption

```{r}
# Checking for Multicollinearity: Variance Inflation Factor (VIF)
vif(mf_poiss_model7)
```
**Findings:** The VIF values ranging between 1 and 4 suggest moderate multicollinearity among the independent variables. This level of correlation between the predictors is not severe enough to drastically impact the reliability or interpretation of the regression model. However, it's important to remain vigilant about potential issues that could arise from multicollinearity in future modeling or predictions. If necessary, further adjustments such as feature selection, regularization, or transformation could help mitigate its effects on model performance.The VIF values are between 1 and 4, indicating moderate multicollinearity. While there is some correlation between the independent variables, the outputs remain within acceptable levels, meaning that multicollinearity is not severe enough to significantly affect the regression model's reliability or interpretation. However, it's still important to monitor and consider potential issues in further modeling or predictions.

#### Normality Assumption. Goodness of fit using Pearson residuals

```{r fig.align="center", fig.width=6, fig.height=4}
# Calculating model residuals
pearson_residuals <- residuals(mf_poiss_model7, type = "pearson")
qqnorm(pearson_residuals)
qqline(pearson_residuals)

# Creating a 1x2 grid of plots (histogram and Q-Q plot)
par(mfrow = c(1, 2), mar = c(5, 4, 4, 2))

# Histogram of residuals with adjusted bins and axis formatting
hist(
  pearson_residuals,
  breaks = 5,  # Increase the number of bins
  main = "Histogram of Residuals",
  xlab = "Residual Value",
  col = "skyblue",
  border = "black",
  xaxt = "n"
)

# Customize x-axis to remove scientific notation
axis(1, at = pretty(residuals), 
     labels = format(pretty(residuals), 
                                                scientific = FALSE))

# Q-Q plot of residuals
qqnorm(pearson_residuals, main = "Normal Q-Q Plot")
qqline(pearson_residuals, col = "red")

# Reset plotting layout to default
par(mfrow = c(1, 1))
```
**Findings:** The histogram of the residuals shows a normal distribution, which confirms that the normality assumption holds for this model. Furthermore, the Q-Q plot displays a straight line, further supporting the conclusion that the residuals are normally distributed. This alignment suggests that the model's residuals do not significantly deviate from a normal distribution, which is crucial for ensuring the reliability of statistical inferences, including hypothesis testing and confidence intervals. Thus, the model appears to meet the assumption of normality, reinforcing its suitability for stress-testing Operational Risk Losses.

#### Multiple Poisson Regression Model 8

```{r}
# Multiple Poisson regression model construction
X <- freq_final_df
y <- freq_final_df$Total_freq

# Fitting a Poisson regression model
mf_poiss_model8 <- glm(y ~ poil + GDD_Elc_R_y + GDD_Trd_R_y, 
                      data = X, family = poisson())

# Calculating pseudo R-squared values
pseudo_r2_values8 <- pR2(mf_poiss_model8)

# Printing the results
summary(mf_poiss_model8)
pseudo_r2_values8

```
**Findings:** McFadden's R^2 of 0.0448 indicates that the model explains only about 4.5% of the variance compared to the null model, implying limited explanatory power and suggesting potential for improvement. However, the r^2ML (Maximum-likelihood pseudo-R^2) of 0.3138 and r^2CU (Cragg-Uhler/Nagelkerke pseudo-R^2) of 0.3137 are significantly higher, indicating that approximately 31.4% of the variation in Operational Risk Losses is explained by the chosen macroeconomic variables. These pseudo-R^2 values suggest a stronger model fit, although further refinements and adjustments may still be needed to enhance prediction accuracy.

#### Creating correlation matrix

```{r}
kendall_corr12 <- freq_final_df %>% 
  dplyr:: select(poil, GDD_Elc_R_y, GDD_Trd_R_y, Total_freq)

# Calculating Kendall's correlation matrix
kendall_corr12 <- cor(kendall_corr12, method = "kendall", 
                    use = "complete.obs")
print(kendall_corr12)
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Visualization Kendall's correlation matrix by correlation plot
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", 
                          "#77AADD", "#4477AA"))
corrplot(kendall_corr12, method = "color", col = col(200),
         type = "upper", order = "hclust",
         addCoef.col = "black", 
         tl.col = "black", tl.srt = 45,
         
)
```
**Findings:** The moderate negative correlations between the independent and dependent variables suggest an inverse relationship, where increases in certain macroeconomic variables are associated with a decrease in the frequency or severity of Operational Risk Losses. While the correlation is not strong enough to establish a definitive causal relationship, this inverse association warrants further exploration. Refining the model or including additional variables could help clarify the nature of these relationships and improve predictive accuracy for Operational Risk Losses.

#### Linearity Assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = freq_final_df, aes(x = poil, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "red") +
  labs(title = "Scatterplot of poil vs. Total_freq", 
       x = "poil", y = "Total_freq") +
  theme_minimal()
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = freq_final_df, aes(x = GDD_Elc_R_y, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "green") +
  labs(title = "Scatterplot of GDD_Elc_R_y vs. Total_freq", 
       x = "GDD_Elc_R_y", y = "Total_freq") +
  theme_minimal()
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = freq_final_df, aes(x = GDD_Trd_R_y, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "blue") +
  labs(title = "Scatterplot of GDD_Trd_R_y  vs. Total_freq", 
       x = "GDD_Trd_R_y", y = "Total_freq") +
  theme_minimal()
```

**Findings:** The difficulty in confirming linear relationships between independent and dependent variables suggests a potential violation of the linearity assumption. If the relationship between macroeconomic variables and Operational Risk Losses is non-linear, using a linear model could result in inaccurate predictions. This could lead to misleading conclusions about the severity and impact of Operational Risk Losses under different macroeconomic conditions. To improve prediction accuracy, it may be beneficial to explore non-linear models or consider transformations of the features to capture more complex interactions between variables.

#### Independence assumption

```{r}
# Using Durbin-Watson test (requires car package)
dwtest(mf_poiss_model8)
```
**Findings:** The Durbin-Watson (DW) statistic of 2.4516, which is close to 2, suggests that there is no significant autocorrelation in the residuals of the model. The p-value of 0.6877 further supports this conclusion, as it indicates insufficient evidence to suggest autocorrelation. This confirms that the residuals are not correlated over time, and the assumption of no autocorrelation holds. This is crucial for ensuring the reliability and validity of the model's predictions.

#### Poisson Distribution assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Checking for Poisson Distribution assumption: 
# Plot residuals vs. fitted values
ggplot(data = data.frame(fitted = mf_poiss_model8$fitted.values, 
                         residuals = residuals(mf_poiss_model8)), 
       aes(x = fitted, y = residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "green") +
  labs(title = "Residuals vs. Fitted Values (Poisson Distribution Check)", 
       x = "Fitted Values", y = "Residuals") +
  theme_minimal()
```
**Findings:** The residuals being randomly scattered around the horizontal line at 0 in the residual plot suggests that the model assumptions are likely met. This indicates that the model provides a good fit to the data, as there is no obvious pattern in the residuals. This is an important indicator of a well-fitted model and reinforces the model's validity, making it appropriate for stress-testing Operational Risk Losses.

#### Overdispersion assumption

```{r}
# Checking for overdispersion: Comparing the residual deviance 
# to the degrees of freedom
deviance <- mf_poiss_model8$deviance
df <- mf_poiss_model8$df.residual
dispersion <- deviance / df
dispersion
```
**Findings:** The dispersion value close to 1 indicates that the Poisson model is appropriate, as there is no significant overdispersion. This suggests that the assumptions regarding the distribution of the dependent variable (Operational Risk Losses frequency) are met, which is crucial for ensuring the reliability of the stress-testing results. The model's appropriateness supports accurate forecasting and assessment of Operational Risk Losses.

#### Multicollinearity assumption

```{r}
# Checking for Multicollinearity: Variance Inflation Factor (VIF)
vif(mf_poiss_model8)
```
**Findings:** The VIF values range between 1 and 8, indicating moderate multicollinearity. While there is some correlation between the independent variables, it is not severe enough to significantly impact the regression model's reliability or interpretation. However, it is important to remain cautious and monitor for potential multicollinearity issues in future modeling or predictions, as it could still influence the precision of the coefficient estimates.

#### Normality Assumption. Goodness of fit using Pearson residuals

```{r fig.align="center", fig.width=6, fig.height=4}
# Calculating model residuals
pearson_residuals <- residuals(mf_poiss_model8, type = "pearson")
qqnorm(pearson_residuals)
qqline(pearson_residuals)

# Creating a 1x2 grid of plots (histogram and Q-Q plot)
par(mfrow = c(1, 2), mar = c(5, 4, 4, 2))

# Histogram of residuals with adjusted bins and axis formatting
hist(
  pearson_residuals,
  breaks = 5,  # Increase the number of bins
  main = "Histogram of Residuals",
  xlab = "Residual Value",
  col = "skyblue",
  border = "black",
  xaxt = "n"
)

# Customize x-axis to remove scientific notation
axis(1, at = pretty(residuals), 
     labels = format(pretty(residuals), 
                                                scientific = FALSE))

# Q-Q plot of residuals
qqnorm(pearson_residuals, main = "Normal Q-Q Plot")
qqline(pearson_residuals, col = "red")

# Reset plotting layout to default
par(mfrow = c(1, 1))
```
**Findings:** The histogram of the residuals shows a near-normal distribution, and the Q-Q plot indicates that the residuals almost follow a straight line. This confirms that the normality assumption is not fully met, suggesting that the model's residuals deviate from a normal distribution. This does not support the validity of statistical inferences, such as hypothesis testing and confidence intervals, reinforcing the reliability of the model for stress-testing Operational Risk Losses.

#### Multiple Poisson Regression Model 9

```{r}
# Multiple Poisson regression model construction
X <- freq_final_df
y <- freq_final_df$Total_freq

# Fitting a Poisson regression model
mf_poiss_model9 <- glm(y ~ poil + GDD_Trd_R_y + Rexppop_q_y , 
                      data = X, family = poisson())

# Calculating pseudo R-squared values
pseudo_r2_values9 <- pR2(mf_poiss_model9)

# Printing the results
summary(mf_poiss_model9)
pseudo_r2_values9

```
**Findings:** McFadden's R^2 of 0.04256 indicates that the model explains about 4.3% of the variance compared to the null model, showing some improvement but suggesting that there is still room for improvement in the model fit. However, the r^2ML (Maximum-likelihood pseudo-R^2) of 0.301 and r^2CU (Cragg-Uhler/Nagelkerke pseudo-R^2) of 0.301 indicate a more favorable model fit, suggesting that approximately 30.1% of the variation in the frequency of Operational Risk Losses is explained by the selected macroeconomic variables. These metrics imply that the model fits the data better and has reasonable explanatory power.

#### Creating correlation matrix

```{r}
kendall_corr13 <- freq_final_df %>% 
  dplyr:: select(poil, GDD_Trd_R_y, Rexppop_q_y, Total_freq)

# Calculating Kendall's correlation matrix
kendall_corr13 <- cor(kendall_corr13, method = "kendall", 
                    use = "complete.obs")
print(kendall_corr13)
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Visualization Kendall's correlation matrix by correlation plot
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", 
                          "#77AADD", "#4477AA"))
corrplot(kendall_corr13, method = "color", col = col(200),
         type = "upper", order = "hclust",
         addCoef.col = "black", 
         tl.col = "black", tl.srt = 45,
         
)
```
**Findings:** The moderate negative correlations between the independent and dependent variables suggest that as certain macroeconomic variables increase, the frequency or severity of Operational Risk Losses tends to decrease, and vice versa. While the correlation is not strong enough to establish a direct causal relationship, this inverse association warrants further exploration. It may be useful to refine the model by considering additional variables, interactions, or non-linear relationships to enhance the predictive accuracy and better capture the underlying dynamics of Operational Risk Losses.

#### Linearity Assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = freq_final_df, aes(x = poil, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "red") +
  labs(title = "Scatterplot of poil vs. Total_freq", 
       x = "poil", y = "Total_freq") +
  theme_minimal()
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable
# and the dependent variable
ggplot(data = freq_final_df, aes(x = GDD_Trd_R_y, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "green") +
  labs(title = "Scatterplot of GDD_Trd_R_y vs. Total_freq", 
       x = "GDD_Trd_R_y", y = "Total_freq") +
  theme_minimal()
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = freq_final_df, aes(x = Rexppop_q_y, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "blue") +
  labs(title = "Scatterplot of Rexppop_q_y  vs. Total_freq", 
       x = "Rexppop_q_y", y = "Total_freq") +
  theme_minimal()
```

**Findings:** The difficulty in confirming linear relationships between the independent and dependent variables highlights a potential issue with the linearity assumption. If the relationship between the predictors (macroeconomic variables) and the response variable (Operational Risk Losses) is not strictly linear, the model may not accurately capture more complex interactions, potentially leading to biased or inefficient predictions. Given that macroeconomic factors can have non-linear interactions with risk losses, it's crucial to explore non-linear models or feature transformations. Such adjustments may improve prediction accuracy and ensure more reliable stress-testing results, ultimately providing more accurate assessments of the potential impact and severity of Operational Risk Losses.

#### Independence assumption

```{r}
# Using Durbin-Watson test (requires car package)
dwtest(mf_poiss_model9)
```
**Findings:** The Durbin-Watson (DW) statistic is 2.4276, which is close to the ideal value of 2. This indicates that there is no significant autocorrelation in the model's residuals. The p-value of 0.662 further supports this conclusion, as it fails to provide sufficient evidence to reject the null hypothesis of no autocorrelation. These results confirm that the residuals are not correlated over time, validating the assumption of no autocorrelation. This is critical for ensuring the reliability and accuracy of the model's predictions.

#### Poisson Distribution assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Checking for Poisson Distribution assumption: 
# Plot residuals vs. fitted values
ggplot(data = data.frame(fitted = mf_poiss_model9$fitted.values, 
                         residuals = residuals(mf_poiss_model9)), 
       aes(x = fitted, y = residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "green") +
  labs(title = "Residuals vs. Fitted Values (Poisson Distribution Check)", 
       x = "Fitted Values", y = "Residuals") +
  theme_minimal()
```
**Findings:** The residual plot shows a random scatter of points around the horizontal zero line, suggesting that the model's assumptions are likely satisfied and it provides a good fit to the data.  This lack of discernible pattern in the residuals is a positive indication of a well-fitted model, supporting its validity and suitability for stress-testing Operational Risk Losses.

#### Overdispersion assumption

```{r}
# Checking for overdispersion: Comparing the residual deviance 
# to the degrees of freedom
deviance <- mf_poiss_model9$deviance
df <- mf_poiss_model9$df.residual
dispersion <- deviance / df
dispersion
```
**Findings:** A dispersion value close to 1 indicates that the Poisson model is appropriate and there is no significant overdispersion. This suggests the model's suitability for the data and confirms that the distributional assumptions for the frequency of Operational Risk Losses are met.  This is crucial for ensuring the reliability of stress-testing results.

#### Multicollinearity assumption

```{r}
# Checking for Multicollinearity: Variance Inflation Factor (VIF)
vif(mf_poiss_model9)
```
**Findings:** Variance Inflation Factors (VIFs) between 2 and 8 suggest moderate multicollinearity. While some correlation exists among the independent variables, its impact on the regression model's reliability and interpretability appears acceptable.  The multicollinearity is not severe enough to pose a significant problem. Nevertheless, it warrants monitoring and consideration in future modeling or predictive exercises.

#### Normality Assumption. Goodness of fit using Pearson residuals

```{r fig.align="center", fig.width=6, fig.height=4}
# Calculating model residuals
pearson_residuals <- residuals(mf_poiss_model9, type = "pearson")
qqnorm(pearson_residuals)
qqline(pearson_residuals)

# Creating a 1x2 grid of plots (histogram and Q-Q plot)
par(mfrow = c(1, 2), mar = c(5, 4, 4, 2))

# Histogram of residuals with adjusted bins and axis formatting
hist(
  pearson_residuals,
  breaks = 5,  # Increase the number of bins
  main = "Histogram of Residuals",
  xlab = "Residual Value",
  col = "skyblue",
  border = "black",
  xaxt = "n"
)

# Customize x-axis to remove scientific notation
axis(1, at = pretty(residuals), 
     labels = format(pretty(residuals), 
                                                scientific = FALSE))

# Q-Q plot of residuals
qqnorm(pearson_residuals, main = "Normal Q-Q Plot")
qqline(pearson_residuals, col = "red")

# Reset plotting layout to default
par(mfrow = c(1, 1))
```
**Findings:** The near-normal distribution of residuals, as shown in the histogram, supports the normality assumption for this model.  This is further corroborated by the Q-Q plot, where the residuals align closely along a straight line.  These findings suggest that deviations from a normal distribution are not substantial, bolstering the reliability of statistical inferences drawn from the model, including hypothesis tests and confidence intervals.

#### Multiple Poisson Regression Model 10

```{r}
# Multiple Poisson regression model construction
X <- freq_final_df
y <- freq_final_df$Total_freq

# Fitting a Poisson regression model
mf_poiss_model10 <- glm(y ~ cpi + GDD_Elc_R_y + GDD_Inf_R_y , 
                      data = X, family = poisson())

# Calculating pseudo R-squared values
pseudo_r2_values10 <- pR2(mf_poiss_model10)

# Printing the results
summary(mf_poiss_model10)
pseudo_r2_values10

```
**Findings:** McFadden's R^2 of 0.0546 indicates the model explains approximately 5.5% of the variance compared to the null model, suggesting some improvement but also highlighting the potential for further refinement.  However, the r^2ML (Maximum-likelihood pseudo-R^2) and r^2CU (Cragg-Uhler/Nagelkerke pseudo-R^2) of 0.368 suggest a more substantial explanatory power, indicating the model accounts for approximately 36.8% of the variation in the frequency of Operational Risk Losses using the selected macroeconomic variables. These latter metrics offer a more optimistic assessment of the model's overall fit.

#### Creating correlation matrix

```{r}
kendall_corr14 <- freq_final_df %>% 
  dplyr:: select(cpi, GDD_Elc_R_y, GDD_Inf_R_y, Total_freq)

# Calculating Kendall's correlation matrix
kendall_corr14 <- cor(kendall_corr14, method = "kendall", 
                    use = "complete.obs")
print(kendall_corr14)
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Visualization Kendall's correlation matrix by correlation plot
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", 
                          "#77AADD", "#4477AA"))
corrplot(kendall_corr14, method = "color", col = col(200),
         type = "upper", order = "hclust",
         addCoef.col = "black", 
         tl.col = "black", tl.srt = 45,
         
)
```
**Findings:** The independent and dependent variables show moderate negative correlations with GDD_Elc_R_y and GDD_Inf_R_y, and a moderate positive correlation with CPI. This suggests a tendency for the frequency or severity of Operational Risk Losses to decrease as the former two macroeconomic variables increase, and to increase with CPI. While these correlations are not strong enough to establish causality, they do reveal moderate inverse and positive associations, respectively, warranting further investigation and potential model refinements to improve predictive accuracy.

#### Linearity Assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable
# and the dependent variable
ggplot(data = freq_final_df, aes(x = cpi, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "red") +
  labs(title = "Scatterplot of cpi vs. Total_freq", 
       x = "cpi", y = "Total_freq") +
  theme_minimal()
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = freq_final_df, aes(x = GDD_Elc_R_y, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "green") +
  labs(title = "Scatterplot of GDD_Elc_R_y vs. Total_freq", 
       x = "GDD_Elc_R_y", y = "Total_freq") +
  theme_minimal()
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = freq_final_df, aes(x = GDD_Inf_R_y, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "blue") +
  labs(title = "Scatterplot of GDD_Inf_R_y  vs. Total_freq", 
       x = "GDD_Inf_R_y", y = "Total_freq") +
  theme_minimal()
```

**Findings:** Establishing linear relationships between the independent and dependent variables is challenging. The linearity assumption posits a direct, proportional relationship between the predictors (macroeconomic variables) and the response variable (Operational Risk Losses).  If this assumption is violated, the model may fail to capture more complex, non-linear relationships, potentially leading to biased or inefficient predictions.  For Operational Risk forecasting, where macroeconomic factors can interact with risk losses in intricate ways, neglecting non-linear relationships could result in inaccurate assessments.  Stress tests based on a linear model under such circumstances may yield misleading conclusions about the potential impact and severity of Operational Risk Losses. Exploring non-linear models or feature transformations may be necessary to improve predictive accuracy.

#### Independence assumption

```{r}
# Using Durbin-Watson test (requires car package)
dwtest(mf_poiss_model10)
```
**Findings:** A Durbin-Watson statistic of 2.4955, close to 2, suggests no significant autocorrelation in the model's residuals.  This is further supported by the high p-value of 0.723, which provides insufficient evidence to reject the null hypothesis of no autocorrelation.  These findings indicate that the residuals are not correlated over time, satisfying the assumption of no autocorrelation and contributing to the reliability of the model's predictions.

#### Poisson Distribution assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Checking for Poisson Distribution assumption: 
# Plot residuals vs. fitted values
ggplot(data = data.frame(fitted = mf_poiss_model10$fitted.values, 
                         residuals = residuals(mf_poiss_model10)), 
       aes(x = fitted, y = residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "green") +
  labs(title = "Residuals vs. Fitted Values (Poisson Distribution Check)", 
       x = "Fitted Values", y = "Residuals") +
  theme_minimal()
```
**Findings:** The random scatter of residuals around the horizontal zero line in the residual plot suggests that the model assumptions are likely met and the model provides a good fit.  This absence of discernible patterns in the residuals is a key indicator of a well-fitted model, supporting its validity and suitability for stress-testing Operational Risk Losses.

#### Overdispersion assumption

```{r}
# Checking for overdispersion: Comparing the residual deviance 
# to the degrees of freedom
deviance <- mf_poiss_model10$deviance
df <- mf_poiss_model10$df.residual
dispersion <- deviance / df
dispersion
```
**Findings:** A dispersion value near 1 indicates that the Poisson model is appropriate, with no significant overdispersion. This suggests the model's suitability for the data and confirms that the distributional assumptions for the frequency of Operational Risk Losses are met, which is crucial for reliable stress-testing results.

#### Multicollinearity assumption

```{r}
# Checking for Multicollinearity: Variance Inflation Factor (VIF)
vif(mf_poiss_model10)
```
**Findings:** VIF values between 1 and 5 suggest some degree of multicollinearity.  While correlation exists among the independent variables, its impact on the regression model's reliability and interpretability appears acceptable. The multicollinearity is not severe enough to pose a significant problem. Nevertheless, monitoring and consideration are warranted in future modeling or prediction efforts.

#### Normality Assumption. Goodness of fit using Pearson residuals

```{r fig.align="center", fig.width=6, fig.height=4}
# Calculating model residuals
pearson_residuals <- residuals(mf_poiss_model10, type = "pearson")
qqnorm(pearson_residuals)
qqline(pearson_residuals)

# Creating a 1x2 grid of plots (histogram and Q-Q plot)
par(mfrow = c(1, 2), mar = c(5, 4, 4, 2))

# Histogram of residuals with adjusted bins and axis formatting
hist(
  pearson_residuals,
  breaks = 5,  # Increase the number of bins
  main = "Histogram of Residuals",
  xlab = "Residual Value",
  col = "skyblue",
  border = "black",
  xaxt = "n"
)

# Customize x-axis to remove scientific notation
axis(1, at = pretty(residuals), 
     labels = format(pretty(residuals), 
                                                scientific = FALSE))

# Q-Q plot of residuals
qqnorm(pearson_residuals, main = "Normal Q-Q Plot")
qqline(pearson_residuals, col = "red")

# Reset plotting layout to default
par(mfrow = c(1, 1))
```
**Findings:** The histogram of residuals suggests a normal distribution, supporting the model's normality assumption. But this is not reinforced by the Q-Q plot, where the residuals does not follow a straight line. These findings indicate that the residuals deviate from a normal distribution, challenging the reliability of statistical inferences, such as hypothesis tests and confidence intervals.

#### Multiple Poisson Regression Model 11

```{r}
# Multiple Poisson regression model construction
X <- freq_final_df
y <- freq_final_df$Total_freq

# Fitting a Poisson regression model
mf_poiss_model11 <- glm(y ~ cpi + GDD_Inf_R_y + Rexppop_q_y, 
                      data = X, family = poisson())

# Calculating pseudo R-squared values
pseudo_r2_values11 <- pR2(mf_poiss_model11)

# Printing the results
summary(mf_poiss_model11)
pseudo_r2_values11

```
**Findings:** A McFadden's R^2 of 0.0478 indicates the model explains approximately 4.8% of the variance compared to the null model, suggesting some improvement but also considerable room for enhancement.  However, the r^2ML (Maximum-likelihood pseudo-R^2) and r^2CU (Cragg-Uhler/Nagelkerke pseudo-R^2) of 0.331 suggest a more substantial explanatory power, indicating the model accounts for roughly 33.1% of the variation in the frequency of Operational Risk Losses using the selected macroeconomic variables. These latter pseudo-R^2 values offer a more optimistic perspective on the model's overall fit.

#### Creating correlation matrix

```{r}
kendall_corr15 <- freq_final_df %>% 
  dplyr:: select(cpi, GDD_Inf_R_y, Rexppop_q_y, Total_freq)

# Calculating Kendall's correlation matrix
kendall_corr15 <- cor(kendall_corr15, method = "kendall", 
                    use = "complete.obs")
print(kendall_corr15)
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Visualization Kendall's correlation matrix by correlation plot
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", 
                          "#77AADD", "#4477AA"))
corrplot(kendall_corr15, method = "color", col = col(200),
         type = "upper", order = "hclust",
         addCoef.col = "black", 
         tl.col = "black", tl.srt = 45,
         
)
```
**Findings:** The independent and dependent variables exhibit moderate negative correlations with GDD_Inf_R_y and Rexppop_q_y, and a moderate positive correlation with CPI. This suggests that as the former two macroeconomic variables increase, the frequency or severity of Operational Risk Losses tends to decrease, while it tends to increase with CPI.  While these correlations don't establish causality, they do reveal moderate inverse and positive associations, respectively, that warrant further investigation and potential model refinements to improve predictive accuracy.

#### Linearity Assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable 
# and the dependent variable
ggplot(data = freq_final_df, aes(x = cpi, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "red") +
  labs(title = "Scatterplot of cpi vs. Total_freq", 
       x = "cpi", y = "Total_freq") +
  theme_minimal()
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable
# and the dependent variable
ggplot(data = freq_final_df, aes(x = GDD_Inf_R_y, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "green") +
  labs(title = "Scatterplot of GDD_Inf_R_y vs. Total_freq", 
       x = "GDD_Inf_R_y", y = "Total_freq") +
  theme_minimal()
```

```{r fig.align="center", fig.width=6, fig.height=4}
# Creating a scatterplot for each independent variable
# and the dependent variable
ggplot(data = freq_final_df, aes(x = Rexppop_q_y, y = Total_freq)) +
  geom_point() + 
  stat_smooth(method = "lm", col = "blue") +
  labs(title = "Scatterplot of Rexppop_q_y  vs. Total_freq", 
       x = "Rexppop_q_y", y = "Total_freq") +
  theme_minimal()
```

**Findings:** Establishing linear relationships between the independent and dependent variables is challenging.  The linearity assumption requires a direct, proportional relationship between the predictors (macroeconomic variables) and the response variable (Operational Risk Losses).  If this assumption is violated, the model may struggle to capture more complex, non-linear relationships, potentially resulting in biased or inefficient predictions.  In Operational Risk forecasting, where macroeconomic factors can interact with risk losses in complex ways, neglecting non-linear relationships could lead to inaccurate assessments.  Stress tests based on a linear model in such scenarios may produce misleading conclusions about the potential impact and severity of Operational Risk Losses.  Exploring non-linear models or feature engineering may be necessary to improve predictive accuracy.

#### Independence assumption

```{r}
# Using Durbin-Watson test (requires car package)
dwtest(mf_poiss_model11)
```
**Findings:** A Durbin-Watson statistic of 2.386, being very close to 2, indicates no significant autocorrelation in the model's residuals.  This is reinforced by the p-value of 0.6182, which provides insufficient evidence to suggest autocorrelation.  These findings imply that the residuals are not correlated over time, satisfying the assumption of no autocorrelation and supporting the reliability of the model's predictions.

#### Poisson Distribution assumption

```{r fig.align="center", fig.width=6, fig.height=4}
# Checking for Poisson Distribution assumption: 
# Plot residuals vs. fitted values
ggplot(data = data.frame(fitted = mf_poiss_model11$fitted.values, 
                         residuals = residuals(mf_poiss_model11)), 
       aes(x = fitted, y = residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "green") +
  labs(title = "Residuals vs. Fitted Values (Poisson Distribution Check)", 
       x = "Fitted Values", y = "Residuals") +
  theme_minimal()
```
**Findings:** The random scatter of residuals around zero in the residual plot suggests the model assumptions are likely met and it provides a good fit.  This lack of discernible pattern is a key indicator of a well-fitted model, supporting its validity and suitability for stress-testing Operational Risk Losses.

#### Overdispersion assumption

```{r}
# Checking for overdispersion: Comparing the residual deviance 
# to the degrees of freedom
deviance <- mf_poiss_model11$deviance
df <- mf_poiss_model11$df.residual
dispersion <- deviance / df
dispersion
```
**Findings:** A dispersion value close to 1 indicates the Poisson model is appropriate, with no significant overdispersion. This suggests the model's suitability for the data and confirms that the distributional assumptions for the frequency of Operational Risk Losses are met, which is crucial for reliable stress-testing.

#### Multicollinearity assumption

```{r}
# Checking for Multicollinearity: Variance Inflation Factor (VIF)
vif(mf_poiss_model11)
```
**Findings:** VIF values between 2 and 5 suggest moderate multicollinearity. While some correlation exists among the independent variables, its impact on the model's reliability and interpretability appears acceptable.  The level of multicollinearity is not severe enough to significantly compromise the model. However, it should be monitored and considered in future modeling or prediction efforts.

#### Normality Assumption. Goodness of fit using Pearson residuals

```{r fig.align="center", fig.width=6, fig.height=4}
# Calculating model residuals
pearson_residuals <- residuals(mf_poiss_model11, type = "pearson")
qqnorm(pearson_residuals)
qqline(pearson_residuals)

# Creating a 1x2 grid of plots (histogram and Q-Q plot)
par(mfrow = c(1, 2), mar = c(5, 4, 4, 2))

# Histogram of residuals with adjusted bins and axis formatting
hist(
  pearson_residuals,
  breaks = 5,  # Increase the number of bins
  main = "Histogram of Residuals",
  xlab = "Residual Value",
  col = "skyblue",
  border = "black",
  xaxt = "n"
)

# Customize x-axis to remove scientific notation
axis(1, at = pretty(residuals), 
     labels = format(pretty(residuals), 
                                                scientific = FALSE))

# Q-Q plot of residuals
qqnorm(pearson_residuals, main = "Normal Q-Q Plot")
qqline(pearson_residuals, col = "red")

# Reset plotting layout to default
par(mfrow = c(1, 1))
```
**Findings:** The histogram of the residuals suggests a normal distribution, supporting the model's normality assumption.  This is further corroborated by the Q-Q plot, where the residuals align closely along a straight line. These findings indicate that the residuals do not deviate substantially from a normal distribution, bolstering the reliability of statistical inferences, including hypothesis tests and confidence intervals.

### Analysis of Mean Squared Error (MSE) and Root Mean Squared Error (RMSE)

```{r}
# Checking Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) 
# for Poisson Regression Model 1
options(scipen = 999)
poisson_residuals <- residuals(mf_poiss_model, type = "response")
mse_poisson_model <- mean(poisson_residuals^2)
mse_poisson_model
rmse_poisson_model <- sqrt(mse_poisson_model)
rmse_poisson_model
deviance_explained <- 1 - (mf_poiss_model$deviance / mf_poiss_model$null.deviance)
deviance_explained
pseudo_r2_values
```
```{r}
# Checking Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) 
# for Poisson Regression Model 2
options(scipen = 999)
poisson_residuals2 <- residuals(mf_poiss_model2, type = "response")
mse_poisson_model2 <- mean(poisson_residuals2^2)
mse_poisson_model2
rmse_poisson_model2 <- sqrt(mse_poisson_model2)
rmse_poisson_model2
deviance_explained2 <- 1 - (mf_poiss_model2$deviance / mf_poiss_model2$null.deviance)
deviance_explained2
pseudo_r2_values2
```
```{r}
# Checking Mean Squared Error (MSE) and Root Mean Squared Error (RMSE)
# for Poisson Regression Model 3
options(scipen = 999)
poisson_residuals3 <- residuals(mf_poiss_model3, type = "response")
mse_poisson_model3 <- mean(poisson_residuals3^2)
mse_poisson_model3
rmse_poisson_model3 <- sqrt(mse_poisson_model3)
rmse_poisson_model3
deviance_explained3 <- 1 - (mf_poiss_model3$deviance / mf_poiss_model3$null.deviance)
deviance_explained3
pseudo_r2_values3
```
```{r}
# Checking Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) 
# for Poisson Regression Model 4
options(scipen = 999)
poisson_residuals4 <- residuals(mf_poiss_model4, type = "response")
mse_poisson_model4 <- mean(poisson_residuals4^2)
mse_poisson_model4
rmse_poisson_model4 <- sqrt(mse_poisson_model4)
rmse_poisson_model4
deviance_explained4 <- 1 - (mf_poiss_model4$deviance / mf_poiss_model4$null.deviance)
deviance_explained4
pseudo_r2_values4
```
```{r}
# Checking Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) 
# for Poisson Regression Model 5
options(scipen = 999)
poisson_residuals5 <- residuals(mf_poiss_model5, type = "response")
mse_poisson_model5 <- mean(poisson_residuals5^2)
mse_poisson_model5
rmse_poisson_model5 <- sqrt(mse_poisson_model5)
rmse_poisson_model5
deviance_explained5 <- 1 - (mf_poiss_model5$deviance / mf_poiss_model5$null.deviance)
deviance_explained5
pseudo_r2_values5
```
```{r}
# Checking Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) 
# for Poisson Regression Model 6
options(scipen = 999)
poisson_residuals6 <- residuals(mf_poiss_model6, type = "response")
mse_poisson_model6 <- mean(poisson_residuals6^2)
mse_poisson_model6
rmse_poisson_model6 <- sqrt(mse_poisson_model6)
rmse_poisson_model6
deviance_explained6 <- 1 - (mf_poiss_model6$deviance / mf_poiss_model6$null.deviance)
deviance_explained6
pseudo_r2_values6
```
```{r}
# Checking Mean Squared Error (MSE) and Root Mean Squared Error (RMSE)
# for Poisson Regression Model 7
options(scipen = 999)
poisson_residuals7 <- residuals(mf_poiss_model7, type = "response")
mse_poisson_model7 <- mean(poisson_residuals7^2)
mse_poisson_model7
rmse_poisson_model7 <- sqrt(mse_poisson_model7)
rmse_poisson_model7
deviance_explained7 <- 1 - (mf_poiss_model7$deviance / mf_poiss_model7$null.deviance)
deviance_explained7
pseudo_r2_values7
```
```{r}
# Checking Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) 
# for Poisson Regression Model 8
options(scipen = 999)
poisson_residuals8 <- residuals(mf_poiss_model8, type = "response")
mse_poisson_model8 <- mean(poisson_residuals8^2)
mse_poisson_model8
rmse_poisson_model8 <- sqrt(mse_poisson_model8)
rmse_poisson_model8
deviance_explained8 <- 1 - (mf_poiss_model8$deviance / mf_poiss_model8$null.deviance)
deviance_explained8
pseudo_r2_values8
```
```{r}
# Checking Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) 
# for Poisson Regression Model 9
options(scipen = 999)
poisson_residuals9 <- residuals(mf_poiss_model9, type = "response")
mse_poisson_model9 <- mean(poisson_residuals9^2)
mse_poisson_model9
rmse_poisson_model9 <- sqrt(mse_poisson_model9)
rmse_poisson_model9
deviance_explained9 <- 1 - (mf_poiss_model9$deviance / mf_poiss_model9$null.deviance)
deviance_explained9
pseudo_r2_values9
```
```{r}
# Checking Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) 
# for Poisson Regression Model 10
options(scipen = 999)
poisson_residuals10 <- residuals(mf_poiss_model10, type = "response")
mse_poisson_model10 <- mean(poisson_residuals10^2)
mse_poisson_model10
rmse_poisson_model10 <- sqrt(mse_poisson_model10)
rmse_poisson_model10
deviance_explained10 <- 1 - (mf_poiss_model10$deviance / mf_poiss_model10$null.deviance)
deviance_explained10
pseudo_r2_values10
```
```{r}
# Checking Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) 
# for Poisson Regression Model 11
options(scipen = 999)
poisson_residuals11 <- residuals(mf_poiss_model11, type = "response")
mse_poisson_model11 <- mean(poisson_residuals11^2)
mse_poisson_model11
rmse_poisson_model11 <- sqrt(mse_poisson_model11)
rmse_poisson_model11
deviance_explained11 <- 1 - (mf_poiss_model11$deviance / mf_poiss_model11$null.deviance)
deviance_explained11
pseudo_r2_values11
```


## Multiple Negative Binomial Model Construction

### Multiple Negative Binomial Model Fitting

The Multiple Negative Binomial Regression Model applied for the same macroeconomic variables chosen for Multiple Poisson Regression Model.

#### Hypothesis Formulation:
Null Hypothesis (H0): The macroeconomic variables do not have relationships with Operational Risk Losses.
Alternative Hypothesis (Ha): The macroeconomic variables have relationships with Operational Risk Losses.
Setting alpha level = 0.1 (90% confidence level).
Setting acceptable Pseudo R^2 (Coefficient of determination) = 0.35 (35%).

```{r warning=FALSE}
# Multiple Poisson Model Construction
nb_model <- glm.nb(Total_freq ~ rurkzt + Rincpop_q_y + GDD_R_y, 
                 data = freq_final_df) 
summary(nb_model)
pseudo_r2_values_nb <- pR2(nb_model)
pseudo_r2_values_nb
```
**Findings:** McFadden's R^2 of 0.0719 indicates the model explains approximately 7.2% of the variance compared to the null model, suggesting some improvement but also highlighting the potential for further refinement.  However, the r^2ML (Maximum-likelihood pseudo-R^2) and r^2CU (Cragg-Uhler/Nagelkerke pseudo-R^2) of 0.4528 suggest a more substantial explanatory power, indicating the model accounts for approximately 45.3% of the variation in the frequency of Operational Risk Losses using the selected macroeconomic variables. These latter metrics offer a more optimistic assessment of the model's overall fit. The null hypothesis is rejected and the alternative hypothesis is accepted, the results indicate that macroeconomic variables significantly impact the frequency (number) of Operational Risk Losses.

```{r}
# Checking Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) 
# for Negative Binomial Regression Model
options(scipen = 999)
nb_model_residual <- residuals(nb_model, type = "response")
mse_nb_model <- mean(nb_model_residual^2)
mse_nb_model
rmse_nb_model <- sqrt(mse_nb_model)
rmse_nb_model
deviance_explained <- 1 - (nb_model$deviance / nb_model$null.deviance)
deviance_explained
pseudo_r2_values_nb
```
### Comparative Analysis of Model Performances

```{r}
# Creating a data frame with the model results
poisson_nb_models <- data.frame(
  Model = c("Multiple Poisson Model 1", "Multiple Poisson Model 2", 
            "Multiple Poisson Model 3", "Multiple Poisson Model 4", 
            "Multiple Poisson Model 5", "Multiple Poisson Model 6", 
            "Multiple Poisson Model 7", "Multiple Poisson Model 8",
            "Multiple Poisson Model 9", "Multiple Poisson Model 10",
            "Multiple Poisson Model 11", "Negative Binomial Model"),
  MSE = c(171.996, 171.996, 173.690, 162.550, 173.382, 160.246, 129.036, 
          178.682, 182.303, 162.554, 173.631, 129.0357),
  RMSE = c(13.115, 13.115, 13.179, 12.750, 13.167, 12.659, 11.359, 13.367, 
           13.502, 12.750, 13.177, 11.359),
  Deviance = c(0.3185, 0.3185, 0.3127, 0.3553, 0.3129, 0.3642, 0.4928,
               0.2916, 0.2773, 0.3557, 0.3117, 0.4928),
  Log_Likelihood = c(-96.038, -96.038, -96.128, -95.468, -96.125, 
                     -95.331, -93.337, -96.454, -96.676, -95.462, -96.143, -93.337),
  McFadden_R2 = c(0.04888, 0.04888, 0.04798, 0.05452, 0.04802, 0.05588, 
                  0.07562, 0.04475, 0.04256, 0.05458, 0.04784, 0.07194),
  R2ML = c(0.3372, 0.3372, 0.3322, 0.3679, 0.3324, 0.3751, 0.4708, 
           0.3138, 0.3010, 0.3683, 0.3314, 0.4528),
  R2CU = c(0.3373, 0.3373, 0.3323, 0.3680, 0.3324, 0.3752, 
           0.4709, 0.3138, 0.3011, 0.3683, 0.3314, 0.4529)
)

kable(poisson_nb_models, format = "markdown", digits = 5, 
      caption = "Poisson and Negative Binomial Model Performance Metrics")
```

### Interim conclusion
Based on the evaluation of key metrics (MSE, RMSE, deviance, pseudo R², and log-likelihood), Poisson Regression Model 7 emerges as the best model for predicting the frequency of Operational Risk Losses. The key points supporting this choice include:

Lowest MSE (129.0357) and RMSE (11.35939): These values indicate the most accurate predictions among all models tested.
Lowest Deviance (0.4928244): Suggests that the model fits the data well.
Highest Pseudo R^2 values:
McFadden’s R^2 = 0.0756,
r^2ML = 0.4708,
r^2CU = 0.4709. These values indicate that the model explains the most variance in the data compared to other models.
Log-likelihood (-93.3372): Higher (less negative) than other models, further supporting the good fit of Poisson Model 7.
The model includes the following significant macroeconomic variables:

rurkzt (RUB KZT exchange rate),
GDD_R_y (Real gross value added, transformed),
Rincpop_q_y (Real population average monthly income, transformed). The p-values for all variables are below alpha = 0.1, indicating statistical significance.
Comparison with Negative Binomial Model:
While the Negative Binomial Model has the lowest MSE and RMSE (129.036 and 11.359), its performance is nearly identical to that of Poisson Model 7:

Both models have the same log-likelihood (-93.337), indicating similar fit in terms of likelihood.
Deviance (0.4928) is the same for both models.
Pseudo R^2: The Negative Binomial model has slightly lower values:
McFadden’s R^2 = 0.07194 (vs. 0.0756 for Poisson Model 7),
r^2ML = 0.4528 and r^2CU = 0.4529 (vs. 0.4708 and 0.4709 for Poisson Model 7).
Although the Negative Binomial model is more robust in handling overdispersion, the Poisson Model 7 still provides comparable performance, with only marginal differences in the metrics. Importantly, Poisson Model 7 demonstrates underdispersion (dispersion value of 0.7858), which may indicate potential overfitting or excess zeros in the data, but does not appear to necessitate the more complex Negative Binomial approach.

Conclusion:
Given the comparable performance of the Poisson and Negative Binomial models, Poisson Regression Model 7 is selected as the best model. It balances predictive accuracy with explanatory power and is simpler to interpret. It successfully incorporates key macroeconomic variables (rurkzt, GDD_R_y, and Rincpop_q_y), which are statistically significant and highly relevant to predicting the frequency of Operational Risk Losses. Further investigation into the underdispersion in Poisson Model 7 is recommended, but overall, it is the most appropriate choice for forecasting taking into account that assumption of linearity is not fully met.

## Regression Model Scenario Forecasting (Stress Testing of Operational Risk)

### Forecasting amounts (impact/severity) of Operational Risk Losses 

#### Creating correlation matrix

```{r fig.align="center", fig.width=6, fig.height=4}
# Visualization Kendall's correlation matrix by correlation plot
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", 
                          "#77AADD", "#4477AA"))
corrplot(kendall_corr1, method = "color", col = col(200),
         type = "upper", order = "hclust",
         addCoef.col = "black", 
         tl.col = "black", tl.srt = 45,
         
)
```
**Findings:** The analysis of correlations between independent variables and the dependent variable, Operational Risk Losses (OR_Loss_in_assets), yields the following insights:

Negative Correlations with OR_Loss_in_assets:
All independent variables exhibit a negative correlation with OR_Loss_in_assets. This suggests that as the values of the independent variables (such as macroeconomic indicators) increase, Operational Risk Losses tend to decrease, or vice versa. This implies that stronger macroeconomic conditions might reduce operational risk losses, potentially due to improved financial stability, risk management, or overall economic resilience.

Relationships between Independent Variables:
GDD_Trn_R_y (GDP growth trend) and GDD_Inf_R_y (GDP inflation) have a moderate positive correlation (0.512). This indicates that GDP growth trends and inflation tend to move in the same direction—when one increases, the other also tends to increase. This makes sense, as strong economic growth may lead to higher inflation or vice versa.
GDD_Inf_R_y and Rincpop_q_y (Real income per capita) show a strong positive correlation (0.664). This suggests that when inflation increases, real income per capita tends to rise as well. This relationship may reflect the impact of inflationary pressure on income distribution or economic dynamics, which could be related to higher operational costs and risk factors.
GDD_Trn_R_y and Rincpop_q_y have a weak positive correlation (0.313), implying that while there is some alignment between GDP growth and real income growth, the relationship is not as strong.

Implications of Negative Correlations with Operational Risk Losses:
The negative correlations between the independent variables and OR_Loss_in_assets suggest that better macroeconomic conditions—characterized by higher GDP growth, inflation, and real income per capita—tend to result in fewer operational risk losses. This could be explained by a more stable business environment and improved financial performance during periods of economic growth.


#### Defining historical minimums and maximums of independent and dependent variables

```{r}
# Reviewing historical minimum values of "GDD_Trn_R_y" variable
GDD_Trn_R_y_min <- min(final_df$GDD_Trn_R_y, na.rm = TRUE)
cat("GDD_Trn_R_y historical minimum is", GDD_Trn_R_y_min)
```
```{r}
# Reviewing historical maximum values of "GDD_Inf_R_y" variable
GDD_Trn_R_y_max <- max(final_df$GDD_Trn_R_y, na.rm = TRUE)
cat("GDD_Trn_R_y_max historical maximum is", GDD_Trn_R_y_max, "\n")
```
```{r}
# Reviewing historical minimum values of "GDD_Trn_R_y" variable
GDD_Inf_R_y_min <- min(final_df$GDD_Inf_R_y, na.rm = TRUE)
cat("GDD_Inf_R_y historical minimum is", GDD_Inf_R_y_min)
```
```{r}
# Reviewing historical maximum values of "GDD_Inf_R_y" variable
GDD_Inf_R_y_max <- max(final_df$GDD_Inf_R_y, na.rm = TRUE)
cat("GDD_Inf_R_y_max historical maximum is", GDD_Inf_R_y_max, "\n")
```
```{r}
# Reviewing historical minimum values of "GDD_Trn_R_y" variable
Rincpop_q_y_min <- min(final_df$Rincpop_q_y, na.rm = TRUE)
cat("Rincpop_q_y historical minimum is", Rincpop_q_y_min)
```
```{r}
# Reviewing historical maximum values of "GDD_Inf_R_y" variable
Rincpop_q_y_max <- max(final_df$Rincpop_q_y, na.rm = TRUE)
cat("Rincpop_q_y_max historical maximum is", Rincpop_q_y_max, "\n")
```

### Defining Scenarios

```{r}
banking_stats$Value <- as.numeric(as.character(banking_stats$Value))
mean_bank_stats <- mean(banking_stats$Value, na.rm = TRUE)
stdev_bank_stats <- sd(banking_stats$Value, na.rm = TRUE)
cat("Mean of Total Assets:", 
    mean_bank_stats, "\n")
cat("Standard deviation of Total Assets:", 
    stdev_bank_stats, "\n")
```


```{r}
# Financial data on Total Assets for the following 4 quarters 2017 
# for forecasting
# Positive Scenario
total_assets_2017_Q1p <- 24255600000
total_assets_2017_Q2p <- 25993960000
total_assets_2017_Q3p <- 27856910000
total_assets_2017_Q4p <- 29853370000

# Negative Scenario
total_assets_2017_Q1n <- 22356410000
total_assets_2017_Q2n <- 22082730000
total_assets_2017_Q3n <- 21812390000
total_assets_2017_Q4n <- 21545360000
```
**Findings:** The projected total asset values for the next 4 quarters were calculated under positive and negative scenarios, in absolute amounts. These values are based on a simple growth-based projection, considering historical volatility.
Positive Scenario: Growth rate = historical mean + 1 standard deviation.
Negative Scenario: Growth rate = historical mean - 1 standard deviation.


```{r}
# Positive Scenario
GDD_Trn_R_y_2017_Q1p <- 5.500
GDD_Trn_R_y_2017_Q2p <- 6.500
GDD_Trn_R_y_2017_Q3p <- 7.200
GDD_Trn_R_y_2017_Q4p <- 7.800

GDD_Inf_R_y_2017_Q1p <- 7.100
GDD_Inf_R_y_2017_Q2p <- 10.000
GDD_Inf_R_y_2017_Q3p <- 15.000
GDD_Inf_R_y_2017_Q4p <- 18.000

Rincpop_q_y_2017_Q1p <- 40.000
Rincpop_q_y_2017_Q2p <- 60.000
Rincpop_q_y_2017_Q3p <- 90.000
Rincpop_q_y_2017_Q4p <- 110.000
```

```{r}
# Negative Scenario
GDD_Trn_R_y_2017_Q1n <- 4.500
GDD_Trn_R_y_2017_Q2n <- 4.000
GDD_Trn_R_y_2017_Q3n <- 3.500
GDD_Trn_R_y_2017_Q4n <- 3.200

GDD_Inf_R_y_2017_Q1n <- 3.000
GDD_Inf_R_y_2017_Q2n <- 1.500
GDD_Inf_R_y_2017_Q3n <- 1.000
GDD_Inf_R_y_2017_Q4n <- -0.500

Rincpop_q_y_2017_Q1n <- -0.000
Rincpop_q_y_2017_Q2n <- -5.000
Rincpop_q_y_2017_Q3n <- -10.000
Rincpop_q_y_2017_Q4n <- -15.000
```


### Forecasting amounts (impact/severity) of Operational Risk Losses with Multiple Linear Regression Model
```{r}
# Summary of the Multiple Linear Regression Model
summary(mfl_model_or)
```

#### Positive scenario

```{r}
# Forecasting share of Operational Risk Losses 
# in Total Assets (Positive scenario)
intercept <- coef(mfl_model_or)["(Intercept)"]
GDD_Trn_R_y_coef <- coef(mfl_model_or)["GDD_Trn_R_y"]
GDD_Inf_R_y_coef <- coef(mfl_model_or)["GDD_Inf_R_y"]
Rincpop_q_y_coef <- coef(mfl_model_or)["Rincpop_q_y"]

# Positive Scenario
GDD_Trn_R_y_2017_Q1p <- 5.500

GDD_Inf_R_y_2017_Q1p <- 7.100

Rincpop_q_y_2017_Q1p <- 40.000


# Forecasting the share of Operational Risk Losses 
# in Total Assets (Positive scenario)
y_hat2017_Q1p <- intercept + GDD_Trn_R_y_coef * GDD_Trn_R_y_2017_Q1p + 
  GDD_Inf_R_y_coef * GDD_Inf_R_y_2017_Q1p +
  Rincpop_q_y_coef * Rincpop_q_y_2017_Q1p

# Printing the forecasted value
cat("Share of Operational Risk Losses (Positive scenario) for Q1-2017:", 
    y_hat2017_Q1p, "\n")

```

```{r}
# Forecasting share of Operational Risk Losses 
# in Total Assets (Positive scenario)
intercept <- coef(mfl_model_or)["(Intercept)"]
GDD_Trn_R_y_coef <- coef(mfl_model_or)["GDD_Trn_R_y"]
GDD_Inf_R_y_coef <- coef(mfl_model_or)["GDD_Inf_R_y"]
Rincpop_q_y_coef <- coef(mfl_model_or)["Rincpop_q_y"]

# Positive Scenario
GDD_Trn_R_y_2017_Q2p <- 6.500

GDD_Inf_R_y_2017_Q2p <- 10.000

Rincpop_q_y_2017_Q2p <- 60.000

# Forecasting the share of Operational Risk Losses 
# in Total Assets (Positive scenario)
y_hat2017_Q2p <- intercept + GDD_Trn_R_y_coef * GDD_Trn_R_y_2017_Q2p + 
  GDD_Inf_R_y_coef * GDD_Inf_R_y_2017_Q2p +
  Rincpop_q_y_coef * Rincpop_q_y_2017_Q2p

# Printing the forecasted value
cat("Share of Operational Risk Losses (Positive scenario) for Q2-2017:", 
    y_hat2017_Q2p, "\n")
```
```{r}
# Forecasting share of Operational Risk Losses 
# in Total Assets (Positive scenario)
intercept <- coef(mfl_model_or)["(Intercept)"]
GDD_Trn_R_y_coef <- coef(mfl_model_or)["GDD_Trn_R_y"]
GDD_Inf_R_y_coef <- coef(mfl_model_or)["GDD_Inf_R_y"]
Rincpop_q_y_coef <- coef(mfl_model_or)["Rincpop_q_y"]

# Positive Scenario
GDD_Trn_R_y_2017_Q3p <- 7.200

GDD_Inf_R_y_2017_Q3p <- 15.000

Rincpop_q_y_2017_Q3p <- 90.000

# Forecasting the share of Operational Risk Losses 
# in Total Assets (Positive scenario)
y_hat2017_Q3p <- intercept + GDD_Trn_R_y_coef * GDD_Trn_R_y_2017_Q3p + 
  GDD_Inf_R_y_coef * GDD_Inf_R_y_2017_Q3p +
  Rincpop_q_y_coef * Rincpop_q_y_2017_Q3p

# Printing the forecasted value
cat("Share of Operational Risk Losses (Positive scenario) for Q3-2017:", 
    y_hat2017_Q3p, "\n")

```
```{r}
# Forecasting share of Operational Risk Losses 
# in Total Assets (Positive scenario)
intercept <- coef(mfl_model_or)["(Intercept)"]
GDD_Trn_R_y_coef <- coef(mfl_model_or)["GDD_Trn_R_y"]
GDD_Inf_R_y_coef <- coef(mfl_model_or)["GDD_Inf_R_y"]
Rincpop_q_y_coef <- coef(mfl_model_or)["Rincpop_q_y"]

# Positive Scenario
GDD_Trn_R_y_2017_Q4p <- 7.800

GDD_Inf_R_y_2017_Q4p <- 18.000

Rincpop_q_y_2017_Q4p <- 110.000

# Forecasting the share of Operational Risk Losses 
# in Total Assets (Positive scenario)
y_hat2017_Q4p <- intercept + GDD_Trn_R_y_coef * GDD_Trn_R_y_2017_Q4p + 
  GDD_Inf_R_y_coef * GDD_Inf_R_y_2017_Q4p +
  Rincpop_q_y_coef * Rincpop_q_y_2017_Q4p

# Printing the forecasted value
cat("Share of Operational Risk Losses (Positive scenario) for Q4-2017:", 
    y_hat2017_Q4p, "\n")

```

```{r}
#Forecasting amount of Operational Risk Losses (Positive scenario)

# Financial data on Total Assets for the following 4 quarters 2017 
# for forecasting
# Positive Scenario
total_assets_2017_Q1p <- 24255600000
total_assets_2017_Q2p <- 25993960000
total_assets_2017_Q3p <- 27856910000
total_assets_2017_Q4p <- 29853370000



# Forecasted share of Operational Risk Losses 
# in Total Assets (Positive scenario) for Q1-2017:
y_hat2017_Q1p
y_hat2017_Q2p
y_hat2017_Q3p
y_hat2017_Q4p

# Forecasting amount of Operational Risk Losses (Positive scenario)
or_losses_2017_Q1p <- total_assets_2017_Q1p * y_hat2017_Q1p
or_losses_2017_Q2p <- total_assets_2017_Q2p * y_hat2017_Q2p
or_losses_2017_Q3p <- total_assets_2017_Q3p * y_hat2017_Q3p
or_losses_2017_Q4p <- total_assets_2017_Q4p * y_hat2017_Q4p

# Printing the forecasted value
cat("Amount of Operational Risk Losses (Positive scenario) for Q1-2017:", 
    or_losses_2017_Q1p, "\n")

cat("Amount of Operational Risk Losses (Positive scenario) for Q2-2017:", 
    or_losses_2017_Q2p, "\n")

cat("Amount of Operational Risk Losses (Positive scenario) for Q3-2017:", 
    or_losses_2017_Q3p, "\n")

cat("Amount of Operational Risk Losses (Positive scenario) for Q4-2017:", 
    or_losses_2017_Q4p, "\n")
```

#### Negative scenario

```{r}
# Forecasting share of Operational Risk Losses 
# in Total Assets (Negative scenario)
intercept <- coef(mfl_model_or)["(Intercept)"]
GDD_Trn_R_y_coef <- coef(mfl_model_or)["GDD_Trn_R_y"]
GDD_Inf_R_y_coef <- coef(mfl_model_or)["GDD_Inf_R_y"]
Rincpop_q_y_coef <- coef(mfl_model_or)["Rincpop_q_y"]

# Negative Scenario
GDD_Trn_R_y_2017_Q1n <- 4.500

GDD_Inf_R_y_2017_Q1n <- 3.000

Rincpop_q_y_2017_Q1n <- -0.000

# Forecasting the share of Operational Risk Losses 
# in Total Assets (Positive scenario)
y_hat2017_Q1n <- intercept + GDD_Trn_R_y_coef * GDD_Trn_R_y_2017_Q1n + 
  GDD_Inf_R_y_coef * GDD_Inf_R_y_2017_Q1n +
  Rincpop_q_y_coef * Rincpop_q_y_2017_Q1n

# Printing the forecasted value
cat("Share of Operational Risk Losses (Negative scenario) for Q1-2017:", 
    y_hat2017_Q1n, "\n")

```
```{r}
# Forecasting share of Operational Risk Losses 
# in Total Assets (Negative scenario)
intercept <- coef(mfl_model_or)["(Intercept)"]
GDD_Trn_R_y_coef <- coef(mfl_model_or)["GDD_Trn_R_y"]
GDD_Inf_R_y_coef <- coef(mfl_model_or)["GDD_Inf_R_y"]
Rincpop_q_y_coef <- coef(mfl_model_or)["Rincpop_q_y"]

# Negative Scenario
GDD_Trn_R_y_2017_Q2n <- 4.000

GDD_Inf_R_y_2017_Q2n <- 1.500

Rincpop_q_y_2017_Q2n <- -5.000

# Forecasting the share of Operational Risk Losses (Positive scenario)
y_hat2017_Q2n <- intercept + GDD_Trn_R_y_coef * GDD_Trn_R_y_2017_Q2n + 
  GDD_Inf_R_y_coef * GDD_Inf_R_y_2017_Q2n +
  Rincpop_q_y_coef * Rincpop_q_y_2017_Q2n

# Printing the forecasted value
cat("Share of Operational Risk Losses (Negative scenario) for Q2-2017:", 
    y_hat2017_Q2n, "\n")

```
```{r}
# Forecasting share of Operational Risk Losses 
# in Total Assets (Negative scenario)
intercept <- coef(mfl_model_or)["(Intercept)"]
GDD_Trn_R_y_coef <- coef(mfl_model_or)["GDD_Trn_R_y"]
GDD_Inf_R_y_coef <- coef(mfl_model_or)["GDD_Inf_R_y"]
Rincpop_q_y_coef <- coef(mfl_model_or)["Rincpop_q_y"]

# Negative Scenario
GDD_Trn_R_y_2017_Q3n <- 3.500

GDD_Inf_R_y_2017_Q3n <- 1.000

Rincpop_q_y_2017_Q3n <- -10.000

# Forecasting the share of Operational Risk Losses (Positive scenario)
y_hat2017_Q3n <- intercept + GDD_Trn_R_y_coef * GDD_Trn_R_y_2017_Q3n + 
  GDD_Inf_R_y_coef * GDD_Inf_R_y_2017_Q3n +
  Rincpop_q_y_coef * Rincpop_q_y_2017_Q3n

# Printing the forecasted value
cat("Share of Operational Risk Losses (Negative scenario) for Q3-2017:", 
    y_hat2017_Q3n, "\n")
```

```{r}
# Forecasting share of Operational Risk Losses 
# in Total Assets (Negative scenario)
intercept <- coef(mfl_model_or)["(Intercept)"]
GDD_Trn_R_y_coef <- coef(mfl_model_or)["GDD_Trn_R_y"]
GDD_Inf_R_y_coef <- coef(mfl_model_or)["GDD_Inf_R_y"]
Rincpop_q_y_coef <- coef(mfl_model_or)["Rincpop_q_y"]

# Negative Scenario
GDD_Trn_R_y_2017_Q4n <- 3.200

GDD_Inf_R_y_2017_Q4n <- -0.500

Rincpop_q_y_2017_Q4n <- -15.000

# Forecasting the share of Operational Risk Losses (Positive scenario)
y_hat2017_Q4n <- intercept + GDD_Trn_R_y_coef * GDD_Trn_R_y_2017_Q4n + 
  GDD_Inf_R_y_coef * GDD_Inf_R_y_2017_Q4n +
  Rincpop_q_y_coef * Rincpop_q_y_2017_Q4n

# Printing the forecasted value
cat("Share of Operational Risk Losses (Negative scenario) for Q4-2017:", 
    y_hat2017_Q4n, "\n")
```
```{r}
#Forecasting amount of Operational Risk Losses (Negative scenario)

# Financial data on Total Assets for the following 
# 3 quarters 2017 for forecasting
# Negative Scenario
total_assets_2017_Q1n <- 22356410000
total_assets_2017_Q2n <- 22082730000
total_assets_2017_Q3n <- 21812390000
total_assets_2017_Q4n <- 21545360000


# Forecasted share of Operational Risk Losses (Negative scenario) for Q1-2017:
y_hat2017_Q1n
y_hat2017_Q2n
y_hat2017_Q3n
y_hat2017_Q4n

# Forecasting amount of Operational Risk Losses (Negative scenario)
or_losses_2017_Q1n <- total_assets_2017_Q1n * y_hat2017_Q1n
or_losses_2017_Q2n <- total_assets_2017_Q2n * y_hat2017_Q2n
or_losses_2017_Q3n <- total_assets_2017_Q3n * y_hat2017_Q3n
or_losses_2017_Q4n <- total_assets_2017_Q4n * y_hat2017_Q4n

# Print the forecasted value
cat("Amount of Operational Risk Losses (Negative scenario) for Q1-2017:", 
    or_losses_2017_Q1n, "\n")

cat("Amount of Operational Risk Losses (Negative scenario) for Q2-2017:", 
    or_losses_2017_Q2n, "\n")

cat("Amount of Operational Risk Losses (Negative scenario) for Q3-2017:", 
    or_losses_2017_Q3n, "\n")

cat("Amount of Operational Risk Losses (Negative scenario) for Q4-2017:", 
    or_losses_2017_Q4n, "\n")
```

#### Amounts (impact/severity) of Operational Risk Losses forecasted values (Multiple Linear Regression):

```{r}
# Printing the forecasted values
cat("Amount of Operational Risk Losses (Positive scenario) for Q1-2017:", 
    or_losses_2017_Q1p, "\n")

cat("Amount of Operational Risk Losses (Positive scenario) for Q2-2017:", 
    or_losses_2017_Q2p, "\n")

cat("Amount of Operational Risk Losses (Positive scenario) for Q3-2017:", 
    or_losses_2017_Q3p, "\n")

cat("Amount of Operational Risk Losses (Positive scenario) for Q4-2017:", 
    or_losses_2017_Q4p, "\n")

# Printing the forecasted values
cat("Amount of Operational Risk Losses (Negative scenario) for Q1-2017:", 
    or_losses_2017_Q1n, "\n")

cat("Amount of Operational Risk Losses (Negative scenario) for Q2-2017:", 
    or_losses_2017_Q2n, "\n")

cat("Amount of Operational Risk Losses (Negative scenario) for Q3-2017:", 
    or_losses_2017_Q3n, "\n")

cat("Amount of Operational Risk Losses (Negative scenario) for Q4-2017:", 
    or_losses_2017_Q4n, "\n")
```
### Forecasting amounts (impact/severity) of Operational Risk Losses with Multiple Generalized Additive Model (GAM)

```{r}
#Summary of the Multiple Generalized Additive Model (GAM)
summary(gam_model_or)
```
#### Positive scenario

```{r}
# Creating a data frame for Positive Scenario
new_data_positive <- data.frame(
  GDD_Trn_R_y = c(2.500, 2.800, 3.100, 3.500),
  GDD_Inf_R_y = c(0.500, 0.800, 1.200, 1.500),
  Rincpop_q_y = c(130.200, 130.500, 131.100, 132.600)
)

# Print the new_data frame
print(new_data_positive)
```

```{r}
# Creating a data frame for Negative Scenario
new_data_negative <- data.frame(
  GDD_Trn_R_y = c(1.500, 1.200, 1.000, 0.800),
  GDD_Inf_R_y = c(0.100, 0.060, 0.020, -0.100),
  Rincpop_q_y = c(-20.000, -18.500, -16.000, -12.000)
)

# Print the new_data_negative frame
print(new_data_negative)
```

```{r}
# Forecasting with Multiple Generalized Additive Model (GAM) 
# for Positive scenario
predictions_positive <- predict(gam_model_or, 
                                newdata = new_data_positive)

# Print predictions
print(predictions_positive)
```
```{r}
#Forecasting amount of Operational Risk Losses with 
# Multiple Generalized Additive Model (GAM) (Positive scenario)

# Financial data on Total Assets for the following 
# 4 quarters 2017 for forecasting
# Positive Scenario
total_assets_2017_Q1p <- 24255600000
total_assets_2017_Q2p <- 25993960000
total_assets_2017_Q3p <- 27856910000
total_assets_2017_Q4p <- 29853370000



# Forecasted share of Operational Risk Losses
# (Positive scenario) for 2017:
y_hat2017_gam_Q1p <- 0.0010611856
y_hat2017_gam_Q2p <- 0.0010288484
y_hat2017_gam_Q3p <- 0.0009969525
y_hat2017_gam_Q4p <- 0.0009378848

# Forecasting amount of Operational Risk Losses (Positive scenario)
or_losses_gam_2017_Q1p <- total_assets_2017_Q1p * y_hat2017_gam_Q1p
or_losses_gam_2017_Q2p <- total_assets_2017_Q2p * y_hat2017_gam_Q2p
or_losses_gam_2017_Q3p <- total_assets_2017_Q3p * y_hat2017_gam_Q3p
or_losses_gam_2017_Q4p <- total_assets_2017_Q4p * y_hat2017_gam_Q4p

# Printing the forecasted value
cat("Amount of Operational Risk Lossesc with Multiple (GAM) (Positive scenario) for Q1-2017:", 
    or_losses_gam_2017_Q1p, "\n")

cat("Amount of Operational Risk Losses with Multiple (GAM) (Positive scenario) for Q2-2017:", 
    or_losses_gam_2017_Q2p, "\n")

cat("Amount of Operational Risk Losses with Multiple (GAM) (Positive scenario) for Q3-2017:", 
    or_losses_gam_2017_Q3p, "\n")
 
cat("Amount of Operational Risk Losses with Multiple (GAM) (Positive scenario) for Q4-2017:", 
    or_losses_gam_2017_Q4p, "\n")
```
```{r}
# Forecasting with Multiple Generalized Additive Model (GAM) 
# for Negative scenario
predictions_negative <- predict(gam_model_or, 
                                newdata = new_data_negative)

# Print predictions
print(predictions_negative)
```

```{r}
#Forecasting amount of Operational Risk Losses (Negative scenario)

# Financial data on Total Assets for the following 4 quarters 2017 
# for forecasting
# Negative Scenario
total_assets_2017_Q1n <- 22356410000
total_assets_2017_Q2n <- 22082730000
total_assets_2017_Q3n <- 21812390000
total_assets_2017_Q4n <- 21545360000


# Forecasted share of Operational Risk Losses (Negative scenario) for 2017:
y_hat2017_gam_Q1n <- 0.002844487
y_hat2017_gam_Q2n <- 0.002866672
y_hat2017_gam_Q3n <- 0.002864343
y_hat2017_gam_Q4n <- 0.002842384

# Forecasting amount of Operational Risk Losses  with 
# Multiple Generalized Additive Model (GAM) (Negative scenario)
or_losses_2017_gam_Q1n <- total_assets_2017_Q1n * y_hat2017_gam_Q1n
or_losses_2017_gam_Q2n <- total_assets_2017_Q2n * y_hat2017_gam_Q2n
or_losses_2017_gam_Q3n <- total_assets_2017_Q3n * y_hat2017_gam_Q3n
or_losses_2017_gam_Q4n <- total_assets_2017_Q4n * y_hat2017_gam_Q4n

# Printing the forecasted value
cat("Amount of Operational Risk Losses with Multiple (GAM) (Negative scenario) for Q1-2017:", 
    or_losses_2017_gam_Q1n, "\n")

cat("Amount of Operational Risk Losses  with Multiple (GAM) (Negative scenario) for Q2-2017:", 
    or_losses_2017_gam_Q2n, "\n")

cat("Amount of Operational Risk Losses  with Multiple (GAM) (Negative scenario) for Q3-2017:", 
    or_losses_2017_gam_Q3n, "\n")

cat("Amount of Operational Risk Losses with Multiple (GAM)  (Negative scenario) for Q4-2017:", 
    or_losses_2017_gam_Q4n, "\n")
```
#### Amounts (impact/severity) of Operational Risk Losses forecasted values (Multiple Generalized Additive Model (GAM):

```{r}
# Printing the forecasted values
cat("Amount of Operational Risk Losses with (GAM) (Positive scenario) for Q1-2017:", 
    or_losses_gam_2017_Q1p, "\n")

cat("Amount of Operational Risk Losses  with (GAM) (Positive scenario) for Q2-2017:", 
    or_losses_gam_2017_Q2p, "\n")

cat("Amount of Operational Risk Losses  with (GAM) (Positive scenario) for Q3-2017:", 
    or_losses_gam_2017_Q3p, "\n")

cat("Amount of Operational Risk Losses  with (GAM) (Positive scenario) for Q4-2017:", 
    or_losses_gam_2017_Q4p, "\n")

# Printing the forecasted values
cat("Amount of Operational Risk Losses  with (GAM) (Negative scenario) for Q1-2017:", 
    or_losses_2017_gam_Q1n, "\n")

cat("Amount of Operational Risk Losses  with (GAM) (Negative scenario) for Q2-2017:", 
    or_losses_2017_gam_Q2n, "\n")

cat("Amount of Operational Risk Losses  with (GAM) (Negative scenario) for Q3-2017:", 
    or_losses_2017_gam_Q3n, "\n")

cat("Amount of Operational Risk Losses  with (GAM) (Negative scenario) for Q4-2017:", 
    or_losses_2017_gam_Q4n, "\n")
```

### Forecasting frequency (number) of Operational Risk Losses

#### Multiple Poisson Regression

#### Creating correlation matrix

```{r fig.align="center", fig.width=6, fig.height=4}
# Visualization Kendall's correlation matrix by correlation plot
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", 
                          "#77AADD", "#4477AA"))
corrplot(kendall_corr11, method = "color", col = col(200),
         type = "upper", order = "hclust",
         addCoef.col = "black", 
         tl.col = "black", tl.srt = 45,
         
)
```
**Findings:** The correlations between the independent variables and the dependent variable, Total_freq (operational risk frequency), suggest the following insights:

Negative Correlation with Total_freq (Operational Risk Frequency):
All independent variables exhibit negative correlations with Total_freq, indicating that as macroeconomic conditions (such as exchange rates, GDP growth, and real income per capita) improve, the frequency of operational risk events tends to decrease. This inverse relationship implies that stronger economic indicators might lead to a more stable business environment with fewer operational risk events. This finding supports the hypothesis that improved macroeconomic conditions could help mitigate operational risks.

Relationships Between Independent Variables:
rurkzt (RUB/KZT exchange rate) and GDD_R_y (GDP growth rate) have a weak positive correlation (0.287). This suggests that when the exchange rate fluctuates, GDP growth tends to increase slightly, though the relationship is not strong.
rurkzt and Rincpop_q_y (real income per capita) have a weak positive correlation (0.178), meaning that both variables may move in the same direction, but the association is not significant.
GDD_R_y and Rincpop_q_y have a strong positive correlation (0.664), indicating that as GDP growth increases, real income per capita tends to rise substantially. This is an expected economic relationship, as higher GDP growth generally leads to increased income levels in an economy.

Implications for Operational Risk Frequency:
The negative correlations between the independent variables and Total_freq imply that when macroeconomic factors such as exchange rates, GDP growth, and income levels improve, the frequency of operational risk events decreases. This may reflect the stabilizing effect of positive economic growth on business operations and risk management.
Further exploration is needed to confirm whether these correlations are statistically significant and to better understand whether these relationships are causal or merely coincidental.


```{r}
#Summary of the Multiple Generalized Poisson Model
summary(mf_poiss_model7)
```
#### Defining historical minimums and maximums of independent and dependent variables

```{r}
# Reviewing historical minimum values of "rurkzt" variable
rurkzt_min <- min(final_df$rurkzt, na.rm = TRUE)
cat("rurkzt historical minimum is", rurkzt_min)
```
```{r}
# Reviewing historical maximum values of "rurkzt" variable
rurkzt_max <- max(final_df$rurkzt, na.rm = TRUE)
cat("rurkzt_max historical maximum is", rurkzt_max, "\n")
```
```{r}
# Reviewing historical minimum values of "Rincpop_q_y" variable
Rincpop_q_y_min <- min(final_df$Rincpop_q_y, na.rm = TRUE)
cat("Rincpop_q_y historical minimum is", Rincpop_q_y_min)
```
```{r}
# Reviewing historical maximum values of "Rincpop_q_y" variable
Rincpop_q_y_max <- max(final_df$Rincpop_q_y, na.rm = TRUE)
cat("Rincpop_q_y_max historical maximum is", Rincpop_q_y_max, "\n")
```
```{r}
# Reviewing historical minimum values of "GDD_R_y" variable
GDD_R_y_min <- min(final_df$GDD_R_y, na.rm = TRUE)
cat("GDD_R_y historical minimum is", GDD_R_y_min)
```
```{r}
# Reviewing historical maximum values of "GDD_R_y" variable
GDD_R_y_max <- max(final_df$GDD_R_y, na.rm = TRUE)
cat("GDD_R_y_max historical maximum is", GDD_R_y_max, "\n")
```

### Defining Scenarios

```{r}
# Positive Scenario
rurkzt_y_2017_Q1p <- 10.000
rurkzt_y_2017_Q2p <- 8.000
rurkzt_y_2017_Q3p <- 6.000
rurkzt_y_2017_Q4p <- 4.000

GDD_R_y_2017_Q1p = 30.000
GDD_R_y_2017_Q2p = 50.000
GDD_R_y_2017_Q3p = 80.000
GDD_R_y_2017_Q4p = 100.000

Rincpop_q_y_2017_Q1p = 5.000
Rincpop_q_y_2017_Q2p = 6.500
Rincpop_q_y_2017_Q3p = 7.000
Rincpop_q_y_2017_Q4p = 7.400
```

```{r}
# Negative Scenario
rurkzt_y_2017_Q1n <- 12.000
rurkzt_y_2017_Q2n <- 14.000
rurkzt_y_2017_Q3n <- 16.500
rurkzt_y_2017_Q4n <- 18.000

GDD_R_y_2017_Q1n <- -5.000
GDD_R_y_2017_Q2n <- -10.000
GDD_R_y_2017_Q3n <- -13.000
GDD_R_y_2017_Q4n <- -16.000

Rincpop_q_y_2017_Q1n <- 3.000
Rincpop_q_y_2017_Q2n <- 2.000
Rincpop_q_y_2017_Q3n <- 1.000
Rincpop_q_y_2017_Q4n <- 0.800
```

### Forecasting frequency (number) of Operational Risk Losses with Poisson Regression Model

#### Positive scenario

```{r}
# Forecasting of frequency (number) of Operational Risk Losses 
# (Positive scenario)
intercept <- coef(mf_poiss_model7)["(Intercept)"]
rurkzt_coef <- coef(mf_poiss_model7)["rurkzt"]
Rincpop_q_y_coef <- coef(mf_poiss_model7)["Rincpop_q_y"]
GDD_R_y_coef <- coef(mf_poiss_model7)["GDD_R_y"]

# Positive Scenario
rurkzt_y_2017_Q1p <- 10.000

GDD_R_y_2017_Q1p = 40.000

Rincpop_q_y_2017_Q1p = 5.000

# Forecasting of frequency (number) of Operational Risk Losses 
# (Positive scenario)
y_hat2017_freq_Q1p <- (intercept + rurkzt_y_2017_Q1p * rurkzt_coef +
  GDD_R_y_2017_Q1p *GDD_R_y_coef +
  Rincpop_q_y_coef * Rincpop_q_y_2017_Q1p)

# Predicting the count (y) by taking the exponential function
predicted_count2017_Q1p <- exp(y_hat2017_freq_Q1p)

# Print the forecasted value
cat("Frequency of Operational Risk Losses (Positive scenario) for Q1-2017:", 
    predicted_count2017_Q1p, "\n")

```
```{r}
# Forecasting of frequency (number) of Operational Risk Losses 
# (Positive scenario)
intercept <- coef(mf_poiss_model7)["(Intercept)"]
rurkzt_coef <- coef(mf_poiss_model7)["rurkzt"]
Rincpop_q_y_coef <- coef(mf_poiss_model7)["Rincpop_q_y"]
GDD_R_y_coef <- coef(mf_poiss_model7)["GDD_R_y"]

# Positive Scenario
rurkzt_y_2017_Q2p <- 8.000

GDD_R_y_2017_Q2p = 60.000

Rincpop_q_y_2017_Q2p = 6.500

# Forecasting of frequency (number) of Operational Risk Losses 
# (Positive scenario)
y_hat2017_freq_Q2p <- (intercept + rurkzt_y_2017_Q2p * rurkzt_coef + 
                         GDD_R_y_2017_Q2p * GDD_R_y_coef + 
                         Rincpop_q_y_coef * Rincpop_q_y_2017_Q2p)

# Predicting the count (y) by taking the exponential function
predicted_count2017_Q2p <- exp(y_hat2017_freq_Q2p)

# Printing the forecasted value
cat("Frequency of Operational Risk Losses (Positive scenario) for Q2-2017:", 
    predicted_count2017_Q2p, "\n")

```
```{r}
# Forecasting of frequency (number) of Operational Risk Losses 
# (Positive scenario)
intercept <- coef(mf_poiss_model7)["(Intercept)"]
rurkzt_coef <- coef(mf_poiss_model7)["rurkzt"]
Rincpop_q_y_coef <- coef(mf_poiss_model7)["Rincpop_q_y"]
GDD_R_y_coef <- coef(mf_poiss_model7)["GDD_R_y"]

# Positive Scenario
rurkzt_y_2017_Q3p <- 6.000

GDD_R_y_2017_Q3p = 80.000

Rincpop_q_y_2017_Q3p = 7.000

# Forecasting of frequency (number) of Operational Risk Losses 
# (Positive scenario)
y_hat2017_freq_Q3p <- (intercept + rurkzt_y_2017_Q3p * rurkzt_coef + 
                         GDD_R_y_2017_Q3p * GDD_R_y_coef + 
                         Rincpop_q_y_coef * Rincpop_q_y_2017_Q3p)

# Predicting the count (y) by taking the exponential function
predicted_count2017_Q3p <- exp(y_hat2017_freq_Q3p)

# Printing the forecasted value
cat("Frequency of Operational Risk Losses (Positive scenario) for Q3-2017:",
    predicted_count2017_Q3p, "\n")
```

```{r}
# Forecasting of frequency (number) of Operational Risk Losses 
# (Positive scenario)
intercept <- coef(mf_poiss_model7)["(Intercept)"]
rurkzt_coef <- coef(mf_poiss_model7)["rurkzt"]
Rincpop_q_y_coef <- coef(mf_poiss_model7)["Rincpop_q_y"]
GDD_R_y_coef <- coef(mf_poiss_model7)["GDD_R_y"]

# Positive Scenario
rurkzt_y_2017_Q4p <- 4.000

GDD_R_y_2017_Q4p = 100.000

Rincpop_q_y_2017_Q4p = 7.400

# Forecasting of frequency (number) of Operational Risk Losses 
# (Positive scenario)
y_hat2017_freq_Q4p <- (intercept + rurkzt_y_2017_Q4p * rurkzt_coef + 
                         GDD_R_y_2017_Q4p * GDD_R_y_coef + 
                         Rincpop_q_y_coef * Rincpop_q_y_2017_Q4p)

# Predicting the count (y) by taking the exponential function
predicted_count2017_Q4p <- exp(y_hat2017_freq_Q4p)

# Printing the forecasted value
cat("Frequency of Operational Risk Losses (Positive scenario) for Q4-2017:", 
    predicted_count2017_Q4p, "\n")
```

#### Negaive scenario

```{r}
# Forecasting of frequency (number) of Operational Risk Losses 
# (Negative scenario)
intercept <- coef(mf_poiss_model7)["(Intercept)"]
rurkzt_coef <- coef(mf_poiss_model7)["rurkzt"]
Rincpop_q_y_coef <- coef(mf_poiss_model7)["Rincpop_q_y"]
GDD_R_y_coef <- coef(mf_poiss_model7)["GDD_R_y"]

# Negative Scenario
rurkzt_y_2017_Q1n <- 12.000

GDD_R_y_2017_Q1n <- -5.000

Rincpop_q_y_2017_Q1n <- 3.000

# Forecasting of frequency (number) of Operational Risk Losses 
# (Negative scenario)
y_hat2017_freq_Q1n <- (intercept + rurkzt_y_2017_Q1n * rurkzt_coef + 
                         GDD_R_y_2017_Q1n * GDD_R_y_coef + 
                         Rincpop_q_y_2017_Q1n * Rincpop_q_y_coef)

# Predicting the count (y) by taking the exponential function
predicted_count2017_Q1n <- exp(y_hat2017_freq_Q1n)

# Printing the forecasted value
cat("Frequency of Operational Risk Losses (Negative scenario) for Q1-2017:", 
    predicted_count2017_Q1n, "\n")
```
```{r}
# Forecasting of frequency (number) of Operational Risk Losses 
# (Negative scenario)
intercept <- coef(mf_poiss_model7)["(Intercept)"]
rurkzt_coef <- coef(mf_poiss_model7)["rurkzt"]
Rincpop_q_y_coef <- coef(mf_poiss_model7)["Rincpop_q_y"]
GDD_R_y_coef <- coef(mf_poiss_model7)["GDD_R_y"]

# Negative Scenario
rurkzt_y_2017_Q2n <- 14.000

GDD_R_y_2017_Q2n <- -10.000

Rincpop_q_y_2017_Q2n <- 2.000

# Forecasting of frequency (number) of Operational Risk Losses 
# (Negative scenario)
y_hat2017_freq_Q2n <- (intercept + rurkzt_y_2017_Q2n * rurkzt_coef + 
                         GDD_R_y_2017_Q2n * GDD_R_y_coef + 
                         Rincpop_q_y_2017_Q2n * Rincpop_q_y_coef)

# Predicting the count (y) by taking the exponential function
predicted_count2017_Q2n <- exp(y_hat2017_freq_Q2n)

# Printing the forecasted value
cat("Frequency of Operational Risk Losses (Negative scenario) for Q2-2017:", 
    predicted_count2017_Q2n, "\n")
```
```{r}
# Forecasting of frequency (number) of Operational Risk Losses 
# (Negative scenario)
intercept <- coef(mf_poiss_model7)["(Intercept)"]
rurkzt_coef <- coef(mf_poiss_model7)["rurkzt"]
Rincpop_q_y_coef <- coef(mf_poiss_model7)["Rincpop_q_y"]
GDD_R_y_coef <- coef(mf_poiss_model7)["GDD_R_y"]

# Negative Scenario
rurkzt_y_2017_Q3n <- 16.500

GDD_R_y_2017_Q3n <- -13.000

Rincpop_q_y_2017_Q3n <- 1.000

# Forecasting of frequency (number) of Operational Risk Losses 
# (Negative scenario)
y_hat2017_freq_Q3n <- (intercept + rurkzt_y_2017_Q3n * rurkzt_coef + 
                         GDD_R_y_2017_Q3n * GDD_R_y_coef + 
                         Rincpop_q_y_2017_Q3n * Rincpop_q_y_coef)

# Predicting the count (y) by taking the exponential function
predicted_count2017_Q3n <- exp(y_hat2017_freq_Q3n)

# Printing the forecasted value
cat("Frequency of Operational Risk Losses (Negative scenario) for Q3-2017:", 
    predicted_count2017_Q3n, "\n")
```
```{r}
# Forecasting of frequency (number) of Operational Risk Losses 
# (Negative scenario)
intercept <- coef(mf_poiss_model7)["(Intercept)"]
rurkzt_coef <- coef(mf_poiss_model7)["rurkzt"]
Rincpop_q_y_coef <- coef(mf_poiss_model7)["Rincpop_q_y"]
GDD_R_y_coef <- coef(mf_poiss_model7)["GDD_R_y"]

# Negative Scenario
rurkzt_y_2017_Q4n <- 18.000

GDD_R_y_2017_Q4n <- -16.000

Rincpop_q_y_2017_Q4n <- 0.800

# Forecasting of frequency (number) of Operational Risk Losses 
# (Negative scenario)
y_hat2017_freq_Q4n <- (intercept + rurkzt_y_2017_Q4n * rurkzt_coef + 
                         GDD_R_y_2017_Q4n * GDD_R_y_coef + 
                         Rincpop_q_y_2017_Q4n * Rincpop_q_y_coef)

# Predicting the count (y) by taking the exponential function
predicted_count2017_Q4n <- exp(y_hat2017_freq_Q4n)

# Printing the forecasted value
cat("Frequency of Operational Risk Losses (Negative scenario) for Q4-2017:",
    predicted_count2017_Q4n, "\n")
```

#### Frequency (number) of Operational Risks forecasted values (Multiple Poisson Regression):

```{r}
# Printing the forecasted value
cat("Amount of Operational Risk Losse (Positive scenario) for Q1-2017:", 
    predicted_count2017_Q1p, "\n")

cat("Amount of Operational Risk Losse (Positive scenario) for Q2-2017:", 
    predicted_count2017_Q2p, "\n")

cat("Amount of Operational Risk Losse (Positive scenario) for Q3-2017:", 
    predicted_count2017_Q3p, "\n")

cat("Amount of Operational Risk Losse (Positive scenario) for Q4-2017:", 
    predicted_count2017_Q4p, "\n")

# Printing the forecasted value
cat("Amount of Operational Risk Losse (Negative scenario) for Q1-2017:", 
    predicted_count2017_Q1n, "\n")

cat("Amount of Operational Risk Losse (Negative scenario) for Q2-2017:", 
    predicted_count2017_Q2n, "\n")

cat("Amount of Operational Risk Losse (Negative scenario) for Q3-2017:", 
    predicted_count2017_Q3n, "\n")

cat("Amount of Operational Risk Losse (Negative scenario) for Q4-2017:", 
    predicted_count2017_Q4n, "\n")
```


### Interim Conclusion
### Regression Model Stress Testing Summary Table

```{r, results='asis'}
# Creating the summary data frame for the stress testing results 
# with hierarchical and unique row names
stresstest_summary <- data.frame(
  Scenario = c("Positive scenario", "2017 Q1 - Positive", 
               "2017 Q2 - Positive", "2017 Q3 - Positive", 
               "2017 Q4 - Positive", "Negative scenario", 
               "2017 Q1 - Negative", "2017 Q2 - Negative", 
               "2017 Q3 - Negative", "2017 Q4 - Negative"),
  `OR Loss Amount (Linear)` = c("KZT", 46228220, 43127346, 
                                39583768, 36771242, 
                                "KZT", 52068502, 52890742, 
                                54506252, 54684134),
  `OR Loss Amount (GAM)` = c("KZT", 25739693, 26743844, 
                            27772016, 27999022, 
                            "KZT", 63592518, 63303944, 
                            62478167, 61240187),
  `OR Frequency (Poisson)` = c("QTY", 568, 999, 
                               1760, 3101, 
                               "QTY", 162, 139, 
                               126, 115)
)

kable(stresstest_summary, format = "markdown", digits = 5, 
      caption = "Regression Model Stress Testing Summary for Operational Risk")
```
### Interim Conclusion
Stress testing of Operational Risk was conducted using Multiple Linear Regression (MLR) and the Generalized Additive Model (GAM) to predict the severity of losses. A statistical threshold of 0.35 (35%) for R^2 (Coefficient of Determination) and an alpha level of 0.1 (90% confidence) were applied.

Since the assumptions of linearity and normality were not fully met for MLR, non-linear models, including second-degree, third-degree, and sixth-degree Polynomial Regression models, as well as GAM, were tested. Although Polynomial Regression models exhibited higher R^2 values—0.449 (44.9%) for second-degree, 0.562 (56.2%) for third-degree, and 0.867 (86.7%) for sixth-degree—all p-values for independent variables exceeded the alpha threshold of 0.1, rendering them statistically insignificant. Consequently, these models were not utilized for stress testing.

GAM demonstrated an Adjusted R^2 of 0.359 (35.9%) and explained 44% of the deviance, with all p-values falling below the alpha threshold. In comparison, MLR yielded an R^2 of 0.4426 (44.3%) and an Adjusted R^2 of 0.359 (35.9%), with all p-values below 0.1. As a result, the Null hypothesis (H0) was rejected in favor of the Alternative hypothesis (Ha), confirming a relationship between Operational Risk losses and macroeconomic variables.

**Optimal Model for Predicting Loss Severity**

The most effective model for predicting the amount (severity) of Operational Risk losses was determined using the following independent variables from the "AFR" R package dataset:

GDD_Trn_R_y: Real Gross Value Added for Transportation

GDD_Inf_R_y: Real Gross Value Added for Information

Rincpop_q_y: Real Population Average Monthly Income

The dependent variable was the proportion of total Operational Risk losses in the assets of Bank "X".

**Frequency of Losses**

Multiple Poisson Regression was employed to estimate the frequency of losses. The results indicated that Multiple Poisson Regression provided reasonable predictions, with Multiple Negative Binomial Regression closely aligning with its outcomes. A statistical threshold of 0.35 (35%) for R^2 and an alpha level of 0.1 (90% confidence) were maintained.

The best model for predicting loss frequency was identified using Multiple Poisson Regression with the following independent variables:

ruktzt: RUB/KZT exchange rate

Rincpop_q_y: Real Population Average Monthly Income

GDD_R_y: Real Gross Value Added

The dependent variable was the total frequency of Operational Risk losses for Bank "X". The Pseudo R^2 for this model was 0.48 (r2ML, r2CU), with all p-values below the 0.1 threshold. Consequently, the Null hypothesis (H0) was rejected in favor of the Alternative hypothesis (Ha), reinforcing the correlation between Operational Risk losses and macroeconomic variables.

**Correlation Analysis**

Across all models, a negative correlation was observed between independent and dependent variables.

**Predicted Outcomes**

**Multiple Linear Regression (Loss Severity)**

Positive Scenario:

Highest loss: KZT 46,228,220

Lowest loss: KZT 36,771,242

Negative Scenario:

Highest loss: KZT 54,684,134

Lowest loss: KZT 52,068,502

**Generalized Additive Model (Loss Severity)**

Positive Scenario:

Highest loss: KZT 27,999,022

Lowest loss: KZT 25,739,693

Negative Scenario:

Highest loss: KZT 63,592,518

Lowest loss: KZT 61,240,187

**Multiple Poisson Regression (Loss Frequency)**

Positive Scenario:

Highest frequency: 3,101

Lowest frequency: 568

Negative Scenario:

Highest frequency: 162

Lowest frequency: 115

**Interim Considerations**

The results from this stress testing should be interpreted with caution, as some modeling assumptions, such as linearity and normality, were not fully satisfied. Despite this limitation, the findings provide valuable insights into the relationship between Operational Risk losses and macroeconomic variables, aiding in risk assessment and mitigation strategies.

# Historical Simulation Model
## Data Preprocessing

```{r}
# Exploratory data analysis
summary(or_type1)
glimpse(or_type1)
str(or_type1)
```
Truncating data frame in line with Regression Model time frames.
```{r}
# Truncating data frame for the period 01.01.2010 - 31.12.2016
or_type1_truncated <- or_type1 %>%
  filter(Date >= as.Date("2010-01-01") & Date <= as.Date("2016-12-31"))
head(or_type1_truncated)
tail(or_type1_truncated)
```

Converting USD values to KZT values
```{r}
# Converting USD values to KZT values
usd_kzt_exchange_rates <- c(
  `2016` = 342.16,
  `2015` = 221.73,
  `2014` = 179.19,
  `2013` = 152.13,
  `2012` = 149.11,
  `2011` = 146.62,
  `2010` = 147.35
)

convert_to_kzt <- function(year, value) {
  exchange_rate <- usd_kzt_exchange_rates[as.character(year)]
  if (!is.na(exchange_rate)) {
    return(value * exchange_rate)
  } else {
    return(NA)
  }
}

or_type1_kzt <- or_type1_truncated %>%
  mutate(Year = as.numeric(format(Date, "%Y")),
         Loss_kzt = mapply(convert_to_kzt, Year, Loss)) %>%
  relocate(Loss_kzt, .after = Loss) %>%
  dplyr::select(-Year)  # Explicitly use dplyr's select


# Checking the data frame
head(or_type1_kzt)
tail(or_type1_kzt)
```

```{r}
# Exploratory data analysis
summary(or_type2)
glimpse(or_type2)
str(or_type2)
```
Truncating data frame in line with Regression Model time frames.
```{r}
# Truncating data frame for the period 01.01.2010 - 31.12.2016
or_type2_truncated <- or_type2 %>%
  filter(Date >= as.Date("2010-01-01") & Date <= as.Date("2016-12-31"))
head(or_type2_truncated)
tail(or_type2_truncated)
```
Converting USD values to KZT values
```{r}
# Converting USD values to KZT values
usd_kzt_exchange_rates <- c(
  `2016` = 342.16,
  `2015` = 221.73,
  `2014` = 179.19,
  `2013` = 152.13,
  `2012` = 149.11,
  `2011` = 146.62,
  `2010` = 147.35
)

convert_to_kzt <- function(year, value) {
  exchange_rate <- usd_kzt_exchange_rates[as.character(year)]
  if (!is.na(exchange_rate)) {
    return(value * exchange_rate)
  } else {
    return(NA)
  }
}

or_type2_kzt <- or_type2_truncated %>%
  mutate(Year = as.numeric(format(Date, "%Y")),
         Loss_kzt = mapply(convert_to_kzt, Year, Loss)) %>%
  relocate(Loss_kzt, .after = Loss) %>%
  dplyr::select(-Year)  


# Checking the data frame
head(or_type2_kzt)
tail(or_type2_kzt)
```



```{r}
# Exploratory data analysis
summary(or_type3)
glimpse(or_type3)
str(or_type3)
```
Truncating data frame in line with Regression Model time frames.
```{r}
# Truncating data frame for the period 01.01.2010 - 31.12.2016
or_type3_truncated <- or_type3 %>%
  filter(Date >= as.Date("2010-01-01") & Date <= as.Date("2016-12-31"))
head(or_type3_truncated)
tail(or_type3_truncated)
```
Converting USD values to KZT values
```{r}
# Converting USD values to KZT values
usd_kzt_exchange_rates <- c(
  `2016` = 342.16,
  `2015` = 221.73,
  `2014` = 179.19,
  `2013` = 152.13,
  `2012` = 149.11,
  `2011` = 146.62,
  `2010` = 147.35
)

convert_to_kzt <- function(year, value) {
  exchange_rate <- usd_kzt_exchange_rates[as.character(year)]
  if (!is.na(exchange_rate)) {
    return(value * exchange_rate)
  } else {
    return(NA)
  }
}

or_type3_kzt <- or_type3_truncated %>%
  mutate(Year = as.numeric(format(Date, "%Y")),
         Loss_kzt = mapply(convert_to_kzt, Year, Loss)) %>%
  relocate(Loss_kzt, .after = Loss) %>%
  dplyr::select(-Year)


# Checking the data frame
head(or_type3_kzt)
tail(or_type3_kzt)
```



```{r}
# Exploratory data analysis
summary(or_type4)
glimpse(or_type4)
str(or_type4)
```
Truncating data frame in line with Regression Model time frames.
```{r}
# Truncating data frame for the period 01.01.2010 - 31.12.2016
or_type4_truncated <- or_type4 %>%
  filter(Date >= as.Date("2010-01-01") & Date <= as.Date("2016-12-31"))
head(or_type4_truncated)
tail(or_type4_truncated)
```
Converting USD values to KZT values
```{r}
# Converting USD values to KZT values
usd_kzt_exchange_rates <- c(
  `2016` = 342.16,
  `2015` = 221.73,
  `2014` = 179.19,
  `2013` = 152.13,
  `2012` = 149.11,
  `2011` = 146.62,
  `2010` = 147.35
)

convert_to_kzt <- function(year, value) {
  exchange_rate <- usd_kzt_exchange_rates[as.character(year)]
  if (!is.na(exchange_rate)) {
    return(value * exchange_rate)
  } else {
    return(NA)
  }
}

or_type4_kzt <- or_type4_truncated %>%
  mutate(Year = as.numeric(format(Date, "%Y")),
         Loss_kzt = mapply(convert_to_kzt, Year, Loss)) %>%
  relocate(Loss_kzt, .after = Loss) %>%
  dplyr::select(-Year) 


# Checking the data frame
head(or_type4_kzt)
tail(or_type4_kzt)
```


### Correlations between different types of Operational Risks

```{r}
# Finding minimal number of rows between each type of Operational Risk
min_rows <- min(nrow(or_type1_kzt), nrow(or_type2_kzt), 
                nrow(or_type3_kzt), nrow(or_type4_kzt))

# Truncating all data frames to minimal number of rows between them
or_type1_minrow <- or_type1_kzt[1:min_rows, ]
or_type2_minrow  <- or_type2_kzt[1:min_rows, ]
or_type3_minrow  <- or_type3_kzt[1:min_rows, ]
or_type4_minrow  <- or_type4_kzt[1:min_rows, ]

# Creating combined the data frame
combined_or_loss <- cbind(or_type1_minrow$Loss_kzt, or_type2_minrow$Loss_kzt, 
                          or_type3_minrow$Loss_kzt, or_type4_minrow$Loss_kzt)
str(combined_or_loss)
```
```{r}
# Checking the data frame
head(combined_or_loss)
tail(combined_or_loss)
```
#### Calculation Kendall's correlation
```{r fig.align="center", fig.width=6, fig.height=4}
# Calculating Kendall's correlation matrix
kendall_corr <- cor(combined_or_loss, method = "kendall", 
                    use = "complete.obs")
print(kendall_corr)
```
```{r fig.align="center", fig.width=6, fig.height=4}
# Visualization Kendall's correlation matrix by correlation plot
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", 
                          "#77AADD", "#4477AA"))
corrplot(kendall_corr, method = "color", col = col(200),
         type = "upper", order = "hclust",
         addCoef.col = "black", 
         tl.col = "black", tl.srt = 45,
         
)
```
**Findings:** The Kendall's correlation matrix shows weak correlations between different types of Operational Risks and it can be concluded that these variables are mostly independent or have minimal linear relationships.
Changes in one Operational Risk Type have little impact on others. For modeling purposes, this low correlation structure may reduce concerns about multicollinearity in regression or stress-testing scenarios.

### Operational Risk Type 1

Calculation of frequency of Operational Risk Losses per month.


```{r}
# Calculating frequency of Operational Risk Losses per month
or_type1_bymonths <- or_type1_kzt %>% 
  mutate(YearMonth = format(Date, "%Y-%m")) %>%
  group_by(YearMonth) %>% 
  summarise(Frequency_Monthly = n())
print(or_type1_bymonths)
or_type1_bymonths <- as.data.frame(or_type1_bymonths)
head(or_type1_bymonths)
```


### Operational Risk Type 2


Calculation of frequency of Operational Risk Losses per month.


```{r}
# Calculating frequency of Operational Risk Losses per month
or_type2_bymonths <- or_type2_kzt %>% 
  mutate(YearMonth = format(Date, "%Y-%m")) %>%
  group_by(YearMonth) %>% 
  summarise(Frequency_Monthly = n())
print(or_type2_bymonths)
or_type2_bymonths <- as.data.frame(or_type2_bymonths)
head(or_type2_bymonths)
```


### Operational Risk Type 3


Calculation of frequency of Operational Risk Losses per month.


```{r}
# Calculating frequency of Operational Risk Losses per month
or_type3_bymonths <- or_type3_kzt %>% 
  mutate(YearMonth = format(Date, "%Y-%m")) %>%
  group_by(YearMonth) %>% 
  summarise(Frequency_Monthly = n())
print(or_type3_bymonths)
or_type3_bymonths <- as.data.frame(or_type3_bymonths)
head(or_type3_bymonths)
```


### Operational Risk Type 4


Calculation of frequency of Operational Risk Losses per month.


```{r}
# Calculating frequency of Operational Risk Losses per month
or_type4_bymonths <- or_type4_kzt %>% 
  mutate(YearMonth = format(Date, "%Y-%m")) %>%
  group_by(YearMonth) %>% 
  summarise(Frequency_Monthly = n())
print(or_type4_bymonths)
or_type4_bymonths <- as.data.frame(or_type4_bymonths)
head(or_type4_bymonths)
```


## Statistical tests for different distributions



In order to choose appropriate distribution for generation of
Operational Risk Losses (Impact/Severity) statistical test were applied
to historical data to choose between (Log-Normal, Normal and Weibull
distributions) and confirm that data fit chosen distributions.


### Operational Risk Type 1


#### Fitting different distributions


```{r warning=FALSE}
# Fitting historical data to Log-Normal distribution
fit_lnorm_type1 <- fitdist(or_type1_kzt$Loss_kzt, "lnorm")
summary(fit_lnorm_type1)
```


```{r warning=FALSE}
# Fitting historical data to Normal distribution
fit_norm_type1 <- fitdist(or_type1_kzt$Loss_kzt, "norm")
summary(fit_norm_type1)
```


```{r warning=FALSE}
# Fitting historical data to Weibull distribution
fit_weibull_type1 <- fitdist(or_type1_kzt$Loss_kzt, "weibull")
summary(fit_weibull_type1)
```


```{r}
# Plotting fitted Log-Normal distribution
par(mfrow = c(2, 2)) 
plot(fit_lnorm_type1)
```


```{r}
# Plotting fitted Normal distribution
par(mfrow = c(2, 2)) 
plot(fit_norm_type1)
```


```{r}
# Plotting fitted Weibull distribution
par(mfrow = c(2, 2)) 
plot(fit_weibull_type1)
```


#### Statistical tests


**Hypothesis formulation:**
The Null hypothesis (H0) the sample comes
from the reference distribution (Log-Normal/Normal/Weibull
distribution). The Alternative hypothesis (HA) is that the sample does
not come from the reference distribution (Log-Normal/Normal/ Weibull
distribution).


```{r}
# Removing duplicates from the data
or_type1_unique <- unique(or_type1_kzt$Loss_kzt)
# Kolmogorov-Smirnov test for Log-Normal distribution with unique values
ks_lnorm_type1 <- ks.test(or_type1_unique, "plnorm", 
                          meanlog = fit_lnorm_type1$estimate["meanlog"], 
                          sdlog = fit_lnorm_type1$estimate["sdlog"])
print(ks_lnorm_type1)
```


**Findings:** The p-value is very small 0.00003716 < 0.05. A very small p-value
suggests strong evidence against the Null hypothesis. The Null
hypothesis is rejected. Data does not follow Log-Normal distribution.


```{r}
# Kolmogorov-Smirnov test for Normal distribution
ks_norm_type1 <- ks.test(or_type1_unique, "pnorm", 
                         mean = fit_norm_type1$estimate["mean"], 
                         sd = fit_norm_type1$estimate["sd"])
print(ks_norm_type1)
```


**Findings:** The p-value is very small 0.00000000000000022 < 0.05. A very small p-value
suggests strong evidence against the Null hypothesis. The Null
hypothesis is rejected. Data does not follow Normal distribution.


```{r}
# Kolmogorov-Smirnov test for Weibull distribution with unique values
ks_weibull_type1 <- ks.test(or_type1_unique, "pweibull", 
                            shape = fit_weibull_type1$estimate["shape"], 
                            scale = fit_weibull_type1$estimate["scale"])
print(ks_weibull_type1)
```


**Findings:** The p-value is small =0.5356 > 0.05. A p-value suggests there is no significant evidence that your data deviates from the theoretical (Weibull) distribution. We fail to reject the Null
hypothesis. Data follow Weibull distribution.


```{r}
# Anderson-Darling test for Log-Normal Distribution
gof_lnorm_type1 <- gofstat(fit_lnorm_type1)
print(gof_lnorm_type1)
```


**Findings:** 0.0505 is the Kolmogorov-Smirnov statistic for the fit of the Log-Normal distribution. The closer this value is to 0, the better the fit. A value of 0.0505 suggests a reasonable fit.
1.3405 is the Cramer-von Mises statistic, another measure of goodness-of-fit. Like the Kolmogorov-Smirnov statistic, a smaller value indicates a better fit.
8.6006 is the Anderson-Darling statistic, which is more sensitive to discrepancies in the tails of the distribution. A larger value generally indicates a poor fit, particularly in the tails. Since 8.6006 is relatively high, it suggests that the Log-Normal distribution may not perfectly fit the data, especially in the tails.
Akaike's Information Criterion (AIC): 36,638.32
Bayesian Information Criterion (BIC): 36,648.79
These values will be compared with the results for other distributions to determine the best-fitting model.


```{r}
# Anderson-Darling test for Normal Distribution
ad_norm_type1 <- ad.test(or_type1_kzt$Loss_kzt)
print(ad_norm_type1)
```


**Findings:** The p-value is very small \< 2.2e-16. A very small p-value
suggests strong evidence against the Null hypothesis. The Null
hypothesis is rejected. Data does not follow Normal distribution.


```{r}
# Anderson-Darling test for Weibull Distribution
gof_weibull_type1 <- gofstat(fit_weibull_type1)
print(gof_weibull_type1)
```


**Findings:** 0.0234 is the Kolmogorov-Smirnov statistic for the fit of the Weibull distribution. The closer this value is to 0, the better the fit. A value of 0.0234 suggests a reasonable fit.
0.1902 is the Cramer-von Mises statistic, another measure of goodness-of-fit. Like the Kolmogorov-Smirnov statistic, a smaller value indicates a better fit.
1.3191 is the Anderson-Darling statistic, which measures the fit of the distribution more sensitively in the tails. A smaller value suggests a better fit in the tails. Since 1.3191 is relatively low, it indicates that the Weibull distribution fits the data well, including in the tails.
Akaike's Information Criterion (AIC): 36,519.45
Bayesian Information Criterion (BIC): 36,529.92
These values will be compared with results from other distributions to determine the best-fitting model.


### Operational Risk Type 2


#### Fitting different distributions


```{r warning=FALSE}
# Fitting historical data to Log-Normal distribution
fit_lnorm_type2 <- fitdist(or_type2_kzt$Loss_kzt, "lnorm")
summary(fit_lnorm_type2)
```


```{r warning=FALSE}
# Fitting historical data to Weibull distribution
fit_norm_type2 <- fitdist(or_type2_kzt$Loss_kzt, "norm")
summary(fit_norm_type2)
```


```{r warning=FALSE}
# Fitting historical data to Weibull distribution
fit_weibull_type2 <- fitdist(or_type2_kzt$Loss_kzt, "weibull")
summary(fit_weibull_type2)
```


```{r}
# Plotting fitted Log-Normal distribution
par(mfrow = c(2, 2)) 
plot(fit_lnorm_type2)
```


```{r}
# Plotting fitted Normal distribution
par(mfrow = c(2, 2)) 
plot(fit_norm_type2)
```


```{r}
# Plotting fitted Weibull distribution
par(mfrow = c(2, 2)) 
plot(fit_weibull_type2)
```


#### Statistical tests


**Formulation hypothesis:** 
The Null hypothesis (H0) the sample comes
from the reference distribution (Log-Normal/Normal/Weibull
distribution). The alternative hypothesis (HA) is that the sample does
not come from the reference distribution (Log-Normal/Normal/ Weibull
distribution).


```{r}
# Removing duplicates from the data
or_type2_unique <- unique(or_type2_kzt$Loss_kzt)
# Kolmogorov-Smirnov test for Log-Normal distribution with unique values
ks_lnorm_type2 <- ks.test(or_type2_unique, "plnorm", 
                          meanlog = fit_lnorm_type2$estimate["meanlog"], 
                          sdlog = fit_lnorm_type2$estimate["sdlog"])
print(ks_lnorm_type2)
```


**Findings:** The p-value is very small \< 0.00001325. A very small p-value
suggests strong evidence against the Null hypothesis. The Null
hypothesis is rejected. Data does not follow Log-Normal distribution.


```{r}
# Kolmogorov-Smirnov test for Normal distribution
ks_norm_type2 <- ks.test(or_type2_unique, "pnorm", mean = fit_norm_type2$estimate["mean"], 
                         sd = fit_norm_type2$estimate["sd"])
print(ks_norm_type2)
```


**Findings:** The p-value is very small \< 0.00000000000000022. A very small p-value
suggests strong evidence against the Null hypothesis. The Null
hypothesis is rejected. Data does not follow Normal distribution.


```{r}
# Kolmogorov-Smirnov test for Weibull distribution with unique values
ks_weibull_type2 <- ks.test(or_type2_unique, "pweibull", 
                            shape = fit_weibull_type2$estimate["shape"], 
                            scale = fit_weibull_type2$estimate["scale"])
print(ks_weibull_type2)
```


**Findings:** The p-value = 0.2813 > 0.05. The p-value is relatively large (0.2813), this does not provide strong evidence against the Null hypothesis, which assumes that the data follows a Weibull distribution. We fail to reject the Null hypothesis. Data may follow Weibull distribution.


```{r}
# Anderson-Darling test for Log-Normal Distribution
gof_lnorm_type2 <- gofstat(fit_lnorm_type2)
print(gof_lnorm_type2)
```


**Findings:** The Kolmogorov-Smirnov statistic for the fit of the Log-Normal distribution is 0.0613. The closer this value is to 0, the better the fit. A value of 0.0613 suggests a reasonable fit.
The Cramer-von Mises statistic is 1.8016. Like the Kolmogorov-Smirnov statistic, a smaller value indicates a better fit.
The Anderson-Darling statistic is 12.0650, which measures the fit of the distribution more sensitively for the tails of the distribution. A higher value generally indicates a poor fit, particularly in the tails. 12.0650 is relatively large, suggesting that the Log-Normal distribution may not perfectly fit the data, especially in the tails.
The Akaike's Information Criterion (AIC) = 37,961.13
The Bayesian Information Criterion (BIC) = 37,971.64 
These values will be compared with the same results for different distributions to determine the best fit.


```{r}
# Anderson-Darling test for Normal Distribution
ad_norm_type2 <- ad.test(or_type2_kzt$Loss_kzt)
print(ad_norm_type2)
```


**Findings:** The p-value is very small \< 2.2e-16. A very small p-value
suggests strong evidence against the Null hypothesis. The Null
hypothesis is rejected. Data does not follow Normal distribution.


```{r}
# Anderson-Darling test for Weibull Distribution
gof_weibull_type2 <- gofstat(fit_weibull_type2)
print(gof_weibull_type2)
```


**Findings:** The Kolmogorov-Smirnov statistic is 0.0280. Since this value is close to 0, it suggests a reasonable fit for the Weibull distribution.
The Cramer-von Mises statistic is 0.2808. Like the Kolmogorov-Smirnov statistic, a smaller value indicates a better fit.
The Anderson-Darling statistic is 1.7831, which measures the fit of the distribution more sensitively in the tails. A lower value suggests a better fit, and 1.7831 is relatively small, indicating that the Weibull distribution fits the data well.
Akaike's Information Criterion (AIC): 37,753.40
Bayesian Information Criterion (BIC): 37,763.91
These values will be compared with other distributions to determine the best fit for the data.


### Operational Risk Type 3


#### Fitting different distributions


```{r warning=FALSE}
# Fitting historical data to Log-Normal distribution
fit_lnorm_type3 <- fitdist(or_type3_kzt$Loss_kzt, "lnorm")
summary(fit_lnorm_type3)
```


```{r warning=FALSE}
# Fitting historical data to Normal distribution
fit_norm_type3 <- fitdist(or_type3_kzt$Loss_kzt, "norm")
summary(fit_norm_type3)
```


```{r warning=FALSE}
# Fitting historical data to Weibull distribution
fit_weibull_type3 <- fitdist(or_type3_kzt$Loss_kzt, "weibull")
summary(fit_weibull_type3)
```


```{r}
# Plotting fitted Log-Normal distribution
par(mfrow = c(2, 2)) 
plot(fit_lnorm_type3)
```


```{r}
# Plotting fitted Normal distribution
par(mfrow = c(2, 2)) 
plot(fit_norm_type3)
```


```{r}
# Plotting fitted Weibull distribution
par(mfrow = c(2, 2)) 
plot(fit_weibull_type3)
```


#### Statistical tests


**Formulation hypothesis:** 
The Null hypothesis (H0) the sample comes
from the reference distribution (Log-Normal/Normal/Weibull
distribution). The Alternative hypothesis (HA) is that the sample does
not come from the reference distribution (Log-Normal/Normal/ Weibull
distribution).


```{r}
# Removing duplicates from the data
or_type3_unique <- unique(or_type3_kzt$Loss_kzt)
# Kolmogorov-Smirnov test for Log-Normal distribution with unique values
ks_lnorm_type3 <- ks.test(or_type3_unique, "plnorm", 
                          meanlog = fit_lnorm_type3$estimate["meanlog"], 
                          sdlog = fit_lnorm_type3$estimate["sdlog"])
print(ks_lnorm_type3)
```


**Findings:** The p-value is 0.6867, which is large. A large p-value does not provide strong evidence against the null hypothesis.
Since the null hypothesis assumes that the data follows a Log-Normal distribution, we fail to reject it.
This suggests that the Log-Normal distribution is a good fit for the data.


```{r}
# Kolmogorov-Smirnov test for Normal distribution
ks_norm_type3 <- ks.test(or_type3_unique, "pnorm", 
                         mean = fit_norm_type3$estimate["mean"], 
                         sd = fit_norm_type3$estimate["sd"])
print(ks_norm_type3)
```


**Findings:** The p-value is very small \< 2.2e-16. A very small p-value
suggests strong evidence against the Null hypothesis. The Null
hypothesis is rejected. Data does not follow Normal distribution.


```{r}
# Kolmogorov-Smirnov test for Weibull distribution with unique values
ks_weibull_type3 <- ks.test(or_type3_unique, "pweibull", 
                            shape = fit_weibull_type3$estimate["shape"], 
                            scale = fit_weibull_type3$estimate["scale"])
print(ks_weibull_type3)
```


**Findings:** The p-value is very small (0.000005129), which provides strong evidence against the null hypothesis.
The null hypothesis assumes that the data follows a Weibull distribution.
Since we reject the null hypothesis, we conclude that the data does not follow a Weibull distribution.


```{r}
# Anderson-Darling test for Log-Normal Distribution
gof_lnorm_type3 <- gofstat(fit_lnorm_type3)
print(gof_lnorm_type3)
```


**Findings:** 0.0185 is the Kolmogorov-Smirnov statistic for the fit of the Log-Normal distribution. The closer this value is to 0, the better the fit. A value of 0.0185 suggests a reasonable fit.
0.0960 is the Cramer-von Mises statistic. Like the Kolmogorov-Smirnov statistic, a smaller value indicates a better fit.
0.6089 is the Anderson-Darling statistic, which measures the fit of the distribution more sensitively for the tails of the distribution. A lower value suggests a better fit, and 0.6089 is relatively small, indicating that the Log-Normal distribution may fit the data well.
Akaike's Information Criterion (AIC): 36,272.99 
Bayesian Information Criterion (BIC): 36,283.44 
These values will be compared with the same results for different distributions to determine the best fit.


```{r}
# Anderson-Darling test for Normal Distribution
ad_norm_type3 <- ad.test(or_type3_kzt$Loss_kzt)
print(ad_norm_type3)
```


**Findings:** The p-value is very small \< 2.2e-16. A very small p-value
suggests strong evidence against the Null hypothesis. The Null
hypothesis is rejected. Data does not follow Normal distribution.


```{r}
# Anderson-Darling test for Weibull Distribution
gof_weibull_type3 <- gofstat(fit_weibull_type3)
print(gof_weibull_type3)
```


**Findings:** 0.0726 is the Kolmogorov-Smirnov statistic for the fit of the Weibull distribution. The closer this value is to 0, the better the fit. A value of 0.0726 suggests a moderate fit.
2.6130 is the Cramer-von Mises statistic. Like the Kolmogorov-Smirnov statistic, a smaller value indicates a better fit.
18.6506 is the Anderson-Darling statistic, which measures the fit of the distribution more sensitively for the tails of the distribution. A larger value suggests a poorer fit, especially in the tails. 18.6506 is relatively large, indicating that the Weibull distribution may not perfectly fit the data, particularly in the tails.
Akaike's Information Criterion (AIC): 36,540.56 
Bayesian Information Criterion (BIC): 36,551.02 
These values will be compared with the same results for different distributions to determine the best fit.


### Operational Risk Type 4


#### Fitting different distributions


```{r warning=FALSE}
# Fitting historical data to Lognormal distribution
fit_lnorm_type4 <- fitdist(or_type4_kzt$Loss_kzt, "lnorm")
summary(fit_lnorm_type4)
```


```{r warning=FALSE}
# Fitting historical data to Normal distribution
fit_norm_type4 <- fitdist(or_type4_kzt$Loss_kzt, "norm")
summary(fit_norm_type4)
```


```{r warning=FALSE}
# Fitting historical data to Weibull distribution
fit_weibull_type4 <- fitdist(or_type4_kzt$Loss_kzt, "weibull")
summary(fit_weibull_type4)
```


```{r}
# Plotting fitted Log-Normal distribution
par(mfrow = c(2, 2)) 
plot(fit_lnorm_type4)
```


```{r}
# Plotting fitted Normal distribution
par(mfrow = c(2, 2)) 
plot(fit_norm_type4)
```


```{r}
# Plotting fitted Weibull distribution
par(mfrow = c(2, 2)) 
plot(fit_weibull_type4)
```



#### Statistical tests


**Formulation hypothesis:** 
The Null hypothesis (H0) the sample comes
from the reference distribution (Log-Normal/Normal/Weibull
distribution). The Alternative hypothesis (HA) is that the sample does
not come from the reference distribution (Log-Normal/Normal/ Weibull
distribution).


```{r}
# Removing duplicates from the data
or_type4_unique <- unique(or_type4_kzt$Loss_kzt)
# Kolmogorov-Smirnov test for Lognormal distribution with unique values
ks_lnorm_type4 <- ks.test(or_type4_unique, "plnorm", 
                          meanlog = fit_lnorm_type4$estimate["meanlog"], 
                          sdlog = fit_lnorm_type4$estimate["sdlog"])
print(ks_lnorm_type4)
```


**Findings:** The p-value is small 0.03535 <0.05. A small p-value
suggests evidence against the Null hypothesis. The Null
hypothesis is rejected. Data does not follow Log-Normal distribution.


```{r}
# Kolmogorov-Smirnov test for Normal distribution
ks_norm_type4 <- ks.test(or_type4_unique, "pnorm", 
                         mean = fit_norm_type4$estimate["mean"], 
                         sd = fit_norm_type4$estimate["sd"])
print(ks_norm_type4)
```


**Findings:** The p-value is very small \< 2.2e-16. A very small p-value
suggests strong evidence against the Null hypothesis. The Null
hypothesis is rejected. Data does not follow Normal distribution.


```{r}
# Kolmogorov-Smirnov test for Weibull distribution with unique values
ks_weibull_type4 <- ks.test(or_type4_unique, "pweibull", 
                            shape = fit_weibull_type4$estimate["shape"], 
                            scale = fit_weibull_type4$estimate["scale"])
print(ks_weibull_type4)
```


**Findings:** The p-value is very small = 0.0000004787. A very small
p-value suggests strong evidence against the Null hypothesis. The Null
hypothesis is rejected. Data does not follow Weibull distribution.


```{r}
# Anderson-Darling test for Lognormal Distribution
gof_lnorm_type4 <- gofstat(fit_lnorm_type4)
print(gof_lnorm_type4)
```


**Findings:** Kolmogorov-Smirnov statistic: 0.0453 → A smaller value suggests a better fit, and 0.0453 indicates a reasonable fit.
Cramer-von Mises statistic: 1.0102 → A smaller value indicates a better fit; however, 1.0102 is moderately high, meaning the fit may not be perfect.
Anderson-Darling statistic: 7.6099 → This statistic is more sensitive to the tails of the distribution. A value of 7.61 is relatively large, which suggests the Log-Normal distribution may not be the best fit, particularly in the tails.
AIC (Akaike’s Information Criterion): 29,924.04
BIC (Bayesian Information Criterion): 29,935.18. 
These values should be compared with the AIC/BIC of other distributions to determine the best fit.


```{r}
# Anderson-Darling test for Normal Distribution
ad_norm_type4 <- ad.test(or_type4_kzt$Loss_kzt)
print(ad_norm_type4)
```


**Findings:** The p-value is very small \< 2.2e-16. A very small p-value
suggests strong evidence against the Null hypothesis. The Null
hypothesis is rejected. Data does not follow Normal distribution.


```{r}
# Anderson-Darling test for Weibull Distribution
gof_weibull_type4 <- gofstat(fit_weibull_type4)
print(gof_weibull_type4)
```


**Findings:** Kolmogorov-Smirnov statistic: 0.0774 → A smaller value suggests a better fit, but 0.0774 is relatively high, indicating a moderate fit at best.
Cramer-von Mises statistic: 1.8786 → A smaller value is better, but 1.8786 is relatively large, meaning the fit is not ideal.
Anderson-Darling statistic: 14.5589 → This statistic is more sensitive to the tails of the distribution. A value of 14.56 is quite large, suggesting the Weibull distribution may not fit the data well, especially in the tails.
AIC (Akaike’s Information Criterion): 35,467.93
BIC (Bayesian Information Criterion): 35,478.35. 
These values should be compared with those of other distributions to determine the best fit.


### Choosing better fit for the different types of Operational Risks


**Summary:** 

*Normal:* Normal distribution will not be considered for statistical
modelling as data for all types of Operational Risks show skewed
distribution and also fitting data to Normal Distribution failed
statistical tests for all types of Operational Risks.


#### Operational Risk Type 1:


*Log-Normal:* Kolmogorov-Smirnov: 0.05046176 Cramer-von Mises: 1.34054128
Anderson-Darling: 8.60063520 Akaike's Information Criterion (AIC): 36638.32
Bayesian Information Criterion (BIC): 36648.79.


*Weibull:* Kolmogorov-Smirnov: 0.0234092 Cramer-von Mises: 0.1902371
Anderson-Darling: 1.3191119 Akaike's Information Criterion (AIC): 36519.45
Bayesian Information Criterion (BIC): 36529.92 Better Fit: Weibull, as
it has lower values across all test statistics (KS, CvM, AD, AIC, and
BIC).



#### Operational Risk Type 2:


*Log-Normal:* Kolmogorov-Smirnov: 0.06131419 Cramer-von Mises: 0.1902371
Anderson-Darling: 1.3191119 Akaike's Information Criterion (AIC): 37961.13
Bayesian Information Criterion (BIC): 37971.64.


*Weibull:* Kolmogorov-Smirnov: 0.02803716 Cramer-von Mises: 0.28084810
Anderson-Darling: 1.78313270 Akaike's Information Criterion (AIC): 37753.40
Bayesian Information Criterion (BIC): 37763.91 Better Fit: Weibull, as
it has lower test statistics across the board (KS, CvM, AD, AIC, and
BIC).



#### Operational Risk Type 3:


*Log-Normal:* Kolmogorov-Smirnov: 0.01847924 Cramer-von Mises: 0.09596050
Anderson-Darling: 0.60888939 Akaike's Information Criterion (AIC): 36272.99
Bayesian Information Criterion (BIC): 36283.44.


*Weibull:* Kolmogorov-Smirnov: 0.07255944 Cramer-von Mises: 2.61295261
Anderson-Darling: 18.65059489 Akaike's Information Criterion (AIC): 36540.56
Bayesian Information Criterion (BIC): 36551.02 Better Fit: Log-normal,
as it has lower values for Kolmogorov-Smirnov, Cramer-von Mises,
Anderson-Darling, AIC, and BIC.



#### Operational Risk Type 4:



*Log-Normal:* Kolmogorov-Smirnov: 0.0394907 Cramer-von Mises: 0.5633883
Anderson-Darling: 4.0527426 Akaike's Information Criterion (AIC): 35258.06
Bayesian Information Criterion (BIC): 35268.48.


*Weibull:* Kolmogorov-Smirnov: 0.07744793 Cramer-von Mises: 1.87862934
Anderson-Darling: 14.55892202 Akaike's Information Criterion (AIC): 35467.93
Bayesian Information Criterion (BIC): 35478.35 Better Fit: Log-normal,
as it has lower values for all test statistics (KS, CvM, AD, AIC, and
BIC).


```{r}
# Creating the summary data frame for the best-fit distributions
best_fit_summary <- data.frame(
  `OR Type` = c("Type 1", "Best Fit: Weibull", 
                              "Type 2", "Best Fit: Weibull", 
                              "Type 3", "Best Fit: Log-Normal", 
                              "Type 4", "Best Fit: Log-Normal"),
  
  `K-S` = c("", "0.0234 (Weibull) < 0.0505 (Log-Normal)", 
                           "", "0.0280 (Weibull) < 0.0613 (Log-Normal)", 
                           "", "0.0185 (Log-Normal) < 0.0726 (Weibull)", 
                           "", "0.0395 (Log-Normal) < 0.0774 (Weibull)"),
  
  `C-M` = c("", "0.190 (Weibull) < 1.340 (Log-Normal)", 
                         "", "0.2808 (Weibull) < 1.8016 (Log-Normal)", 
                         "", "0.0960 (Log-Normal) < 2.6129 (Weibull)", 
                         "", "0.5634 (Log-Normal) < 1.8786 (Weibull)"),
  
  `A-D` = c("", "1.319 (Weibull) < 8.601 (Log-Normal)", 
                         "", "1.783 (Weibull) < 12.065 (Log-Normal)", 
                         "", "0.609 (Log-Normal) < 18.6506 (Weibull)", 
                         "", "4.0527 (Log-Normal) < 14.5589 (Weibull)"),
  
  `AIC` = c("", "36519.45 (Weibull) < 36638.32 (Log-Normal)", 
                              "", "37753.40 (Weibull) < 37961.13 (Log-Normal)", 
                              "", "36272.99 (Log-Normal) < 36540.56 (Weibull)", 
                              "", "35258.06 (Log-Normal) < 35467.93 (Weibull)"),
  
  `BIC` = c("", "36529.92 (Weibull) < 36648.79 (Log-Normal)", 
                              "", "37763.91 (Weibull) < 37971.64 (Log-Normal)", 
                              "", "36283.44 (Log-Normal) < 36551.02 (Weibull)", 
                              "", "35268.48 (Log-Normal) < 35478.35 (Weibull)")
)

# Creating the kable table
kable(best_fit_summary, format = "markdown", digits = 5, 
      caption = "Best Fit Distribution for Each Operational Risk Type")

```

**Findings:** 
Operational Risk Type 1
Weibull has lower values for KS (0.0234 vs. 0.0505), CvM (0.190 vs. 1.340), and AD (1.319 vs. 8.601).
Weibull has a lower AIC (36519.45 vs. 36638.32) and BIC (36529.92 vs. 36648.79).
Best Fit: Weibull Distribution
Operational Risk Type 2
Weibull has lower values for KS (0.0280 vs. 0.0613), CvM (0.2808 vs. 1.8016), and AD (1.783 vs. 12.065).
Weibull has a lower AIC (37753.40 vs. 37961.13) and BIC (37763.91 vs. 37971.64).
Best Fit: Weibull Distribution
Operational Risk Type 3
Log-Normal has a significantly lower KS (0.0185 vs. 0.0726), CvM (0.0960 vs. 2.6129), and AD (0.609 vs. 18.6506).
Log-Normal has a lower AIC (36272.99 vs. 36540.56) and BIC (36283.44 vs. 36551.02).
Best Fit: Log-Normal Distribution
Operational Risk Type 4
Log-Normal has a lower KS (0.0395 vs. 0.0774), CvM (0.5634 vs. 1.8786), and AD (4.0527 vs. 14.5589).
Log-Normal has a lower AIC (35258.06 vs. 35467.93) and BIC (35268.48 vs. 35478.35).
Best Fit: Log-Normal Distribution


**Conclusion:** Based on the above, the Weibull Distribution is chosen for Operational
Risk Type 1 and Type 2, and Log-Normal Distribution is chosen for
Operational Risk Type 3 and Type 4.

## Statistical Modelling of distributions

### Modelling Poisson Distribution

Poisson distribution will be used to generate frequency (number) of
Operational Risk Events for all 4 types of Operational Risks.

#### Operational Risk Type 1

```{r}
# Calculation lambda or mean of Operational Risks per month
head(or_type1_bymonths)
lambda_or_type1_bymonths <- mean(or_type1_bymonths$Frequency_Monthly)
print(lambda_or_type1_bymonths)
```


```{r}
# Generation of Poisson Distribution for Operational Risk Type 1
set.seed(123)
poisson_or_type1 <- rpois(n = 100000, 
                          lambda = lambda_or_type1_bymonths)
head(poisson_or_type1)
tail(poisson_or_type1)
```



#### Operational Risk Type 2



```{r}
# Calculation lambda or mean of Operational Risks per month
head(or_type2_bymonths)
lambda_or_type2_bymonths <- mean(or_type2_bymonths$Frequency_Monthly)
print(lambda_or_type2_bymonths)
```


```{r}
# Generation of Poisson Distribution for Operational Risk Type 2
set.seed(456)
poisson_or_type2 <- rpois(n = 100000, 
                          lambda = lambda_or_type2_bymonths)
head(poisson_or_type2)
tail(poisson_or_type2)
```



#### Operational Risk Type 3



```{r}
# Calculation lambda or mean of Operational Risks per month
head(or_type3_bymonths)
lambda_or_type3_bymonths <- mean(or_type3_bymonths$Frequency_Monthly)
print(lambda_or_type3_bymonths)
```


```{r}
# Generation of Poisson Distribution for Operational Risk Type 3
set.seed(789)
poisson_or_type3 <- rpois(n = 100000, 
                          lambda = lambda_or_type3_bymonths)
head(poisson_or_type3)
tail(poisson_or_type3)
```



#### Operational Risk Type 4



```{r}
# Calculation lambda or mean of Operational Risks per month
head(or_type4_bymonths)
lambda_or_type4_bymonths <- mean(or_type4_bymonths$Frequency_Monthly)
print(lambda_or_type4_bymonths)
```


```{r}
# Generation of Poisson Distribution for Operational Risk Type 4
set.seed(012)
poisson_or_type4 <- rpois(n = 100000, 
                          lambda = lambda_or_type4_bymonths)
head(poisson_or_type4)
tail(poisson_or_type4)

```




### Modelling Weibull Distribution




Weibull distribution will be used to generate amounts (impact/severity)
of Operational Risk Events for Operational Risks Type 1 and Type 2.




#### Operational Risk Type 1




```{r warning=FALSE}
# Estimating shape and scale parameters (fitting Weibull distribution) for Operational Risk Type 1
fit_weibull_type1 <- fitdist(or_type1_kzt$Loss_kzt, "weibull")
# Getting estimated parameters
shape_or_type1 <- fit_weibull_type1$estimate["shape"]
scale_or_type1 <- fit_weibull_type1$estimate["scale"]
```


```{r}
# Generating Weibull distribution with estimated parameters for Operational Risk Type 1
set.seed(123)
weibull_or_type1 <- rweibull(n = 100000, 
                             shape = shape_or_type1, 
                             scale = scale_or_type1)
# View the first few generated values
head(weibull_or_type1)
```




#### Operational Risk Type 2




```{r warning=FALSE}
# Estimating shape and scale parameters (fitting Weibull distribution) for Operational Risk Type 2
fit_weibull_type2 <- fitdist(or_type2_kzt$Loss_kzt, "weibull")
# Getting estimated parameters
shape_or_type2 <- fit_weibull_type2$estimate["shape"]
scale_or_type2 <- fit_weibull_type2$estimate["scale"]
```



```{r}
# Generating Weibull distribution with estimated parameters for Operational Risk Type 2
set.seed(456)
weibull_or_type2 <- rweibull(n = 100000, 
                             shape = shape_or_type2, 
                             scale = scale_or_type2)
# View the first few generated values
head(weibull_or_type2)
```



### Modelling Log-Normal Distribution




Log-Normal distribution will be used to generate amounts
(impact/severity) of Operational Risk Events for Operational Risks Type
3 and Type 4.




#### Operational Risk Type 3




```{r warning=FALSE}
# Estimating meanlog and sdlog parameters (fit Log-Normal distribution) for Operational Risk Type 3
fit_lnorm_type3 <- fitdist(or_type3_kzt$Loss_kzt, "lnorm")
# Getting estimated parameters
meanlog_type3 <- fit_lnorm_type3$estimate["meanlog"]
sdlog_type3 <- fit_lnorm_type3$estimate["sdlog"]
```



```{r}
# Generating Log-Normal distribution with estimated parameters for Operational Risk Type 3
set.seed(789)
lnorm_or_type3 <- rlnorm(n = 100000, 
                         meanlog = meanlog_type3, 
                         sdlog = sdlog_type3)
# Viewing the first few generated values
head(lnorm_or_type3)
```




#### Operational Risk Type 4




```{r warning=FALSE}
# Estimating meanlog and sdlog parameters (fit Log-Normal distribution) for Operational Risk Type 4
fit_lnorm_type4 <- fitdist(or_type4_kzt$Loss_kzt, "lnorm")
# Getting estimated parameters
meanlog_type4 <- fit_lnorm_type4$estimate["meanlog"]
sdlog_type4 <- fit_lnorm_type4$estimate["sdlog"]
```


```{r}
# Generating Log-Normal distribution with estimated parameters for Operational Risk Type 4
set.seed(012)
lnorm_or_type4 <- rlnorm(n = 100000, 
                         meanlog = meanlog_type4, 
                         sdlog = sdlog_type4)
# View the first few generated values
head(lnorm_or_type4)
```



## Operational Risk Value-at-Risk Computation



### Data preprocessing



Creation of combined data frame of all generated distributions (Poisson,
Weibull and Log-Normal) for all types of Operational Risks.



```{r}
# Creating combined data frame
generated_data <- data.frame(Poisson_OR_Type1 = poisson_or_type1, 
                             Poisson_OR_Type2 = poisson_or_type2,
                             Poisson_OR_Type3 = poisson_or_type3, 
                             Poisson_OR_Type4 = poisson_or_type4,
                             Weibull_OR_Type1 = weibull_or_type1, 
                             Weibull_OR_Type2 = weibull_or_type2,
                             Lognorm_OR_Type3 = lnorm_or_type3, 
                             Lognorm_OR_Type4 = lnorm_or_type4)
```


```{r}
# Checking data frame
head(generated_data)
tail(generated_data)
```



**Findings:** All variables have 100000 observations with proper data
types.



Multiplication (product) of frequency (number) of Operational Risk
Losses and amounts (impact/severity) of Operational Risk Losses for each
Type of Operational Risk and calculation of Total Operational Risk
Losses.


```{r}
generated_data$OR_Loss_Type1 <- generated_data$Poisson_OR_Type1 * generated_data$Weibull_OR_Type1
generated_data$OR_Loss_Type2 <- generated_data$Poisson_OR_Type2 * generated_data$Weibull_OR_Type2
generated_data$OR_Loss_Type3 <- generated_data$Poisson_OR_Type3 * generated_data$Lognorm_OR_Type3
generated_data$OR_Loss_Type4 <- generated_data$Poisson_OR_Type4 * generated_data$Lognorm_OR_Type4
generated_data$Total_OR_Losses <- generated_data$OR_Loss_Type1 + generated_data$OR_Loss_Type2 +
  generated_data$OR_Loss_Type3 + generated_data$OR_Loss_Type4
```


```{r}
# Checking created data frame
summary(generated_data)
str(generated_data)
glimpse(generated_data)
```


### Visualization of generated distributions



#### Operational Risk Type 1


```{r fig.align="center", fig.width=6, fig.height=4}
# Histogram of distribution of Operational Risk Type 1
ggplot(data = generated_data, aes(x = OR_Loss_Type1 / 1000)) +
  geom_histogram(binwidth = 1000, fill = "blue", 
                 color = "grey", alpha = 0.7) +
  labs(title = "Histogram of Operational Risk Type 1", 
       x = "Operational Risk Loss (Thousands KZT)", 
       y = "Frequency") +
  theme_minimal()
```


```{r fig.align="center", fig.width=6, fig.height=4}
# Boxplot of distribution of Operational Risk Type 1
ggplot(data = generated_data, aes(x = OR_Loss_Type1/1000)) +
  geom_boxplot(fill = "blue", 
               color = "black", alpha = 0.7) +
  labs(title = "Boxplot of Operational Risk Type 1", 
       x = "Operational Risk Loss (Thousands KZT)") +
  theme_minimal()
```
**Findings:** The histogram and boxplot show presence of outliers, which
are also confirmed by significant difference in mean and median.


#### Operational Risk Type 2



```{r fig.align="center", fig.width=6, fig.height=4}
# Histogram of distribution of Operational Risk Type 2
ggplot(data = generated_data, aes(x = OR_Loss_Type2/1000)) +
  geom_histogram(binwidth = 1000, fill = "green", 
                 color = "black", alpha = 0.7) +
  labs(title = "Histogram of Operational Risk Type 2", 
       x = "Operational Risk Loss (Thousands KZT)", y = "Frequency") +
  theme_minimal()
```


```{r fig.align="center", fig.width=6, fig.height=4}
# Boxplot of distribution of Operational Risk Type 2
ggplot(data = generated_data, aes(x = OR_Loss_Type2/1000)) +
  geom_boxplot(fill = "green", 
               color = "black", alpha = 0.7) +
  labs(title = "Boxplot of Operational Risk Type 2", 
       x = "Operational Risk Loss (Thousands KZT)") +
  theme_minimal()
```
**Findings:** The histogram and boxplot show presence of outliers, which
are also confirmed by significant difference in mean and median.

#### Operational Risk Type 3



```{r fig.align="center", fig.width=6, fig.height=4}
# Histogram of distribution of Operational Risk Type 3
ggplot(data = generated_data, aes(x = OR_Loss_Type3/1000)) +
  geom_histogram(binwidth = 1000, 
                 fill = "red", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Operational Risk Type 3", 
       x = "Operational Risk Loss (Thousands KZT)", y = "Frequency") +
  scale_x_continuous(labels = scales::label_number()) +
  scale_y_continuous(labels = scales::label_number()) +
  theme_minimal()
```


```{r fig.align="center", fig.width=6, fig.height=4}
# Boxplot of distribution of Operational Risk Type 3
ggplot(data = generated_data, aes(x = OR_Loss_Type3/1000)) +
  geom_boxplot(fill = "blue", 
               color = "black", alpha = 0.7) +
  labs(title = "Boxplot of Operational Risk Losses Type 3", 
       x = "Operational Risk Loss (Thousands KZT)") +
  scale_x_continuous(labels = scales::label_number()) +
  scale_y_continuous(labels = scales::label_number()) +
  theme_minimal()
```
**Findings:** The histogram and boxplot show presence of outliers, which
are also confirmed by significant difference in mean and median.

#### Operational Risk Type 4


```{r fig.align="center", fig.width=6, fig.height=4}
# Histogram of distribution of Operational Risk Type 4
ggplot(data = generated_data, aes(x = OR_Loss_Type4/1000)) +
  geom_histogram(binwidth = 1000, fill = "skyblue", 
                 color = "black", alpha = 0.7) +
  labs(title = "Histogram of Operational Risk Losses Type 4", 
       x = "Operational Risk Loss (KZT)", y = "Frequency") +
  scale_x_continuous(labels = scales::label_number()) +
  scale_y_continuous(labels = scales::label_number()) +
  theme_minimal()
```


```{r fig.align="center", fig.width=6, fig.height=4}
# Boxplot of distribution of Operational Risk Type 4
ggplot(data = generated_data, aes(x = OR_Loss_Type4/1000)) +
  geom_boxplot(fill = "skyblue", 
               color = "black", alpha = 0.7) +
  labs(title = "Boxplot of Operational Risk Losses Type 4", 
       x = "Operational Risk Loss (Thousands KZT)") +
  scale_x_continuous(labels = scales::label_number()) +
  scale_y_continuous(labels = scales::label_number()) +
  theme_minimal()
```
**Findings:** The histogram and boxplot show presence of outliers, which
are also confirmed by significant difference in mean and median.

### Total Operational Risk Losses


```{r fig.align="center", fig.width=6, fig.height=4}
# Histogram of distribution of Total Operational Risk Losses
ggplot(data = generated_data, aes(x = Total_OR_Losses/1000)) +
  geom_histogram(binwidth = 4000, fill = "yellow", 
                 color = "black", alpha = 0.7) +
  labs(title = "Histogram of Total Operational Risk Losses", 
       x = "Operational Risk Loss (Thousands KZT)", y = "Frequency") +
  scale_x_continuous(labels = scales::label_number()) +
  scale_y_continuous(labels = scales::label_number()) +
  theme_minimal()
```


```{r fig.align="center", fig.width=6, fig.height=4}
# Boxplot of distribution of Total Operational Risk Losses
ggplot(data = generated_data, aes(x = Total_OR_Losses/1000)) +
  geom_boxplot(fill = "yellow", 
               color = "black", alpha = 0.7) +
  labs(title = "Boxplot of Total Operational Risk Losses", 
       x = "Operational Risk Loss (Thousands KZT)") +
  scale_x_continuous(labels = scales::label_number()) +
  scale_y_continuous(labels = scales::label_number()) +
  theme_minimal()
```
**Findings:** The histogram and boxplot show presence of outliers, which
are also confirmed by significant difference in mean and median.

## Operational Risk Value-at-Risk (VaR) computation


Operational Risk Value-at-Risk (VaR) is calculated for confidence levels: 75%,
95%, 99% and 99.9%.


```{r}
# Computation of Operational Risk Value-at-Risk
probs <- c(0.75, 0.95, 0.99, 0.999)
or_var <- quantile(generated_data$Total_OR_Losses, probs)
print(or_var)
```


```{r}
# Converting data to a data frame and changing column name
or_var <- as.data.frame(or_var)
colnames(or_var) <- "var_monthly"
head(or_var)
```


Calculation of monthly Expected Loss (mean), Expected Loss (median),
Unexpected Loss (mean) and Unexpected Loss (median) and calculation of
yearly Value-at-Risk by multiplication of monthly Value-at-Risk (VaR) by
square root of 12. In addition, calculation yearly Expected Loss (mean),
Expected Loss (median), Unexpected Loss (mean) and Unexpected Loss
(median).


```{r}
# Perform the calculation
or_var$EL_mean_monthly <- mean(generated_data$Total_OR_Losses)
or_var$EL_median_monthly <- median(generated_data$Total_OR_Losses)
or_var$UL_mean_monthly <- or_var$var_monthly - or_var$EL_mean_monthly
or_var$UL_median_monthly <- or_var$var_monthly - or_var$EL_median_monthly
or_var$var_quarterly <- or_var$var_monthly * sqrt(3)
or_var$EL_mean_quarterly <- or_var$EL_mean_monthly * 3
or_var$EL_median_quarterly <- or_var$EL_median_monthly * 3
or_var$UL_mean_quarterly <- or_var$var_quarterly - or_var$EL_mean_quarterly
or_var$UL_median_quarterly <- or_var$var_quarterly - or_var$EL_median_quarterly
or_var$var_yearly <- or_var$var_monthly * sqrt(12)
or_var$EL_mean_yearly <- or_var$EL_mean_monthly * 12
or_var$EL_median_yearly <- or_var$EL_median_monthly * 12
or_var$UL_mean_yearly <- or_var$var_yearly - or_var$EL_mean_yearly
or_var$UL_median_yearly <- or_var$var_yearly - or_var$EL_median_yearly
```


```{r}
# Checking Operational Risk Value-at-Risk computation data frame
print(or_var)
or_var <- t(or_var)
print(or_var)
```
# Scenario Forecasting (Stress Testing of Operational Risk)
Scenario Forecasting will be conducted for 2 scenarios: positive and negative. The projection of Operational Risk losses will be taken as the average of projections of 2 modelling approaches: Regression Model and Historical Simulation Model. This methodology is described and used in the Federal Reserve System Supervisory Stress Test Methodology (Dodd-Frank Act Stress Test). As per this methodology the Regression Model captures the sensitivity of the Operational Risk losses to changes in the macroeconomic environment and Historical Simulation Model captures the variations of Operational Risk losses across types of Operational Risk events. 

### Operational Risk Stress Testing Summary Table
```{r}
# Creating the summary data frame for the stress testing results 
# with hierarchical and unique row names
stresstest_summary <- data.frame(
  Scenario = c("Positive scenario", "2017 Q1 - Positive", 
               "2017 Q2 - Positive", "2017 Q3 - Positive", 
               "2017 Q4 - Positive", "Negative scenario", 
               "2017 Q1 - Negative", "2017 Q2 - Negative", 
               "2017 Q3 - Negative", "2017 Q4 - Negative"),
  `Linear` = c("KZT", 46228220, 43127346, 
               39583768, 36771242, 
               "KZT", 52068502, 52890742, 
               54506252, 54684134),
  `GAM` = c("KZT", 25739693, 26743844, 
            27772016, 27999022, 
            "KZT", 63592518, 63303944, 
            62478167, 61240187),
  `LDA` = c("KZT", 45657995, 45657995, 
            45657995, 45657995, 
            "KZT", 91139796, 91139796, 
            91139796, 91139796),
  `Avg (Linear & LDA)` = c("KZT", 
                            round(rowMeans(cbind(46228220, 45657995))), 
                            round(rowMeans(cbind(43127346, 45657995))), 
                            round(rowMeans(cbind(39583768, 45657995))), 
                            round(rowMeans(cbind(36771242, 45657995))), 
                            "KZT", 
                            round(rowMeans(cbind(52068502, 91139796))), 
                            round(rowMeans(cbind(52890742, 91139796))), 
                            round(rowMeans(cbind(54506252, 91139796))), 
                            round(rowMeans(cbind(54684134, 91139796)))),
  `Avg (GAM & LDA)` = c("KZT", 
                         round(rowMeans(cbind(25739693, 45657995))), 
                         round(rowMeans(cbind(26743844, 45657995))), 
                         round(rowMeans(cbind(27772016, 45657995))), 
                         round(rowMeans(cbind(27999022, 45657995))), 
                         "KZT", 
                         round(rowMeans(cbind(63592518, 91139796))), 
                         round(rowMeans(cbind(63303944, 91139796))), 
                         round(rowMeans(cbind(62478167, 91139796))), 
                         round(rowMeans(cbind(61240187, 91139796)))),
  `Poisson` = c("QTY", 568, 999, 
                1760, 3101, 
                "QTY", 162, 139, 
                126, 115)
)

kable(stresstest_summary, format = "markdown", digits = 0, 
      caption = "Stress Testing Summary for Operational Risk")

```

### Final Conclusion
Stress testing of Operational Risk was conducted using the following approaches:

Severity Prediction: Multiple Linear Regression (MLR) and the Generalized Additive Model (GAM) were used to predict the severity of losses.
Frequency Prediction: Multiple Poisson Regression was applied to estimate the frequency (number) of Operational Risk losses. A statistical threshold of 0.35 (35%) for R^2 and an alpha level of 0.1 (90% confidence) were used as evaluation criteria.
Value-at-Risk Estimation: Monte Carlo simulation was employed to estimate Operational Risk Value-at-Risk (VaR) at 95%, 99%, and 99.9% confidence levels.
Model Selection and Performance
Since the assumptions of linearity and normality were not fully met for MLR, alternative non-linear models were tested, including second-degree, third-degree, and sixth-degree Polynomial Regression models, as well as GAM.

Polynomial Regression models yielded higher R^2 values:

Second-degree: R^2 = 0.449 (44.9%)
Third-degree: R^2 = 0.562 (56.2%)
Sixth-degree: R^2 = 0.867 (86.7%)
However, all p-values for independent variables exceeded the alpha threshold of 0.1, making them statistically insignificant. As a result, these models were not used for stress testing.
Generalized Additive Model (GAM):

Adjusted R^2 = 0.359 (35.9%)
Explained 44% of the deviance
All p-values were below the alpha threshold of 0.1
Multiple Linear Regression (MLR):

R^2 = 0.4426 (44.3%)
Adjusted R^2 = 0.359 (35.9%)
All p-values were below 0.1
Since GAM and MLR both met the statistical significance criteria, the null hypothesis (H0) was rejected in favor of the alternative hypothesis (HA), confirming a relationship between Operational Risk losses and macroeconomic variables.

**Optimal Model for Predicting Loss Severity**

The optimal model was selected from 1,330 possible combinations of independent macroeconomic variables based on the highest R^2 (Coefficient of Determination) and statistical tests. The most effective model for predicting the amount (severity) of Operational Risk losses was determined using the following independent variables from the "AFR" R package dataset:

GDD_Trn_R_y: Real Gross Value Added for Transportation

GDD_Inf_R_y: Real Gross Value Added for Information

Rincpop_q_y: Real Population Average Monthly Income

The dependent variable was the proportion of total Operational Risk losses in the assets of Bank "X", which were taken as total assets of banking system.

**Frequency of Losses**

Multiple Poisson Regression was employed to estimate the frequency of losses. The results indicated that Multiple Poisson Regression provided reasonable predictions, with Multiple Negative Binomial Regression closely aligning with its outcomes. A statistical threshold of 0.35 (35%) for R^2 and an alpha level of 0.1 (90% confidence) were maintained.

The best model for predicting loss frequency was identified using Multiple Poisson Regression with the following independent variables:

ruktzt: RUB/KZT exchange rate

Rincpop_q_y: Real Population Average Monthly Income

GDD_R_y: Real Gross Value Added

The dependent variable was the total frequency of Operational Risk losses for Bank "X". The Pseudo R^2 for this model was 0.48 (r2ML, r2CU), with all p-values below the 0.1 threshold. Consequently, the null hypothesis (H0) was rejected in favor of the alternative hypothesis (Ha), reinforcing the correlation between frequency of Operational Risk losses and macroeconomic variables.

**Correlation Analysis**

Across all models, a negative correlation was observed between independent and dependent variables.

**Predicted Outcomes**

**Multiple Linear Regression (Loss Severity)**

Positive Scenario:

Highest loss: KZT 46,228,220

Lowest loss: KZT 36,771,242

Negative Scenario:

Highest loss: KZT 54,684,134

Lowest loss: KZT 52,068,502

**Generalized Additive Model (Loss Severity)**

Positive Scenario:

Highest loss: KZT 27,999,022

Lowest loss: KZT 25,739,693

Negative Scenario:

Highest loss: KZT 63,592,518

Lowest loss: KZT 61,240,187

**Multiple Poisson Regression (Loss Frequency)**

Positive Scenario:

Highest frequency: 3,101

Lowest frequency: 568

Negative Scenario:

Highest frequency: 162

Lowest frequency: 115

**Historical Simulation Model**
Computation of Operational Risk Value-at-Risk (VaR)
Operational Risk Value-at-Risk (VaR) was computed using the Poisson Distribution to model the frequency (number) of Operational Risk events and Weibull and Log-Normal Distributions to model the severity (impact) of Operational Risk events. These distributions were selected based on statistical estimation results.

**Monthly Expected Loss (EL)**
The Expected Loss (EL), representing the mathematical expectation, was KZT 13,512,161 for the mean value and KZT 12,173,884 for the median value. These values remained consistent across all confidence intervals (75%, 95%, 99%, and 99.9%).

**Monthly Operational Risk Value-at-Risk (VaR)**
At a 95% confidence level, the monthly VaR was KZT 26,360,656, with an Unexpected Loss (UL) of KZT 12,848,494 based on the mean and KZT 14,186,771 based on the median.

At a 99% confidence level, the monthly VaR increased to KZT 35,823,119, with an Unexpected Loss (UL) of KZT 22,310,958 for the mean and KZT 23,649,235 for the median.

At a 99.9% confidence level, the monthly VaR reached KZT 52,619,586, while the Unexpected Loss (UL) was KZT 39,107,424 for the mean and KZT 40,445,701 for the median.

**Quarterly Expected Loss (EL)**
The Expected Loss (EL) was scaled linearly over time by multiplying the monthly EL by 3. As a result, the quarterly EL was KZT 40,536,484 for the mean and KZT 36,521,653 for the median, remaining the same across all confidence intervals.

Quarterly Operational Risk Value-at-Risk (VaR)
Quarterly VaR was computed by multiplying the monthly VaR by the square root of 3.

At a 95% confidence level, the quarterly VaR was KZT 45,657,995, with an Unexpected Loss (UL) of KZT 5,121,511 for the mean and KZT 9,136,341 for the median.

At a 99% confidence level, the quarterly VaR increased to KZT 62,047,463, while the Unexpected Loss (UL) was KZT 21,510,979 for the mean and KZT 25,525,810 for the median.

At a 99.9% confidence level, the quarterly VaR was KZT 91,139,796, with an Unexpected Loss (UL) of KZT 50,603,312 for the mean and KZT 54,618,143 for the median.

**Operational Risk Loss Estimates**
Final Operational Risk Loss estimates are derived as the average of projections of 2 modelling approaches: 1) Regression Model and 2) Historical Simulation Model, and are following:

**Average of Multiple Linear Regression (Loss Severity) and Monte-Carlo Simulation (95% and 99.9% confidence levels)**

Positive Scenario:

Highest loss: KZT 45,943,965

Lowest loss: KZT 41,214,107

Negative Scenario:

Highest loss: KZT 72,911,965

Lowest loss: KZT 71,604,149

**Average of Generalized Additive Model (Loss Severity) and Monte-Carlo Simulation (95% and 99.9% confidence levels)**

Positive Scenario:

Highest loss: KZT 36,828,508

Lowest loss: KZT 35,698,844

Negative Scenario:

Highest loss: KZT 77,366,157

Lowest loss: KZT 76,189,991.

**Final Considerations**

The results of this stress testing should be interpreted with caution, as certain modeling assumptions, such as linearity and normality in Regression Models, were not fully met. However, despite these limitations, the findings offer meaningful insights into the relationship between Operational Risk losses and macroeconomic variables, contributing to risk assessment and mitigation efforts.